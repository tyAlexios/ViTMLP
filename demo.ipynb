{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5f364cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "import time\n",
    "import shutil\n",
    "import math\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13884411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1bd35b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "lr = 30\n",
    "print_frequency = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c0a0c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.hidden1 = nn.Linear(dim, 128)\n",
    "        self.out = nn.Linear(128, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.float32)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c1be47a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMoCo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myMoCo, self).__init__()\n",
    "        \n",
    "        self.pos = 4 #the number of positive samples\n",
    "        \n",
    "        self.indim = 512\n",
    "        self.outdim = 2\n",
    "        self.m = 0.999\n",
    "        self.T = 0.07\n",
    "        self.K = 128*(self.pos-1)\n",
    "        \n",
    "        self.mlp_q = MLP(self.indim).cuda()\n",
    "        self.mlp_k = MLP(self.indim).cuda()\n",
    "        for param_q, param_k in zip(self.mlp_q.parameters(), self.mlp_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data) #initialize key MLP\n",
    "            param_k.required_grad = False\n",
    "        \n",
    "        self.register_buffer(\"queue\", torch.randn(self.outdim, self.K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))   \n",
    "        \n",
    "    \"\"\"\n",
    "    input_q : Batch x feat_size == N x inDim\n",
    "    input_k : (Batch x pos_pairs) x feat_size == (N x J) x inDim ==> M x inDim\n",
    "    \"\"\" \n",
    "    def forward(self, pos_pairs):\n",
    "        input_q = pos_pairs[:,:1,:] #N x 1  x inDim\n",
    "        input_q = input_q.squeeze() #N x inDim\n",
    "        input_q = nn.functional.normalize(input_q, dim=1)\n",
    "        \n",
    "        q = self.mlp_q(input_q) # N x outDim\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            self._momentum_update_key_encoder()\n",
    "            \n",
    "            input_k = pos_pairs[:,1:,:] #N x J x inDim\n",
    "            N = input_k.shape[0]\n",
    "            J = input_k.shape[1]\n",
    "            input_k = torch.reshape(input_k, (-1, self.indim)) # reshape : (N x J) x inDim ==> M x inDim\n",
    "            input_k = nn.functional.normalize(input_k, dim=1)\n",
    "            \n",
    "            k = self.mlp_k(input_k) # M x outDim\n",
    "            k = nn.functional.normalize(k, dim=1)\n",
    "            \n",
    "            k = torch.reshape(k, (N, -1, self.outdim)) # undo reshape : M x outDim ==>(N x J) x outDim\n",
    "        \n",
    "        loss_pos = torch.einsum(\"nc,njc->n\", [q, k]).unsqueeze(-1) # N x 1\n",
    "        loss_pos /= self.pos-1\n",
    "        \n",
    "        loss_neg = torch.einsum(\"nc,ck->nk\", [q, self.queue.clone().detach()]) # N x K\n",
    "        logits = torch.cat([loss_pos, loss_neg], dim=1) # N x (1+K)\n",
    "        logits /= self.T\n",
    "        \n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).cuda()\n",
    "        \n",
    "        self._dequeue_and_enqueue(k)\n",
    "        \n",
    "        return logits, labels\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        for param_q, param_k in zip(self.mlp_q.parameters(), self.mlp_k.parameters()):\n",
    "            param_k.data = param_k.data*self.m + param_q.data*(1.0-self.m)\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "#         chosen = random.randint(0, self.pos-2)\n",
    "#         keys = keys[:, chosen, :].squeeze() #chose one view: N x J x C ==> N x 1 x C ==> N x C\n",
    "        keys = torch.reshape(keys, (-1, self.outdim))\n",
    "        M = keys.shape[0]\n",
    "        ptr = int(self.queue_ptr)\n",
    "        self.queue[:, ptr : ptr + M] = keys.T\n",
    "        ptr = (ptr + M) % self.K\n",
    "        self.queue_ptr[0] = ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a83d30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = 1e-3\n",
    "    lr *= 0.5 * (1.0 + math.cos(math.pi * epoch / epochs))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1dd53054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, \"model_best.pth.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a8d9db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    for i, pos_pairs in enumerate(train_loader):\n",
    "        \n",
    "        output, target = model(pos_pairs)\n",
    "        loss = criterion(output, target)\n",
    "       \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch[{0}]    Iter[{1}/8]    Loss: {2}'.format(epoch+1, i+1, loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d114c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    model = myMoCo().cuda()\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(), \n",
    "        lr = 1e-3,\n",
    "        momentum = 0.9,\n",
    "        weight_decay = 1e-4\n",
    "    )\n",
    "    \n",
    "    \"\"\"\n",
    "    # optionally resume from a checkpoint\n",
    "    ...\n",
    "    \"\"\"\n",
    "    \n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "    train_file = '../CUHK01/dataset.pkl'\n",
    "    N = 256\n",
    "    B = 32\n",
    "    \n",
    "    train_dataset = torch.load(train_file).cuda()\n",
    "    train_dataset = train_dataset[:N]\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = B,\n",
    "        shuffle = True\n",
    "    )\n",
    "    \n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        train(trainloader, model, criterion, optimizer, epoch)\n",
    "        \n",
    "        print('\\n\\n')\n",
    "        \n",
    "        torch.save(model.mlp_q.state_dict(), './pretrained/MLP/mlp{:04d}.pth.tar'.format(epoch+1))\n",
    "        save_checkpoint(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "            },\n",
    "            is_best=False,\n",
    "            filename=\"./pretrained/myMoCo/checkpoint_{:04d}.pth.tar\".format(epoch+1),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1aca3ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1]    Iter[1/8]    Loss: 3.777284860610962\n",
      "Epoch[1]    Iter[2/8]    Loss: 5.222867965698242\n",
      "Epoch[1]    Iter[3/8]    Loss: 5.721696853637695\n",
      "Epoch[1]    Iter[4/8]    Loss: 5.928982257843018\n",
      "Epoch[1]    Iter[5/8]    Loss: 5.970641613006592\n",
      "Epoch[1]    Iter[6/8]    Loss: 5.948601245880127\n",
      "Epoch[1]    Iter[7/8]    Loss: 5.983639240264893\n",
      "Epoch[1]    Iter[8/8]    Loss: 5.949517726898193\n",
      "\n",
      "\n",
      "\n",
      "Epoch[2]    Iter[1/8]    Loss: 5.952399253845215\n",
      "Epoch[2]    Iter[2/8]    Loss: 5.956362724304199\n",
      "Epoch[2]    Iter[3/8]    Loss: 5.943922996520996\n",
      "Epoch[2]    Iter[4/8]    Loss: 5.946775436401367\n",
      "Epoch[2]    Iter[5/8]    Loss: 5.969717502593994\n",
      "Epoch[2]    Iter[6/8]    Loss: 5.957752227783203\n",
      "Epoch[2]    Iter[7/8]    Loss: 5.9516072273254395\n",
      "Epoch[2]    Iter[8/8]    Loss: 5.926485538482666\n",
      "\n",
      "\n",
      "\n",
      "Epoch[3]    Iter[1/8]    Loss: 5.981459140777588\n",
      "Epoch[3]    Iter[2/8]    Loss: 5.954057693481445\n",
      "Epoch[3]    Iter[3/8]    Loss: 5.947371006011963\n",
      "Epoch[3]    Iter[4/8]    Loss: 5.9655375480651855\n",
      "Epoch[3]    Iter[5/8]    Loss: 5.947161674499512\n",
      "Epoch[3]    Iter[6/8]    Loss: 5.945493698120117\n",
      "Epoch[3]    Iter[7/8]    Loss: 5.980298042297363\n",
      "Epoch[3]    Iter[8/8]    Loss: 5.968388080596924\n",
      "\n",
      "\n",
      "\n",
      "Epoch[4]    Iter[1/8]    Loss: 5.959039688110352\n",
      "Epoch[4]    Iter[2/8]    Loss: 5.957780838012695\n",
      "Epoch[4]    Iter[3/8]    Loss: 5.967442035675049\n",
      "Epoch[4]    Iter[4/8]    Loss: 5.929430961608887\n",
      "Epoch[4]    Iter[5/8]    Loss: 5.945469379425049\n",
      "Epoch[4]    Iter[6/8]    Loss: 5.965512752532959\n",
      "Epoch[4]    Iter[7/8]    Loss: 5.951016902923584\n",
      "Epoch[4]    Iter[8/8]    Loss: 5.972989082336426\n",
      "\n",
      "\n",
      "\n",
      "Epoch[5]    Iter[1/8]    Loss: 5.974389553070068\n",
      "Epoch[5]    Iter[2/8]    Loss: 5.94537353515625\n",
      "Epoch[5]    Iter[3/8]    Loss: 5.9417877197265625\n",
      "Epoch[5]    Iter[4/8]    Loss: 5.955319404602051\n",
      "Epoch[5]    Iter[5/8]    Loss: 5.941462993621826\n",
      "Epoch[5]    Iter[6/8]    Loss: 5.958234786987305\n",
      "Epoch[5]    Iter[7/8]    Loss: 5.953028202056885\n",
      "Epoch[5]    Iter[8/8]    Loss: 5.949351787567139\n",
      "\n",
      "\n",
      "\n",
      "Epoch[6]    Iter[1/8]    Loss: 5.96403694152832\n",
      "Epoch[6]    Iter[2/8]    Loss: 5.937734127044678\n",
      "Epoch[6]    Iter[3/8]    Loss: 5.955550670623779\n",
      "Epoch[6]    Iter[4/8]    Loss: 5.965876579284668\n",
      "Epoch[6]    Iter[5/8]    Loss: 5.955683708190918\n",
      "Epoch[6]    Iter[6/8]    Loss: 5.962202548980713\n",
      "Epoch[6]    Iter[7/8]    Loss: 5.944086074829102\n",
      "Epoch[6]    Iter[8/8]    Loss: 5.9478044509887695\n",
      "\n",
      "\n",
      "\n",
      "Epoch[7]    Iter[1/8]    Loss: 5.94330358505249\n",
      "Epoch[7]    Iter[2/8]    Loss: 5.956018924713135\n",
      "Epoch[7]    Iter[3/8]    Loss: 5.949713706970215\n",
      "Epoch[7]    Iter[4/8]    Loss: 5.965977668762207\n",
      "Epoch[7]    Iter[5/8]    Loss: 5.956837177276611\n",
      "Epoch[7]    Iter[6/8]    Loss: 5.959687232971191\n",
      "Epoch[7]    Iter[7/8]    Loss: 5.94874906539917\n",
      "Epoch[7]    Iter[8/8]    Loss: 5.954224586486816\n",
      "\n",
      "\n",
      "\n",
      "Epoch[8]    Iter[1/8]    Loss: 5.970630645751953\n",
      "Epoch[8]    Iter[2/8]    Loss: 5.946795463562012\n",
      "Epoch[8]    Iter[3/8]    Loss: 5.951744556427002\n",
      "Epoch[8]    Iter[4/8]    Loss: 5.94002628326416\n",
      "Epoch[8]    Iter[5/8]    Loss: 5.948831558227539\n",
      "Epoch[8]    Iter[6/8]    Loss: 5.946573257446289\n",
      "Epoch[8]    Iter[7/8]    Loss: 5.961365222930908\n",
      "Epoch[8]    Iter[8/8]    Loss: 5.943180084228516\n",
      "\n",
      "\n",
      "\n",
      "Epoch[9]    Iter[1/8]    Loss: 5.952202796936035\n",
      "Epoch[9]    Iter[2/8]    Loss: 5.968781471252441\n",
      "Epoch[9]    Iter[3/8]    Loss: 5.947441101074219\n",
      "Epoch[9]    Iter[4/8]    Loss: 5.9597978591918945\n",
      "Epoch[9]    Iter[5/8]    Loss: 5.941407680511475\n",
      "Epoch[9]    Iter[6/8]    Loss: 5.9602460861206055\n",
      "Epoch[9]    Iter[7/8]    Loss: 5.9508795738220215\n",
      "Epoch[9]    Iter[8/8]    Loss: 5.954992771148682\n",
      "\n",
      "\n",
      "\n",
      "Epoch[10]    Iter[1/8]    Loss: 5.955563068389893\n",
      "Epoch[10]    Iter[2/8]    Loss: 5.9512810707092285\n",
      "Epoch[10]    Iter[3/8]    Loss: 5.944591999053955\n",
      "Epoch[10]    Iter[4/8]    Loss: 5.961721897125244\n",
      "Epoch[10]    Iter[5/8]    Loss: 5.954534530639648\n",
      "Epoch[10]    Iter[6/8]    Loss: 5.945987224578857\n",
      "Epoch[10]    Iter[7/8]    Loss: 5.960367679595947\n",
      "Epoch[10]    Iter[8/8]    Loss: 5.949544429779053\n",
      "\n",
      "\n",
      "\n",
      "Epoch[11]    Iter[1/8]    Loss: 5.956076145172119\n",
      "Epoch[11]    Iter[2/8]    Loss: 5.948575496673584\n",
      "Epoch[11]    Iter[3/8]    Loss: 5.972362041473389\n",
      "Epoch[11]    Iter[4/8]    Loss: 5.945310592651367\n",
      "Epoch[11]    Iter[5/8]    Loss: 5.9500226974487305\n",
      "Epoch[11]    Iter[6/8]    Loss: 5.9356794357299805\n",
      "Epoch[11]    Iter[7/8]    Loss: 5.950199604034424\n",
      "Epoch[11]    Iter[8/8]    Loss: 5.945329666137695\n",
      "\n",
      "\n",
      "\n",
      "Epoch[12]    Iter[1/8]    Loss: 5.957859992980957\n",
      "Epoch[12]    Iter[2/8]    Loss: 5.960958480834961\n",
      "Epoch[12]    Iter[3/8]    Loss: 5.9482855796813965\n",
      "Epoch[12]    Iter[4/8]    Loss: 5.945749759674072\n",
      "Epoch[12]    Iter[5/8]    Loss: 5.957283020019531\n",
      "Epoch[12]    Iter[6/8]    Loss: 5.969662189483643\n",
      "Epoch[12]    Iter[7/8]    Loss: 5.959377765655518\n",
      "Epoch[12]    Iter[8/8]    Loss: 5.945490837097168\n",
      "\n",
      "\n",
      "\n",
      "Epoch[13]    Iter[1/8]    Loss: 5.94778299331665\n",
      "Epoch[13]    Iter[2/8]    Loss: 5.978126525878906\n",
      "Epoch[13]    Iter[3/8]    Loss: 5.9332275390625\n",
      "Epoch[13]    Iter[4/8]    Loss: 5.949913501739502\n",
      "Epoch[13]    Iter[5/8]    Loss: 5.950633525848389\n",
      "Epoch[13]    Iter[6/8]    Loss: 5.933719635009766\n",
      "Epoch[13]    Iter[7/8]    Loss: 5.957671165466309\n",
      "Epoch[13]    Iter[8/8]    Loss: 5.9537153244018555\n",
      "\n",
      "\n",
      "\n",
      "Epoch[14]    Iter[1/8]    Loss: 5.967812538146973\n",
      "Epoch[14]    Iter[2/8]    Loss: 5.956695079803467\n",
      "Epoch[14]    Iter[3/8]    Loss: 5.939920902252197\n",
      "Epoch[14]    Iter[4/8]    Loss: 5.94212007522583\n",
      "Epoch[14]    Iter[5/8]    Loss: 5.965510845184326\n",
      "Epoch[14]    Iter[6/8]    Loss: 5.956533432006836\n",
      "Epoch[14]    Iter[7/8]    Loss: 5.948498725891113\n",
      "Epoch[14]    Iter[8/8]    Loss: 5.95259952545166\n",
      "\n",
      "\n",
      "\n",
      "Epoch[15]    Iter[1/8]    Loss: 5.954170227050781\n",
      "Epoch[15]    Iter[2/8]    Loss: 5.948921203613281\n",
      "Epoch[15]    Iter[3/8]    Loss: 5.962732791900635\n",
      "Epoch[15]    Iter[4/8]    Loss: 5.95600700378418\n",
      "Epoch[15]    Iter[5/8]    Loss: 5.9506025314331055\n",
      "Epoch[15]    Iter[6/8]    Loss: 5.957414627075195\n",
      "Epoch[15]    Iter[7/8]    Loss: 5.935836315155029\n",
      "Epoch[15]    Iter[8/8]    Loss: 5.938246726989746\n",
      "\n",
      "\n",
      "\n",
      "Epoch[16]    Iter[1/8]    Loss: 5.960787773132324\n",
      "Epoch[16]    Iter[2/8]    Loss: 5.95347785949707\n",
      "Epoch[16]    Iter[3/8]    Loss: 5.954751968383789\n",
      "Epoch[16]    Iter[4/8]    Loss: 5.954462051391602\n",
      "Epoch[16]    Iter[5/8]    Loss: 5.962391376495361\n",
      "Epoch[16]    Iter[6/8]    Loss: 5.942306995391846\n",
      "Epoch[16]    Iter[7/8]    Loss: 5.945714950561523\n",
      "Epoch[16]    Iter[8/8]    Loss: 5.960411071777344\n",
      "\n",
      "\n",
      "\n",
      "Epoch[17]    Iter[1/8]    Loss: 5.9510817527771\n",
      "Epoch[17]    Iter[2/8]    Loss: 5.949649333953857\n",
      "Epoch[17]    Iter[3/8]    Loss: 5.947185039520264\n",
      "Epoch[17]    Iter[4/8]    Loss: 5.940861225128174\n",
      "Epoch[17]    Iter[5/8]    Loss: 5.9567999839782715\n",
      "Epoch[17]    Iter[6/8]    Loss: 5.98385763168335\n",
      "Epoch[17]    Iter[7/8]    Loss: 5.956042766571045\n",
      "Epoch[17]    Iter[8/8]    Loss: 5.946611404418945\n",
      "\n",
      "\n",
      "\n",
      "Epoch[18]    Iter[1/8]    Loss: 5.962333679199219\n",
      "Epoch[18]    Iter[2/8]    Loss: 5.946255207061768\n",
      "Epoch[18]    Iter[3/8]    Loss: 5.942422866821289\n",
      "Epoch[18]    Iter[4/8]    Loss: 5.956972122192383\n",
      "Epoch[18]    Iter[5/8]    Loss: 5.927630424499512\n",
      "Epoch[18]    Iter[6/8]    Loss: 5.945049285888672\n",
      "Epoch[18]    Iter[7/8]    Loss: 5.951473236083984\n",
      "Epoch[18]    Iter[8/8]    Loss: 5.957803249359131\n",
      "\n",
      "\n",
      "\n",
      "Epoch[19]    Iter[1/8]    Loss: 5.954028606414795\n",
      "Epoch[19]    Iter[2/8]    Loss: 5.963558197021484\n",
      "Epoch[19]    Iter[3/8]    Loss: 5.9538092613220215\n",
      "Epoch[19]    Iter[4/8]    Loss: 5.952364444732666\n",
      "Epoch[19]    Iter[5/8]    Loss: 5.954312324523926\n",
      "Epoch[19]    Iter[6/8]    Loss: 5.945735931396484\n",
      "Epoch[19]    Iter[7/8]    Loss: 5.935485363006592\n",
      "Epoch[19]    Iter[8/8]    Loss: 5.9667181968688965\n",
      "\n",
      "\n",
      "\n",
      "Epoch[20]    Iter[1/8]    Loss: 5.956089019775391\n",
      "Epoch[20]    Iter[2/8]    Loss: 5.965391159057617\n",
      "Epoch[20]    Iter[3/8]    Loss: 5.936434268951416\n",
      "Epoch[20]    Iter[4/8]    Loss: 5.950964450836182\n",
      "Epoch[20]    Iter[5/8]    Loss: 5.938902378082275\n",
      "Epoch[20]    Iter[6/8]    Loss: 5.959990501403809\n",
      "Epoch[20]    Iter[7/8]    Loss: 5.951152324676514\n",
      "Epoch[20]    Iter[8/8]    Loss: 5.958331108093262\n",
      "\n",
      "\n",
      "\n",
      "Epoch[21]    Iter[1/8]    Loss: 5.941876411437988\n",
      "Epoch[21]    Iter[2/8]    Loss: 5.960181713104248\n",
      "Epoch[21]    Iter[3/8]    Loss: 5.947134971618652\n",
      "Epoch[21]    Iter[4/8]    Loss: 5.955871105194092\n",
      "Epoch[21]    Iter[5/8]    Loss: 5.9505791664123535\n",
      "Epoch[21]    Iter[6/8]    Loss: 5.954089641571045\n",
      "Epoch[21]    Iter[7/8]    Loss: 5.954042911529541\n",
      "Epoch[21]    Iter[8/8]    Loss: 5.946014404296875\n",
      "\n",
      "\n",
      "\n",
      "Epoch[22]    Iter[1/8]    Loss: 5.96249532699585\n",
      "Epoch[22]    Iter[2/8]    Loss: 5.966890335083008\n",
      "Epoch[22]    Iter[3/8]    Loss: 5.945636749267578\n",
      "Epoch[22]    Iter[4/8]    Loss: 5.941630840301514\n",
      "Epoch[22]    Iter[5/8]    Loss: 5.944512367248535\n",
      "Epoch[22]    Iter[6/8]    Loss: 5.94290018081665\n",
      "Epoch[22]    Iter[7/8]    Loss: 5.943892955780029\n",
      "Epoch[22]    Iter[8/8]    Loss: 5.9525465965271\n",
      "\n",
      "\n",
      "\n",
      "Epoch[23]    Iter[1/8]    Loss: 5.9651265144348145\n",
      "Epoch[23]    Iter[2/8]    Loss: 5.951696395874023\n",
      "Epoch[23]    Iter[3/8]    Loss: 5.954207897186279\n",
      "Epoch[23]    Iter[4/8]    Loss: 5.948264122009277\n",
      "Epoch[23]    Iter[5/8]    Loss: 5.946457862854004\n",
      "Epoch[23]    Iter[6/8]    Loss: 5.95333194732666\n",
      "Epoch[23]    Iter[7/8]    Loss: 5.9443440437316895\n",
      "Epoch[23]    Iter[8/8]    Loss: 5.957678318023682\n",
      "\n",
      "\n",
      "\n",
      "Epoch[24]    Iter[1/8]    Loss: 5.957727432250977\n",
      "Epoch[24]    Iter[2/8]    Loss: 5.940831184387207\n",
      "Epoch[24]    Iter[3/8]    Loss: 5.945106029510498\n",
      "Epoch[24]    Iter[4/8]    Loss: 5.964908123016357\n",
      "Epoch[24]    Iter[5/8]    Loss: 5.970607757568359\n",
      "Epoch[24]    Iter[6/8]    Loss: 5.929390907287598\n",
      "Epoch[24]    Iter[7/8]    Loss: 5.940700531005859\n",
      "Epoch[24]    Iter[8/8]    Loss: 5.955208778381348\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[25]    Iter[1/8]    Loss: 5.953950881958008\n",
      "Epoch[25]    Iter[2/8]    Loss: 5.950544834136963\n",
      "Epoch[25]    Iter[3/8]    Loss: 5.943033695220947\n",
      "Epoch[25]    Iter[4/8]    Loss: 5.960649013519287\n",
      "Epoch[25]    Iter[5/8]    Loss: 5.953338146209717\n",
      "Epoch[25]    Iter[6/8]    Loss: 5.950127124786377\n",
      "Epoch[25]    Iter[7/8]    Loss: 5.963711738586426\n",
      "Epoch[25]    Iter[8/8]    Loss: 5.933159828186035\n",
      "\n",
      "\n",
      "\n",
      "Epoch[26]    Iter[1/8]    Loss: 5.9544782638549805\n",
      "Epoch[26]    Iter[2/8]    Loss: 5.936870098114014\n",
      "Epoch[26]    Iter[3/8]    Loss: 5.9589972496032715\n",
      "Epoch[26]    Iter[4/8]    Loss: 5.957029819488525\n",
      "Epoch[26]    Iter[5/8]    Loss: 5.953390121459961\n",
      "Epoch[26]    Iter[6/8]    Loss: 5.9534454345703125\n",
      "Epoch[26]    Iter[7/8]    Loss: 5.953031063079834\n",
      "Epoch[26]    Iter[8/8]    Loss: 5.950675010681152\n",
      "\n",
      "\n",
      "\n",
      "Epoch[27]    Iter[1/8]    Loss: 5.956895351409912\n",
      "Epoch[27]    Iter[2/8]    Loss: 5.952992916107178\n",
      "Epoch[27]    Iter[3/8]    Loss: 5.943135738372803\n",
      "Epoch[27]    Iter[4/8]    Loss: 5.940786361694336\n",
      "Epoch[27]    Iter[5/8]    Loss: 5.946376323699951\n",
      "Epoch[27]    Iter[6/8]    Loss: 5.965662956237793\n",
      "Epoch[27]    Iter[7/8]    Loss: 5.9470672607421875\n",
      "Epoch[27]    Iter[8/8]    Loss: 5.956175327301025\n",
      "\n",
      "\n",
      "\n",
      "Epoch[28]    Iter[1/8]    Loss: 5.945746421813965\n",
      "Epoch[28]    Iter[2/8]    Loss: 5.938031196594238\n",
      "Epoch[28]    Iter[3/8]    Loss: 5.963215351104736\n",
      "Epoch[28]    Iter[4/8]    Loss: 5.94857120513916\n",
      "Epoch[28]    Iter[5/8]    Loss: 5.948760986328125\n",
      "Epoch[28]    Iter[6/8]    Loss: 5.954926013946533\n",
      "Epoch[28]    Iter[7/8]    Loss: 5.954841613769531\n",
      "Epoch[28]    Iter[8/8]    Loss: 5.956215858459473\n",
      "\n",
      "\n",
      "\n",
      "Epoch[29]    Iter[1/8]    Loss: 5.962343215942383\n",
      "Epoch[29]    Iter[2/8]    Loss: 5.946392059326172\n",
      "Epoch[29]    Iter[3/8]    Loss: 5.949054718017578\n",
      "Epoch[29]    Iter[4/8]    Loss: 5.938036918640137\n",
      "Epoch[29]    Iter[5/8]    Loss: 5.945905685424805\n",
      "Epoch[29]    Iter[6/8]    Loss: 5.951531887054443\n",
      "Epoch[29]    Iter[7/8]    Loss: 5.941386699676514\n",
      "Epoch[29]    Iter[8/8]    Loss: 5.954883575439453\n",
      "\n",
      "\n",
      "\n",
      "Epoch[30]    Iter[1/8]    Loss: 5.950958251953125\n",
      "Epoch[30]    Iter[2/8]    Loss: 5.965645790100098\n",
      "Epoch[30]    Iter[3/8]    Loss: 5.943778038024902\n",
      "Epoch[30]    Iter[4/8]    Loss: 5.950180530548096\n",
      "Epoch[30]    Iter[5/8]    Loss: 5.950579643249512\n",
      "Epoch[30]    Iter[6/8]    Loss: 5.958465099334717\n",
      "Epoch[30]    Iter[7/8]    Loss: 5.934615135192871\n",
      "Epoch[30]    Iter[8/8]    Loss: 5.953254222869873\n",
      "\n",
      "\n",
      "\n",
      "Epoch[31]    Iter[1/8]    Loss: 5.951337814331055\n",
      "Epoch[31]    Iter[2/8]    Loss: 5.94717264175415\n",
      "Epoch[31]    Iter[3/8]    Loss: 5.96226692199707\n",
      "Epoch[31]    Iter[4/8]    Loss: 5.950275421142578\n",
      "Epoch[31]    Iter[5/8]    Loss: 5.944135665893555\n",
      "Epoch[31]    Iter[6/8]    Loss: 5.942419052124023\n",
      "Epoch[31]    Iter[7/8]    Loss: 5.953746795654297\n",
      "Epoch[31]    Iter[8/8]    Loss: 5.948488712310791\n",
      "\n",
      "\n",
      "\n",
      "Epoch[32]    Iter[1/8]    Loss: 5.969321250915527\n",
      "Epoch[32]    Iter[2/8]    Loss: 5.949352264404297\n",
      "Epoch[32]    Iter[3/8]    Loss: 5.948948860168457\n",
      "Epoch[32]    Iter[4/8]    Loss: 5.93482780456543\n",
      "Epoch[32]    Iter[5/8]    Loss: 5.9333648681640625\n",
      "Epoch[32]    Iter[6/8]    Loss: 5.9493727684021\n",
      "Epoch[32]    Iter[7/8]    Loss: 5.957880973815918\n",
      "Epoch[32]    Iter[8/8]    Loss: 5.955999374389648\n",
      "\n",
      "\n",
      "\n",
      "Epoch[33]    Iter[1/8]    Loss: 5.9531569480896\n",
      "Epoch[33]    Iter[2/8]    Loss: 5.940759658813477\n",
      "Epoch[33]    Iter[3/8]    Loss: 5.958009719848633\n",
      "Epoch[33]    Iter[4/8]    Loss: 5.963496685028076\n",
      "Epoch[33]    Iter[5/8]    Loss: 5.947588920593262\n",
      "Epoch[33]    Iter[6/8]    Loss: 5.9573798179626465\n",
      "Epoch[33]    Iter[7/8]    Loss: 5.940951347351074\n",
      "Epoch[33]    Iter[8/8]    Loss: 5.949329853057861\n",
      "\n",
      "\n",
      "\n",
      "Epoch[34]    Iter[1/8]    Loss: 5.9531779289245605\n",
      "Epoch[34]    Iter[2/8]    Loss: 5.9483232498168945\n",
      "Epoch[34]    Iter[3/8]    Loss: 5.953646659851074\n",
      "Epoch[34]    Iter[4/8]    Loss: 5.949652194976807\n",
      "Epoch[34]    Iter[5/8]    Loss: 5.960843563079834\n",
      "Epoch[34]    Iter[6/8]    Loss: 5.9438862800598145\n",
      "Epoch[34]    Iter[7/8]    Loss: 5.935613632202148\n",
      "Epoch[34]    Iter[8/8]    Loss: 5.946449279785156\n",
      "\n",
      "\n",
      "\n",
      "Epoch[35]    Iter[1/8]    Loss: 5.9482340812683105\n",
      "Epoch[35]    Iter[2/8]    Loss: 5.963156223297119\n",
      "Epoch[35]    Iter[3/8]    Loss: 5.945013046264648\n",
      "Epoch[35]    Iter[4/8]    Loss: 5.95277738571167\n",
      "Epoch[35]    Iter[5/8]    Loss: 5.946411609649658\n",
      "Epoch[35]    Iter[6/8]    Loss: 5.934514999389648\n",
      "Epoch[35]    Iter[7/8]    Loss: 5.951860427856445\n",
      "Epoch[35]    Iter[8/8]    Loss: 5.968328952789307\n",
      "\n",
      "\n",
      "\n",
      "Epoch[36]    Iter[1/8]    Loss: 5.9495673179626465\n",
      "Epoch[36]    Iter[2/8]    Loss: 5.954101085662842\n",
      "Epoch[36]    Iter[3/8]    Loss: 5.942776679992676\n",
      "Epoch[36]    Iter[4/8]    Loss: 5.948092937469482\n",
      "Epoch[36]    Iter[5/8]    Loss: 5.947788238525391\n",
      "Epoch[36]    Iter[6/8]    Loss: 5.949569225311279\n",
      "Epoch[36]    Iter[7/8]    Loss: 5.955324172973633\n",
      "Epoch[36]    Iter[8/8]    Loss: 5.944441318511963\n",
      "\n",
      "\n",
      "\n",
      "Epoch[37]    Iter[1/8]    Loss: 5.942019462585449\n",
      "Epoch[37]    Iter[2/8]    Loss: 5.949746131896973\n",
      "Epoch[37]    Iter[3/8]    Loss: 5.954070568084717\n",
      "Epoch[37]    Iter[4/8]    Loss: 5.954751491546631\n",
      "Epoch[37]    Iter[5/8]    Loss: 5.961116313934326\n",
      "Epoch[37]    Iter[6/8]    Loss: 5.946396827697754\n",
      "Epoch[37]    Iter[7/8]    Loss: 5.949821472167969\n",
      "Epoch[37]    Iter[8/8]    Loss: 5.940412521362305\n",
      "\n",
      "\n",
      "\n",
      "Epoch[38]    Iter[1/8]    Loss: 5.960788249969482\n",
      "Epoch[38]    Iter[2/8]    Loss: 5.948277950286865\n",
      "Epoch[38]    Iter[3/8]    Loss: 5.947285175323486\n",
      "Epoch[38]    Iter[4/8]    Loss: 5.93867826461792\n",
      "Epoch[38]    Iter[5/8]    Loss: 5.934074878692627\n",
      "Epoch[38]    Iter[6/8]    Loss: 5.955966472625732\n",
      "Epoch[38]    Iter[7/8]    Loss: 5.965672492980957\n",
      "Epoch[38]    Iter[8/8]    Loss: 5.941825866699219\n",
      "\n",
      "\n",
      "\n",
      "Epoch[39]    Iter[1/8]    Loss: 5.950206279754639\n",
      "Epoch[39]    Iter[2/8]    Loss: 5.949586391448975\n",
      "Epoch[39]    Iter[3/8]    Loss: 5.944060325622559\n",
      "Epoch[39]    Iter[4/8]    Loss: 5.945861339569092\n",
      "Epoch[39]    Iter[5/8]    Loss: 5.968562602996826\n",
      "Epoch[39]    Iter[6/8]    Loss: 5.94754695892334\n",
      "Epoch[39]    Iter[7/8]    Loss: 5.941349029541016\n",
      "Epoch[39]    Iter[8/8]    Loss: 5.949252128601074\n",
      "\n",
      "\n",
      "\n",
      "Epoch[40]    Iter[1/8]    Loss: 5.951937198638916\n",
      "Epoch[40]    Iter[2/8]    Loss: 5.94545316696167\n",
      "Epoch[40]    Iter[3/8]    Loss: 5.949229717254639\n",
      "Epoch[40]    Iter[4/8]    Loss: 5.941661357879639\n",
      "Epoch[40]    Iter[5/8]    Loss: 5.952087879180908\n",
      "Epoch[40]    Iter[6/8]    Loss: 5.9567389488220215\n",
      "Epoch[40]    Iter[7/8]    Loss: 5.9410295486450195\n",
      "Epoch[40]    Iter[8/8]    Loss: 5.941754341125488\n",
      "\n",
      "\n",
      "\n",
      "Epoch[41]    Iter[1/8]    Loss: 5.955996990203857\n",
      "Epoch[41]    Iter[2/8]    Loss: 5.960003852844238\n",
      "Epoch[41]    Iter[3/8]    Loss: 5.940827369689941\n",
      "Epoch[41]    Iter[4/8]    Loss: 5.949609279632568\n",
      "Epoch[41]    Iter[5/8]    Loss: 5.94502067565918\n",
      "Epoch[41]    Iter[6/8]    Loss: 5.952152252197266\n",
      "Epoch[41]    Iter[7/8]    Loss: 5.942586421966553\n",
      "Epoch[41]    Iter[8/8]    Loss: 5.940574645996094\n",
      "\n",
      "\n",
      "\n",
      "Epoch[42]    Iter[1/8]    Loss: 5.949827194213867\n",
      "Epoch[42]    Iter[2/8]    Loss: 5.9628143310546875\n",
      "Epoch[42]    Iter[3/8]    Loss: 5.954095840454102\n",
      "Epoch[42]    Iter[4/8]    Loss: 5.950586795806885\n",
      "Epoch[42]    Iter[5/8]    Loss: 5.933372497558594\n",
      "Epoch[42]    Iter[6/8]    Loss: 5.952066898345947\n",
      "Epoch[42]    Iter[7/8]    Loss: 5.93850564956665\n",
      "Epoch[42]    Iter[8/8]    Loss: 5.966522216796875\n",
      "\n",
      "\n",
      "\n",
      "Epoch[43]    Iter[1/8]    Loss: 5.94614839553833\n",
      "Epoch[43]    Iter[2/8]    Loss: 5.951980113983154\n",
      "Epoch[43]    Iter[3/8]    Loss: 5.94736909866333\n",
      "Epoch[43]    Iter[4/8]    Loss: 5.949576377868652\n",
      "Epoch[43]    Iter[5/8]    Loss: 5.949882507324219\n",
      "Epoch[43]    Iter[6/8]    Loss: 5.952128887176514\n",
      "Epoch[43]    Iter[7/8]    Loss: 5.937867164611816\n",
      "Epoch[43]    Iter[8/8]    Loss: 5.9460930824279785\n",
      "\n",
      "\n",
      "\n",
      "Epoch[44]    Iter[1/8]    Loss: 5.951881408691406\n",
      "Epoch[44]    Iter[2/8]    Loss: 5.953861236572266\n",
      "Epoch[44]    Iter[3/8]    Loss: 5.95219612121582\n",
      "Epoch[44]    Iter[4/8]    Loss: 5.948838710784912\n",
      "Epoch[44]    Iter[5/8]    Loss: 5.935760021209717\n",
      "Epoch[44]    Iter[6/8]    Loss: 5.939148426055908\n",
      "Epoch[44]    Iter[7/8]    Loss: 5.964249610900879\n",
      "Epoch[44]    Iter[8/8]    Loss: 5.951886177062988\n",
      "\n",
      "\n",
      "\n",
      "Epoch[45]    Iter[1/8]    Loss: 5.954457759857178\n",
      "Epoch[45]    Iter[2/8]    Loss: 5.9322004318237305\n",
      "Epoch[45]    Iter[3/8]    Loss: 5.940152168273926\n",
      "Epoch[45]    Iter[4/8]    Loss: 5.96016263961792\n",
      "Epoch[45]    Iter[5/8]    Loss: 5.954960346221924\n",
      "Epoch[45]    Iter[6/8]    Loss: 5.950460910797119\n",
      "Epoch[45]    Iter[7/8]    Loss: 5.932370185852051\n",
      "Epoch[45]    Iter[8/8]    Loss: 5.9522271156311035\n",
      "\n",
      "\n",
      "\n",
      "Epoch[46]    Iter[1/8]    Loss: 5.943532466888428\n",
      "Epoch[46]    Iter[2/8]    Loss: 5.944323539733887\n",
      "Epoch[46]    Iter[3/8]    Loss: 5.957225799560547\n",
      "Epoch[46]    Iter[4/8]    Loss: 5.941100597381592\n",
      "Epoch[46]    Iter[5/8]    Loss: 5.959104537963867\n",
      "Epoch[46]    Iter[6/8]    Loss: 5.941403865814209\n",
      "Epoch[46]    Iter[7/8]    Loss: 5.940135478973389\n",
      "Epoch[46]    Iter[8/8]    Loss: 5.983377456665039\n",
      "\n",
      "\n",
      "\n",
      "Epoch[47]    Iter[1/8]    Loss: 5.937504291534424\n",
      "Epoch[47]    Iter[2/8]    Loss: 5.945546627044678\n",
      "Epoch[47]    Iter[3/8]    Loss: 5.947083950042725\n",
      "Epoch[47]    Iter[4/8]    Loss: 5.942415714263916\n",
      "Epoch[47]    Iter[5/8]    Loss: 5.95646858215332\n",
      "Epoch[47]    Iter[6/8]    Loss: 5.944103240966797\n",
      "Epoch[47]    Iter[7/8]    Loss: 5.9367899894714355\n",
      "Epoch[47]    Iter[8/8]    Loss: 5.945989608764648\n",
      "\n",
      "\n",
      "\n",
      "Epoch[48]    Iter[1/8]    Loss: 5.948013782501221\n",
      "Epoch[48]    Iter[2/8]    Loss: 5.947754859924316\n",
      "Epoch[48]    Iter[3/8]    Loss: 5.948335647583008\n",
      "Epoch[48]    Iter[4/8]    Loss: 5.949660301208496\n",
      "Epoch[48]    Iter[5/8]    Loss: 5.95769739151001\n",
      "Epoch[48]    Iter[6/8]    Loss: 5.944958209991455\n",
      "Epoch[48]    Iter[7/8]    Loss: 5.962010383605957\n",
      "Epoch[48]    Iter[8/8]    Loss: 5.944595813751221\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[49]    Iter[1/8]    Loss: 5.948437690734863\n",
      "Epoch[49]    Iter[2/8]    Loss: 5.954164505004883\n",
      "Epoch[49]    Iter[3/8]    Loss: 5.939745903015137\n",
      "Epoch[49]    Iter[4/8]    Loss: 5.927596092224121\n",
      "Epoch[49]    Iter[5/8]    Loss: 5.950538158416748\n",
      "Epoch[49]    Iter[6/8]    Loss: 5.947000503540039\n",
      "Epoch[49]    Iter[7/8]    Loss: 5.950045108795166\n",
      "Epoch[49]    Iter[8/8]    Loss: 5.957053184509277\n",
      "\n",
      "\n",
      "\n",
      "Epoch[50]    Iter[1/8]    Loss: 5.950817584991455\n",
      "Epoch[50]    Iter[2/8]    Loss: 5.942691802978516\n",
      "Epoch[50]    Iter[3/8]    Loss: 5.938488483428955\n",
      "Epoch[50]    Iter[4/8]    Loss: 5.941954612731934\n",
      "Epoch[50]    Iter[5/8]    Loss: 5.942447185516357\n",
      "Epoch[50]    Iter[6/8]    Loss: 5.974099636077881\n",
      "Epoch[50]    Iter[7/8]    Loss: 5.939630031585693\n",
      "Epoch[50]    Iter[8/8]    Loss: 5.955088138580322\n",
      "\n",
      "\n",
      "\n",
      "Epoch[51]    Iter[1/8]    Loss: 5.956601619720459\n",
      "Epoch[51]    Iter[2/8]    Loss: 5.933590888977051\n",
      "Epoch[51]    Iter[3/8]    Loss: 5.939294815063477\n",
      "Epoch[51]    Iter[4/8]    Loss: 5.956461429595947\n",
      "Epoch[51]    Iter[5/8]    Loss: 5.934179306030273\n",
      "Epoch[51]    Iter[6/8]    Loss: 5.953053951263428\n",
      "Epoch[51]    Iter[7/8]    Loss: 5.9491753578186035\n",
      "Epoch[51]    Iter[8/8]    Loss: 5.953536033630371\n",
      "\n",
      "\n",
      "\n",
      "Epoch[52]    Iter[1/8]    Loss: 5.948758125305176\n",
      "Epoch[52]    Iter[2/8]    Loss: 5.936971664428711\n",
      "Epoch[52]    Iter[3/8]    Loss: 5.947845935821533\n",
      "Epoch[52]    Iter[4/8]    Loss: 5.943411350250244\n",
      "Epoch[52]    Iter[5/8]    Loss: 5.945212364196777\n",
      "Epoch[52]    Iter[6/8]    Loss: 5.955120086669922\n",
      "Epoch[52]    Iter[7/8]    Loss: 5.949394226074219\n",
      "Epoch[52]    Iter[8/8]    Loss: 5.9549241065979\n",
      "\n",
      "\n",
      "\n",
      "Epoch[53]    Iter[1/8]    Loss: 5.943840980529785\n",
      "Epoch[53]    Iter[2/8]    Loss: 5.943782806396484\n",
      "Epoch[53]    Iter[3/8]    Loss: 5.935785293579102\n",
      "Epoch[53]    Iter[4/8]    Loss: 5.950544834136963\n",
      "Epoch[53]    Iter[5/8]    Loss: 5.957027912139893\n",
      "Epoch[53]    Iter[6/8]    Loss: 5.937493801116943\n",
      "Epoch[53]    Iter[7/8]    Loss: 5.9591851234436035\n",
      "Epoch[53]    Iter[8/8]    Loss: 5.949872016906738\n",
      "\n",
      "\n",
      "\n",
      "Epoch[54]    Iter[1/8]    Loss: 5.94474458694458\n",
      "Epoch[54]    Iter[2/8]    Loss: 5.940513610839844\n",
      "Epoch[54]    Iter[3/8]    Loss: 5.944260597229004\n",
      "Epoch[54]    Iter[4/8]    Loss: 5.942832946777344\n",
      "Epoch[54]    Iter[5/8]    Loss: 5.944740295410156\n",
      "Epoch[54]    Iter[6/8]    Loss: 5.964253902435303\n",
      "Epoch[54]    Iter[7/8]    Loss: 5.942589282989502\n",
      "Epoch[54]    Iter[8/8]    Loss: 5.949419021606445\n",
      "\n",
      "\n",
      "\n",
      "Epoch[55]    Iter[1/8]    Loss: 5.952737331390381\n",
      "Epoch[55]    Iter[2/8]    Loss: 5.935506343841553\n",
      "Epoch[55]    Iter[3/8]    Loss: 5.940518379211426\n",
      "Epoch[55]    Iter[4/8]    Loss: 5.968055248260498\n",
      "Epoch[55]    Iter[5/8]    Loss: 5.942417144775391\n",
      "Epoch[55]    Iter[6/8]    Loss: 5.933739185333252\n",
      "Epoch[55]    Iter[7/8]    Loss: 5.943915367126465\n",
      "Epoch[55]    Iter[8/8]    Loss: 5.941218852996826\n",
      "\n",
      "\n",
      "\n",
      "Epoch[56]    Iter[1/8]    Loss: 5.962409496307373\n",
      "Epoch[56]    Iter[2/8]    Loss: 5.958590984344482\n",
      "Epoch[56]    Iter[3/8]    Loss: 5.945368766784668\n",
      "Epoch[56]    Iter[4/8]    Loss: 5.940813064575195\n",
      "Epoch[56]    Iter[5/8]    Loss: 5.928569316864014\n",
      "Epoch[56]    Iter[6/8]    Loss: 5.936367034912109\n",
      "Epoch[56]    Iter[7/8]    Loss: 5.945512771606445\n",
      "Epoch[56]    Iter[8/8]    Loss: 5.9586501121521\n",
      "\n",
      "\n",
      "\n",
      "Epoch[57]    Iter[1/8]    Loss: 5.95045804977417\n",
      "Epoch[57]    Iter[2/8]    Loss: 5.9408040046691895\n",
      "Epoch[57]    Iter[3/8]    Loss: 5.935286521911621\n",
      "Epoch[57]    Iter[4/8]    Loss: 5.94221305847168\n",
      "Epoch[57]    Iter[5/8]    Loss: 5.963753700256348\n",
      "Epoch[57]    Iter[6/8]    Loss: 5.949992656707764\n",
      "Epoch[57]    Iter[7/8]    Loss: 5.964552402496338\n",
      "Epoch[57]    Iter[8/8]    Loss: 5.939352989196777\n",
      "\n",
      "\n",
      "\n",
      "Epoch[58]    Iter[1/8]    Loss: 5.9593000411987305\n",
      "Epoch[58]    Iter[2/8]    Loss: 5.929107666015625\n",
      "Epoch[58]    Iter[3/8]    Loss: 5.941320896148682\n",
      "Epoch[58]    Iter[4/8]    Loss: 5.941729545593262\n",
      "Epoch[58]    Iter[5/8]    Loss: 5.941323280334473\n",
      "Epoch[58]    Iter[6/8]    Loss: 5.957215785980225\n",
      "Epoch[58]    Iter[7/8]    Loss: 5.933498859405518\n",
      "Epoch[58]    Iter[8/8]    Loss: 5.9367218017578125\n",
      "\n",
      "\n",
      "\n",
      "Epoch[59]    Iter[1/8]    Loss: 5.944782733917236\n",
      "Epoch[59]    Iter[2/8]    Loss: 5.942253589630127\n",
      "Epoch[59]    Iter[3/8]    Loss: 5.965124130249023\n",
      "Epoch[59]    Iter[4/8]    Loss: 5.9505205154418945\n",
      "Epoch[59]    Iter[5/8]    Loss: 5.948415279388428\n",
      "Epoch[59]    Iter[6/8]    Loss: 5.943883419036865\n",
      "Epoch[59]    Iter[7/8]    Loss: 5.946711540222168\n",
      "Epoch[59]    Iter[8/8]    Loss: 5.949285507202148\n",
      "\n",
      "\n",
      "\n",
      "Epoch[60]    Iter[1/8]    Loss: 5.9556121826171875\n",
      "Epoch[60]    Iter[2/8]    Loss: 5.948162078857422\n",
      "Epoch[60]    Iter[3/8]    Loss: 5.9449543952941895\n",
      "Epoch[60]    Iter[4/8]    Loss: 5.927859783172607\n",
      "Epoch[60]    Iter[5/8]    Loss: 5.934151649475098\n",
      "Epoch[60]    Iter[6/8]    Loss: 5.954702854156494\n",
      "Epoch[60]    Iter[7/8]    Loss: 5.948885917663574\n",
      "Epoch[60]    Iter[8/8]    Loss: 5.950814723968506\n",
      "\n",
      "\n",
      "\n",
      "Epoch[61]    Iter[1/8]    Loss: 5.937219142913818\n",
      "Epoch[61]    Iter[2/8]    Loss: 5.945602893829346\n",
      "Epoch[61]    Iter[3/8]    Loss: 5.95322322845459\n",
      "Epoch[61]    Iter[4/8]    Loss: 5.956686019897461\n",
      "Epoch[61]    Iter[5/8]    Loss: 5.957359790802002\n",
      "Epoch[61]    Iter[6/8]    Loss: 5.931858539581299\n",
      "Epoch[61]    Iter[7/8]    Loss: 5.933826446533203\n",
      "Epoch[61]    Iter[8/8]    Loss: 5.941377639770508\n",
      "\n",
      "\n",
      "\n",
      "Epoch[62]    Iter[1/8]    Loss: 5.951671123504639\n",
      "Epoch[62]    Iter[2/8]    Loss: 5.9446539878845215\n",
      "Epoch[62]    Iter[3/8]    Loss: 5.937456130981445\n",
      "Epoch[62]    Iter[4/8]    Loss: 5.959543704986572\n",
      "Epoch[62]    Iter[5/8]    Loss: 5.942307472229004\n",
      "Epoch[62]    Iter[6/8]    Loss: 5.94527006149292\n",
      "Epoch[62]    Iter[7/8]    Loss: 5.939269542694092\n",
      "Epoch[62]    Iter[8/8]    Loss: 5.9428629875183105\n",
      "\n",
      "\n",
      "\n",
      "Epoch[63]    Iter[1/8]    Loss: 5.945585250854492\n",
      "Epoch[63]    Iter[2/8]    Loss: 5.939704418182373\n",
      "Epoch[63]    Iter[3/8]    Loss: 5.960594654083252\n",
      "Epoch[63]    Iter[4/8]    Loss: 5.943619728088379\n",
      "Epoch[63]    Iter[5/8]    Loss: 5.932990074157715\n",
      "Epoch[63]    Iter[6/8]    Loss: 5.947031497955322\n",
      "Epoch[63]    Iter[7/8]    Loss: 5.940134525299072\n",
      "Epoch[63]    Iter[8/8]    Loss: 5.956472873687744\n",
      "\n",
      "\n",
      "\n",
      "Epoch[64]    Iter[1/8]    Loss: 5.950702667236328\n",
      "Epoch[64]    Iter[2/8]    Loss: 5.927561283111572\n",
      "Epoch[64]    Iter[3/8]    Loss: 5.9595184326171875\n",
      "Epoch[64]    Iter[4/8]    Loss: 5.940861225128174\n",
      "Epoch[64]    Iter[5/8]    Loss: 5.951334476470947\n",
      "Epoch[64]    Iter[6/8]    Loss: 5.948156356811523\n",
      "Epoch[64]    Iter[7/8]    Loss: 5.931248664855957\n",
      "Epoch[64]    Iter[8/8]    Loss: 5.951149940490723\n",
      "\n",
      "\n",
      "\n",
      "Epoch[65]    Iter[1/8]    Loss: 5.9458770751953125\n",
      "Epoch[65]    Iter[2/8]    Loss: 5.942636489868164\n",
      "Epoch[65]    Iter[3/8]    Loss: 5.951148986816406\n",
      "Epoch[65]    Iter[4/8]    Loss: 5.942636013031006\n",
      "Epoch[65]    Iter[5/8]    Loss: 5.938720226287842\n",
      "Epoch[65]    Iter[6/8]    Loss: 5.943374156951904\n",
      "Epoch[65]    Iter[7/8]    Loss: 5.946603775024414\n",
      "Epoch[65]    Iter[8/8]    Loss: 5.940733432769775\n",
      "\n",
      "\n",
      "\n",
      "Epoch[66]    Iter[1/8]    Loss: 5.9494500160217285\n",
      "Epoch[66]    Iter[2/8]    Loss: 5.950272560119629\n",
      "Epoch[66]    Iter[3/8]    Loss: 5.947865009307861\n",
      "Epoch[66]    Iter[4/8]    Loss: 5.9436235427856445\n",
      "Epoch[66]    Iter[5/8]    Loss: 5.942439556121826\n",
      "Epoch[66]    Iter[6/8]    Loss: 5.932648181915283\n",
      "Epoch[66]    Iter[7/8]    Loss: 5.9541449546813965\n",
      "Epoch[66]    Iter[8/8]    Loss: 5.947851657867432\n",
      "\n",
      "\n",
      "\n",
      "Epoch[67]    Iter[1/8]    Loss: 5.933849811553955\n",
      "Epoch[67]    Iter[2/8]    Loss: 5.94296932220459\n",
      "Epoch[67]    Iter[3/8]    Loss: 5.954907417297363\n",
      "Epoch[67]    Iter[4/8]    Loss: 5.955178260803223\n",
      "Epoch[67]    Iter[5/8]    Loss: 5.953217029571533\n",
      "Epoch[67]    Iter[6/8]    Loss: 5.937222957611084\n",
      "Epoch[67]    Iter[7/8]    Loss: 5.928734302520752\n",
      "Epoch[67]    Iter[8/8]    Loss: 5.933928489685059\n",
      "\n",
      "\n",
      "\n",
      "Epoch[68]    Iter[1/8]    Loss: 5.937546730041504\n",
      "Epoch[68]    Iter[2/8]    Loss: 5.962514877319336\n",
      "Epoch[68]    Iter[3/8]    Loss: 5.9496750831604\n",
      "Epoch[68]    Iter[4/8]    Loss: 5.935422420501709\n",
      "Epoch[68]    Iter[5/8]    Loss: 5.941648960113525\n",
      "Epoch[68]    Iter[6/8]    Loss: 5.944117546081543\n",
      "Epoch[68]    Iter[7/8]    Loss: 5.94087028503418\n",
      "Epoch[68]    Iter[8/8]    Loss: 5.940587043762207\n",
      "\n",
      "\n",
      "\n",
      "Epoch[69]    Iter[1/8]    Loss: 5.9574384689331055\n",
      "Epoch[69]    Iter[2/8]    Loss: 5.938074588775635\n",
      "Epoch[69]    Iter[3/8]    Loss: 5.952180862426758\n",
      "Epoch[69]    Iter[4/8]    Loss: 5.93686056137085\n",
      "Epoch[69]    Iter[5/8]    Loss: 5.938720226287842\n",
      "Epoch[69]    Iter[6/8]    Loss: 5.955438613891602\n",
      "Epoch[69]    Iter[7/8]    Loss: 5.95477294921875\n",
      "Epoch[69]    Iter[8/8]    Loss: 5.937499046325684\n",
      "\n",
      "\n",
      "\n",
      "Epoch[70]    Iter[1/8]    Loss: 5.952837944030762\n",
      "Epoch[70]    Iter[2/8]    Loss: 5.928124904632568\n",
      "Epoch[70]    Iter[3/8]    Loss: 5.937339782714844\n",
      "Epoch[70]    Iter[4/8]    Loss: 5.94577693939209\n",
      "Epoch[70]    Iter[5/8]    Loss: 5.951930522918701\n",
      "Epoch[70]    Iter[6/8]    Loss: 5.956697463989258\n",
      "Epoch[70]    Iter[7/8]    Loss: 5.932497978210449\n",
      "Epoch[70]    Iter[8/8]    Loss: 5.924551963806152\n",
      "\n",
      "\n",
      "\n",
      "Epoch[71]    Iter[1/8]    Loss: 5.9547929763793945\n",
      "Epoch[71]    Iter[2/8]    Loss: 5.939228057861328\n",
      "Epoch[71]    Iter[3/8]    Loss: 5.947746276855469\n",
      "Epoch[71]    Iter[4/8]    Loss: 5.949371814727783\n",
      "Epoch[71]    Iter[5/8]    Loss: 5.945300102233887\n",
      "Epoch[71]    Iter[6/8]    Loss: 5.938708305358887\n",
      "Epoch[71]    Iter[7/8]    Loss: 5.93776273727417\n",
      "Epoch[71]    Iter[8/8]    Loss: 5.943343162536621\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[72]    Iter[1/8]    Loss: 5.953064441680908\n",
      "Epoch[72]    Iter[2/8]    Loss: 5.951503276824951\n",
      "Epoch[72]    Iter[3/8]    Loss: 5.935093879699707\n",
      "Epoch[72]    Iter[4/8]    Loss: 5.937602996826172\n",
      "Epoch[72]    Iter[5/8]    Loss: 5.945241928100586\n",
      "Epoch[72]    Iter[6/8]    Loss: 5.949632167816162\n",
      "Epoch[72]    Iter[7/8]    Loss: 5.941051483154297\n",
      "Epoch[72]    Iter[8/8]    Loss: 5.939154148101807\n",
      "\n",
      "\n",
      "\n",
      "Epoch[73]    Iter[1/8]    Loss: 5.955932140350342\n",
      "Epoch[73]    Iter[2/8]    Loss: 5.944364070892334\n",
      "Epoch[73]    Iter[3/8]    Loss: 5.946325778961182\n",
      "Epoch[73]    Iter[4/8]    Loss: 5.930893421173096\n",
      "Epoch[73]    Iter[5/8]    Loss: 5.935590744018555\n",
      "Epoch[73]    Iter[6/8]    Loss: 5.946317672729492\n",
      "Epoch[73]    Iter[7/8]    Loss: 5.9333391189575195\n",
      "Epoch[73]    Iter[8/8]    Loss: 5.9410929679870605\n",
      "\n",
      "\n",
      "\n",
      "Epoch[74]    Iter[1/8]    Loss: 5.950859069824219\n",
      "Epoch[74]    Iter[2/8]    Loss: 5.9501776695251465\n",
      "Epoch[74]    Iter[3/8]    Loss: 5.95236349105835\n",
      "Epoch[74]    Iter[4/8]    Loss: 5.944741249084473\n",
      "Epoch[74]    Iter[5/8]    Loss: 5.937341213226318\n",
      "Epoch[74]    Iter[6/8]    Loss: 5.9333720207214355\n",
      "Epoch[74]    Iter[7/8]    Loss: 5.935042858123779\n",
      "Epoch[74]    Iter[8/8]    Loss: 5.940406799316406\n",
      "\n",
      "\n",
      "\n",
      "Epoch[75]    Iter[1/8]    Loss: 5.939164161682129\n",
      "Epoch[75]    Iter[2/8]    Loss: 5.955634117126465\n",
      "Epoch[75]    Iter[3/8]    Loss: 5.946976184844971\n",
      "Epoch[75]    Iter[4/8]    Loss: 5.948086738586426\n",
      "Epoch[75]    Iter[5/8]    Loss: 5.955742835998535\n",
      "Epoch[75]    Iter[6/8]    Loss: 5.937382698059082\n",
      "Epoch[75]    Iter[7/8]    Loss: 5.944331645965576\n",
      "Epoch[75]    Iter[8/8]    Loss: 5.933859825134277\n",
      "\n",
      "\n",
      "\n",
      "Epoch[76]    Iter[1/8]    Loss: 5.939713478088379\n",
      "Epoch[76]    Iter[2/8]    Loss: 5.939432144165039\n",
      "Epoch[76]    Iter[3/8]    Loss: 5.9439473152160645\n",
      "Epoch[76]    Iter[4/8]    Loss: 5.956611156463623\n",
      "Epoch[76]    Iter[5/8]    Loss: 5.949354648590088\n",
      "Epoch[76]    Iter[6/8]    Loss: 5.935758590698242\n",
      "Epoch[76]    Iter[7/8]    Loss: 5.930675506591797\n",
      "Epoch[76]    Iter[8/8]    Loss: 5.927459239959717\n",
      "\n",
      "\n",
      "\n",
      "Epoch[77]    Iter[1/8]    Loss: 5.93700647354126\n",
      "Epoch[77]    Iter[2/8]    Loss: 5.941969394683838\n",
      "Epoch[77]    Iter[3/8]    Loss: 5.940244674682617\n",
      "Epoch[77]    Iter[4/8]    Loss: 5.959072589874268\n",
      "Epoch[77]    Iter[5/8]    Loss: 5.947725296020508\n",
      "Epoch[77]    Iter[6/8]    Loss: 5.941866874694824\n",
      "Epoch[77]    Iter[7/8]    Loss: 5.940112113952637\n",
      "Epoch[77]    Iter[8/8]    Loss: 5.9468674659729\n",
      "\n",
      "\n",
      "\n",
      "Epoch[78]    Iter[1/8]    Loss: 5.939243316650391\n",
      "Epoch[78]    Iter[2/8]    Loss: 5.94388484954834\n",
      "Epoch[78]    Iter[3/8]    Loss: 5.936694622039795\n",
      "Epoch[78]    Iter[4/8]    Loss: 5.924926280975342\n",
      "Epoch[78]    Iter[5/8]    Loss: 5.953675270080566\n",
      "Epoch[78]    Iter[6/8]    Loss: 5.944429874420166\n",
      "Epoch[78]    Iter[7/8]    Loss: 5.947401523590088\n",
      "Epoch[78]    Iter[8/8]    Loss: 5.944602012634277\n",
      "\n",
      "\n",
      "\n",
      "Epoch[79]    Iter[1/8]    Loss: 5.930378437042236\n",
      "Epoch[79]    Iter[2/8]    Loss: 5.946783542633057\n",
      "Epoch[79]    Iter[3/8]    Loss: 5.952143669128418\n",
      "Epoch[79]    Iter[4/8]    Loss: 5.957119941711426\n",
      "Epoch[79]    Iter[5/8]    Loss: 5.936465263366699\n",
      "Epoch[79]    Iter[6/8]    Loss: 5.926527500152588\n",
      "Epoch[79]    Iter[7/8]    Loss: 5.930493354797363\n",
      "Epoch[79]    Iter[8/8]    Loss: 5.94334077835083\n",
      "\n",
      "\n",
      "\n",
      "Epoch[80]    Iter[1/8]    Loss: 5.942838191986084\n",
      "Epoch[80]    Iter[2/8]    Loss: 5.958616733551025\n",
      "Epoch[80]    Iter[3/8]    Loss: 5.945476055145264\n",
      "Epoch[80]    Iter[4/8]    Loss: 5.9486165046691895\n",
      "Epoch[80]    Iter[5/8]    Loss: 5.93783712387085\n",
      "Epoch[80]    Iter[6/8]    Loss: 5.928457736968994\n",
      "Epoch[80]    Iter[7/8]    Loss: 5.932883262634277\n",
      "Epoch[80]    Iter[8/8]    Loss: 5.946693420410156\n",
      "\n",
      "\n",
      "\n",
      "Epoch[81]    Iter[1/8]    Loss: 5.93625545501709\n",
      "Epoch[81]    Iter[2/8]    Loss: 5.938060760498047\n",
      "Epoch[81]    Iter[3/8]    Loss: 5.934427738189697\n",
      "Epoch[81]    Iter[4/8]    Loss: 5.9456467628479\n",
      "Epoch[81]    Iter[5/8]    Loss: 5.952635765075684\n",
      "Epoch[81]    Iter[6/8]    Loss: 5.949916839599609\n",
      "Epoch[81]    Iter[7/8]    Loss: 5.946583271026611\n",
      "Epoch[81]    Iter[8/8]    Loss: 5.947753429412842\n",
      "\n",
      "\n",
      "\n",
      "Epoch[82]    Iter[1/8]    Loss: 5.938848972320557\n",
      "Epoch[82]    Iter[2/8]    Loss: 5.93600606918335\n",
      "Epoch[82]    Iter[3/8]    Loss: 5.947197437286377\n",
      "Epoch[82]    Iter[4/8]    Loss: 5.930708885192871\n",
      "Epoch[82]    Iter[5/8]    Loss: 5.936911582946777\n",
      "Epoch[82]    Iter[6/8]    Loss: 5.937649726867676\n",
      "Epoch[82]    Iter[7/8]    Loss: 5.955920696258545\n",
      "Epoch[82]    Iter[8/8]    Loss: 5.93819522857666\n",
      "\n",
      "\n",
      "\n",
      "Epoch[83]    Iter[1/8]    Loss: 5.934630870819092\n",
      "Epoch[83]    Iter[2/8]    Loss: 5.9504170417785645\n",
      "Epoch[83]    Iter[3/8]    Loss: 5.929108142852783\n",
      "Epoch[83]    Iter[4/8]    Loss: 5.9331560134887695\n",
      "Epoch[83]    Iter[5/8]    Loss: 5.942293643951416\n",
      "Epoch[83]    Iter[6/8]    Loss: 5.9456257820129395\n",
      "Epoch[83]    Iter[7/8]    Loss: 5.955196857452393\n",
      "Epoch[83]    Iter[8/8]    Loss: 5.939773082733154\n",
      "\n",
      "\n",
      "\n",
      "Epoch[84]    Iter[1/8]    Loss: 5.943158149719238\n",
      "Epoch[84]    Iter[2/8]    Loss: 5.934629917144775\n",
      "Epoch[84]    Iter[3/8]    Loss: 5.9483489990234375\n",
      "Epoch[84]    Iter[4/8]    Loss: 5.937027454376221\n",
      "Epoch[84]    Iter[5/8]    Loss: 5.930817604064941\n",
      "Epoch[84]    Iter[6/8]    Loss: 5.946336269378662\n",
      "Epoch[84]    Iter[7/8]    Loss: 5.934372425079346\n",
      "Epoch[84]    Iter[8/8]    Loss: 5.949787616729736\n",
      "\n",
      "\n",
      "\n",
      "Epoch[85]    Iter[1/8]    Loss: 5.936079025268555\n",
      "Epoch[85]    Iter[2/8]    Loss: 5.930866241455078\n",
      "Epoch[85]    Iter[3/8]    Loss: 5.944098949432373\n",
      "Epoch[85]    Iter[4/8]    Loss: 5.938636779785156\n",
      "Epoch[85]    Iter[5/8]    Loss: 5.945431232452393\n",
      "Epoch[85]    Iter[6/8]    Loss: 5.949095249176025\n",
      "Epoch[85]    Iter[7/8]    Loss: 5.935794353485107\n",
      "Epoch[85]    Iter[8/8]    Loss: 5.933197975158691\n",
      "\n",
      "\n",
      "\n",
      "Epoch[86]    Iter[1/8]    Loss: 5.941746234893799\n",
      "Epoch[86]    Iter[2/8]    Loss: 5.936821460723877\n",
      "Epoch[86]    Iter[3/8]    Loss: 5.92671537399292\n",
      "Epoch[86]    Iter[4/8]    Loss: 5.940032005310059\n",
      "Epoch[86]    Iter[5/8]    Loss: 5.957242965698242\n",
      "Epoch[86]    Iter[6/8]    Loss: 5.938777923583984\n",
      "Epoch[86]    Iter[7/8]    Loss: 5.940021514892578\n",
      "Epoch[86]    Iter[8/8]    Loss: 5.936723232269287\n",
      "\n",
      "\n",
      "\n",
      "Epoch[87]    Iter[1/8]    Loss: 5.933791160583496\n",
      "Epoch[87]    Iter[2/8]    Loss: 5.950028419494629\n",
      "Epoch[87]    Iter[3/8]    Loss: 5.953855514526367\n",
      "Epoch[87]    Iter[4/8]    Loss: 5.927181243896484\n",
      "Epoch[87]    Iter[5/8]    Loss: 5.933548450469971\n",
      "Epoch[87]    Iter[6/8]    Loss: 5.950140953063965\n",
      "Epoch[87]    Iter[7/8]    Loss: 5.94666051864624\n",
      "Epoch[87]    Iter[8/8]    Loss: 5.937514781951904\n",
      "\n",
      "\n",
      "\n",
      "Epoch[88]    Iter[1/8]    Loss: 5.931893348693848\n",
      "Epoch[88]    Iter[2/8]    Loss: 5.928163051605225\n",
      "Epoch[88]    Iter[3/8]    Loss: 5.9593963623046875\n",
      "Epoch[88]    Iter[4/8]    Loss: 5.921855449676514\n",
      "Epoch[88]    Iter[5/8]    Loss: 5.938939571380615\n",
      "Epoch[88]    Iter[6/8]    Loss: 5.943388938903809\n",
      "Epoch[88]    Iter[7/8]    Loss: 5.954436779022217\n",
      "Epoch[88]    Iter[8/8]    Loss: 5.938999176025391\n",
      "\n",
      "\n",
      "\n",
      "Epoch[89]    Iter[1/8]    Loss: 5.934737682342529\n",
      "Epoch[89]    Iter[2/8]    Loss: 5.94504976272583\n",
      "Epoch[89]    Iter[3/8]    Loss: 5.945794105529785\n",
      "Epoch[89]    Iter[4/8]    Loss: 5.934355735778809\n",
      "Epoch[89]    Iter[5/8]    Loss: 5.9394307136535645\n",
      "Epoch[89]    Iter[6/8]    Loss: 5.927128791809082\n",
      "Epoch[89]    Iter[7/8]    Loss: 5.935145378112793\n",
      "Epoch[89]    Iter[8/8]    Loss: 5.951293468475342\n",
      "\n",
      "\n",
      "\n",
      "Epoch[90]    Iter[1/8]    Loss: 5.942737102508545\n",
      "Epoch[90]    Iter[2/8]    Loss: 5.95413064956665\n",
      "Epoch[90]    Iter[3/8]    Loss: 5.920072555541992\n",
      "Epoch[90]    Iter[4/8]    Loss: 5.922511577606201\n",
      "Epoch[90]    Iter[5/8]    Loss: 5.936590671539307\n",
      "Epoch[90]    Iter[6/8]    Loss: 5.94807243347168\n",
      "Epoch[90]    Iter[7/8]    Loss: 5.937510967254639\n",
      "Epoch[90]    Iter[8/8]    Loss: 5.948302745819092\n",
      "\n",
      "\n",
      "\n",
      "Epoch[91]    Iter[1/8]    Loss: 5.932342529296875\n",
      "Epoch[91]    Iter[2/8]    Loss: 5.938635349273682\n",
      "Epoch[91]    Iter[3/8]    Loss: 5.944791316986084\n",
      "Epoch[91]    Iter[4/8]    Loss: 5.931584358215332\n",
      "Epoch[91]    Iter[5/8]    Loss: 5.939080715179443\n",
      "Epoch[91]    Iter[6/8]    Loss: 5.940345287322998\n",
      "Epoch[91]    Iter[7/8]    Loss: 5.943453311920166\n",
      "Epoch[91]    Iter[8/8]    Loss: 5.941589832305908\n",
      "\n",
      "\n",
      "\n",
      "Epoch[92]    Iter[1/8]    Loss: 5.943536758422852\n",
      "Epoch[92]    Iter[2/8]    Loss: 5.935763835906982\n",
      "Epoch[92]    Iter[3/8]    Loss: 5.929661750793457\n",
      "Epoch[92]    Iter[4/8]    Loss: 5.946291446685791\n",
      "Epoch[92]    Iter[5/8]    Loss: 5.941184043884277\n",
      "Epoch[92]    Iter[6/8]    Loss: 5.932287693023682\n",
      "Epoch[92]    Iter[7/8]    Loss: 5.944454669952393\n",
      "Epoch[92]    Iter[8/8]    Loss: 5.931814193725586\n",
      "\n",
      "\n",
      "\n",
      "Epoch[93]    Iter[1/8]    Loss: 5.935487270355225\n",
      "Epoch[93]    Iter[2/8]    Loss: 5.938520431518555\n",
      "Epoch[93]    Iter[3/8]    Loss: 5.934529781341553\n",
      "Epoch[93]    Iter[4/8]    Loss: 5.9369893074035645\n",
      "Epoch[93]    Iter[5/8]    Loss: 5.937024116516113\n",
      "Epoch[93]    Iter[6/8]    Loss: 5.948587894439697\n",
      "Epoch[93]    Iter[7/8]    Loss: 5.9461588859558105\n",
      "Epoch[93]    Iter[8/8]    Loss: 5.930668354034424\n",
      "\n",
      "\n",
      "\n",
      "Epoch[94]    Iter[1/8]    Loss: 5.93442964553833\n",
      "Epoch[94]    Iter[2/8]    Loss: 5.947516441345215\n",
      "Epoch[94]    Iter[3/8]    Loss: 5.94251823425293\n",
      "Epoch[94]    Iter[4/8]    Loss: 5.9417500495910645\n",
      "Epoch[94]    Iter[5/8]    Loss: 5.930675983428955\n",
      "Epoch[94]    Iter[6/8]    Loss: 5.920529842376709\n",
      "Epoch[94]    Iter[7/8]    Loss: 5.958914279937744\n",
      "Epoch[94]    Iter[8/8]    Loss: 5.936519622802734\n",
      "\n",
      "\n",
      "\n",
      "Epoch[95]    Iter[1/8]    Loss: 5.935747146606445\n",
      "Epoch[95]    Iter[2/8]    Loss: 5.930271625518799\n",
      "Epoch[95]    Iter[3/8]    Loss: 5.946022033691406\n",
      "Epoch[95]    Iter[4/8]    Loss: 5.944836139678955\n",
      "Epoch[95]    Iter[5/8]    Loss: 5.932458877563477\n",
      "Epoch[95]    Iter[6/8]    Loss: 5.918457508087158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[95]    Iter[7/8]    Loss: 5.944281101226807\n",
      "Epoch[95]    Iter[8/8]    Loss: 5.9484100341796875\n",
      "\n",
      "\n",
      "\n",
      "Epoch[96]    Iter[1/8]    Loss: 5.93004035949707\n",
      "Epoch[96]    Iter[2/8]    Loss: 5.939234733581543\n",
      "Epoch[96]    Iter[3/8]    Loss: 5.930286884307861\n",
      "Epoch[96]    Iter[4/8]    Loss: 5.920368671417236\n",
      "Epoch[96]    Iter[5/8]    Loss: 5.93794059753418\n",
      "Epoch[96]    Iter[6/8]    Loss: 5.94660758972168\n",
      "Epoch[96]    Iter[7/8]    Loss: 5.953853130340576\n",
      "Epoch[96]    Iter[8/8]    Loss: 5.941853046417236\n",
      "\n",
      "\n",
      "\n",
      "Epoch[97]    Iter[1/8]    Loss: 5.941629886627197\n",
      "Epoch[97]    Iter[2/8]    Loss: 5.935377597808838\n",
      "Epoch[97]    Iter[3/8]    Loss: 5.938872337341309\n",
      "Epoch[97]    Iter[4/8]    Loss: 5.924653053283691\n",
      "Epoch[97]    Iter[5/8]    Loss: 5.9346699714660645\n",
      "Epoch[97]    Iter[6/8]    Loss: 5.944981575012207\n",
      "Epoch[97]    Iter[7/8]    Loss: 5.94415807723999\n",
      "Epoch[97]    Iter[8/8]    Loss: 5.9510273933410645\n",
      "\n",
      "\n",
      "\n",
      "Epoch[98]    Iter[1/8]    Loss: 5.945673942565918\n",
      "Epoch[98]    Iter[2/8]    Loss: 5.92628812789917\n",
      "Epoch[98]    Iter[3/8]    Loss: 5.93703556060791\n",
      "Epoch[98]    Iter[4/8]    Loss: 5.9242472648620605\n",
      "Epoch[98]    Iter[5/8]    Loss: 5.935118675231934\n",
      "Epoch[98]    Iter[6/8]    Loss: 5.929986000061035\n",
      "Epoch[98]    Iter[7/8]    Loss: 5.939629077911377\n",
      "Epoch[98]    Iter[8/8]    Loss: 5.93510627746582\n",
      "\n",
      "\n",
      "\n",
      "Epoch[99]    Iter[1/8]    Loss: 5.929852485656738\n",
      "Epoch[99]    Iter[2/8]    Loss: 5.9450459480285645\n",
      "Epoch[99]    Iter[3/8]    Loss: 5.927555561065674\n",
      "Epoch[99]    Iter[4/8]    Loss: 5.942603588104248\n",
      "Epoch[99]    Iter[5/8]    Loss: 5.939948558807373\n",
      "Epoch[99]    Iter[6/8]    Loss: 5.951407432556152\n",
      "Epoch[99]    Iter[7/8]    Loss: 5.946998119354248\n",
      "Epoch[99]    Iter[8/8]    Loss: 5.927403450012207\n",
      "\n",
      "\n",
      "\n",
      "Epoch[100]    Iter[1/8]    Loss: 5.937657833099365\n",
      "Epoch[100]    Iter[2/8]    Loss: 5.90841817855835\n",
      "Epoch[100]    Iter[3/8]    Loss: 5.929235458374023\n",
      "Epoch[100]    Iter[4/8]    Loss: 5.936906814575195\n",
      "Epoch[100]    Iter[5/8]    Loss: 5.942169189453125\n",
      "Epoch[100]    Iter[6/8]    Loss: 5.935736179351807\n",
      "Epoch[100]    Iter[7/8]    Loss: 5.942075252532959\n",
      "Epoch[100]    Iter[8/8]    Loss: 5.961264133453369\n",
      "\n",
      "\n",
      "\n",
      "Epoch[101]    Iter[1/8]    Loss: 5.928603172302246\n",
      "Epoch[101]    Iter[2/8]    Loss: 5.947495937347412\n",
      "Epoch[101]    Iter[3/8]    Loss: 5.932497978210449\n",
      "Epoch[101]    Iter[4/8]    Loss: 5.9427385330200195\n",
      "Epoch[101]    Iter[5/8]    Loss: 5.922101974487305\n",
      "Epoch[101]    Iter[6/8]    Loss: 5.93147087097168\n",
      "Epoch[101]    Iter[7/8]    Loss: 5.946336269378662\n",
      "Epoch[101]    Iter[8/8]    Loss: 5.934669017791748\n",
      "\n",
      "\n",
      "\n",
      "Epoch[102]    Iter[1/8]    Loss: 5.93164587020874\n",
      "Epoch[102]    Iter[2/8]    Loss: 5.937997817993164\n",
      "Epoch[102]    Iter[3/8]    Loss: 5.929061412811279\n",
      "Epoch[102]    Iter[4/8]    Loss: 5.928588390350342\n",
      "Epoch[102]    Iter[5/8]    Loss: 5.9444050788879395\n",
      "Epoch[102]    Iter[6/8]    Loss: 5.945276737213135\n",
      "Epoch[102]    Iter[7/8]    Loss: 5.946458339691162\n",
      "Epoch[102]    Iter[8/8]    Loss: 5.924866676330566\n",
      "\n",
      "\n",
      "\n",
      "Epoch[103]    Iter[1/8]    Loss: 5.942102432250977\n",
      "Epoch[103]    Iter[2/8]    Loss: 5.930039882659912\n",
      "Epoch[103]    Iter[3/8]    Loss: 5.929360389709473\n",
      "Epoch[103]    Iter[4/8]    Loss: 5.928420543670654\n",
      "Epoch[103]    Iter[5/8]    Loss: 5.938256740570068\n",
      "Epoch[103]    Iter[6/8]    Loss: 5.93501091003418\n",
      "Epoch[103]    Iter[7/8]    Loss: 5.942069053649902\n",
      "Epoch[103]    Iter[8/8]    Loss: 5.9276275634765625\n",
      "\n",
      "\n",
      "\n",
      "Epoch[104]    Iter[1/8]    Loss: 5.939916133880615\n",
      "Epoch[104]    Iter[2/8]    Loss: 5.946836948394775\n",
      "Epoch[104]    Iter[3/8]    Loss: 5.925681114196777\n",
      "Epoch[104]    Iter[4/8]    Loss: 5.938547611236572\n",
      "Epoch[104]    Iter[5/8]    Loss: 5.9368133544921875\n",
      "Epoch[104]    Iter[6/8]    Loss: 5.939401626586914\n",
      "Epoch[104]    Iter[7/8]    Loss: 5.9400634765625\n",
      "Epoch[104]    Iter[8/8]    Loss: 5.936568737030029\n",
      "\n",
      "\n",
      "\n",
      "Epoch[105]    Iter[1/8]    Loss: 5.939945220947266\n",
      "Epoch[105]    Iter[2/8]    Loss: 5.912954807281494\n",
      "Epoch[105]    Iter[3/8]    Loss: 5.925946235656738\n",
      "Epoch[105]    Iter[4/8]    Loss: 5.94015645980835\n",
      "Epoch[105]    Iter[5/8]    Loss: 5.926220893859863\n",
      "Epoch[105]    Iter[6/8]    Loss: 5.935255527496338\n",
      "Epoch[105]    Iter[7/8]    Loss: 5.954689025878906\n",
      "Epoch[105]    Iter[8/8]    Loss: 5.926904678344727\n",
      "\n",
      "\n",
      "\n",
      "Epoch[106]    Iter[1/8]    Loss: 5.925976276397705\n",
      "Epoch[106]    Iter[2/8]    Loss: 5.921441078186035\n",
      "Epoch[106]    Iter[3/8]    Loss: 5.952022552490234\n",
      "Epoch[106]    Iter[4/8]    Loss: 5.946824550628662\n",
      "Epoch[106]    Iter[5/8]    Loss: 5.931090354919434\n",
      "Epoch[106]    Iter[6/8]    Loss: 5.937055587768555\n",
      "Epoch[106]    Iter[7/8]    Loss: 5.946837425231934\n",
      "Epoch[106]    Iter[8/8]    Loss: 5.9363322257995605\n",
      "\n",
      "\n",
      "\n",
      "Epoch[107]    Iter[1/8]    Loss: 5.91985559463501\n",
      "Epoch[107]    Iter[2/8]    Loss: 5.93157958984375\n",
      "Epoch[107]    Iter[3/8]    Loss: 5.926460266113281\n",
      "Epoch[107]    Iter[4/8]    Loss: 5.927289962768555\n",
      "Epoch[107]    Iter[5/8]    Loss: 5.931755065917969\n",
      "Epoch[107]    Iter[6/8]    Loss: 5.955968379974365\n",
      "Epoch[107]    Iter[7/8]    Loss: 5.9327921867370605\n",
      "Epoch[107]    Iter[8/8]    Loss: 5.9392194747924805\n",
      "\n",
      "\n",
      "\n",
      "Epoch[108]    Iter[1/8]    Loss: 5.936056613922119\n",
      "Epoch[108]    Iter[2/8]    Loss: 5.94121789932251\n",
      "Epoch[108]    Iter[3/8]    Loss: 5.948043346405029\n",
      "Epoch[108]    Iter[4/8]    Loss: 5.9368367195129395\n",
      "Epoch[108]    Iter[5/8]    Loss: 5.926952838897705\n",
      "Epoch[108]    Iter[6/8]    Loss: 5.914801120758057\n",
      "Epoch[108]    Iter[7/8]    Loss: 5.929165363311768\n",
      "Epoch[108]    Iter[8/8]    Loss: 5.941854476928711\n",
      "\n",
      "\n",
      "\n",
      "Epoch[109]    Iter[1/8]    Loss: 5.935672760009766\n",
      "Epoch[109]    Iter[2/8]    Loss: 5.941543102264404\n",
      "Epoch[109]    Iter[3/8]    Loss: 5.954080104827881\n",
      "Epoch[109]    Iter[4/8]    Loss: 5.934105396270752\n",
      "Epoch[109]    Iter[5/8]    Loss: 5.918225288391113\n",
      "Epoch[109]    Iter[6/8]    Loss: 5.9217071533203125\n",
      "Epoch[109]    Iter[7/8]    Loss: 5.935247421264648\n",
      "Epoch[109]    Iter[8/8]    Loss: 5.93733024597168\n",
      "\n",
      "\n",
      "\n",
      "Epoch[110]    Iter[1/8]    Loss: 5.947062015533447\n",
      "Epoch[110]    Iter[2/8]    Loss: 5.942862510681152\n",
      "Epoch[110]    Iter[3/8]    Loss: 5.924668312072754\n",
      "Epoch[110]    Iter[4/8]    Loss: 5.913729667663574\n",
      "Epoch[110]    Iter[5/8]    Loss: 5.926207542419434\n",
      "Epoch[110]    Iter[6/8]    Loss: 5.93438720703125\n",
      "Epoch[110]    Iter[7/8]    Loss: 5.937613010406494\n",
      "Epoch[110]    Iter[8/8]    Loss: 5.923398017883301\n",
      "\n",
      "\n",
      "\n",
      "Epoch[111]    Iter[1/8]    Loss: 5.93247127532959\n",
      "Epoch[111]    Iter[2/8]    Loss: 5.9364333152771\n",
      "Epoch[111]    Iter[3/8]    Loss: 5.935213565826416\n",
      "Epoch[111]    Iter[4/8]    Loss: 5.935785293579102\n",
      "Epoch[111]    Iter[5/8]    Loss: 5.934915542602539\n",
      "Epoch[111]    Iter[6/8]    Loss: 5.940783500671387\n",
      "Epoch[111]    Iter[7/8]    Loss: 5.9218645095825195\n",
      "Epoch[111]    Iter[8/8]    Loss: 5.9411091804504395\n",
      "\n",
      "\n",
      "\n",
      "Epoch[112]    Iter[1/8]    Loss: 5.931217193603516\n",
      "Epoch[112]    Iter[2/8]    Loss: 5.935336112976074\n",
      "Epoch[112]    Iter[3/8]    Loss: 5.9389519691467285\n",
      "Epoch[112]    Iter[4/8]    Loss: 5.942730903625488\n",
      "Epoch[112]    Iter[5/8]    Loss: 5.934591770172119\n",
      "Epoch[112]    Iter[6/8]    Loss: 5.920724868774414\n",
      "Epoch[112]    Iter[7/8]    Loss: 5.9233503341674805\n",
      "Epoch[112]    Iter[8/8]    Loss: 5.940871238708496\n",
      "\n",
      "\n",
      "\n",
      "Epoch[113]    Iter[1/8]    Loss: 5.9099321365356445\n",
      "Epoch[113]    Iter[2/8]    Loss: 5.9376044273376465\n",
      "Epoch[113]    Iter[3/8]    Loss: 5.936402797698975\n",
      "Epoch[113]    Iter[4/8]    Loss: 5.9404072761535645\n",
      "Epoch[113]    Iter[5/8]    Loss: 5.937018394470215\n",
      "Epoch[113]    Iter[6/8]    Loss: 5.916089057922363\n",
      "Epoch[113]    Iter[7/8]    Loss: 5.944839954376221\n",
      "Epoch[113]    Iter[8/8]    Loss: 5.935701370239258\n",
      "\n",
      "\n",
      "\n",
      "Epoch[114]    Iter[1/8]    Loss: 5.918991565704346\n",
      "Epoch[114]    Iter[2/8]    Loss: 5.9487624168396\n",
      "Epoch[114]    Iter[3/8]    Loss: 5.9338226318359375\n",
      "Epoch[114]    Iter[4/8]    Loss: 5.935245990753174\n",
      "Epoch[114]    Iter[5/8]    Loss: 5.916213512420654\n",
      "Epoch[114]    Iter[6/8]    Loss: 5.923635482788086\n",
      "Epoch[114]    Iter[7/8]    Loss: 5.931726455688477\n",
      "Epoch[114]    Iter[8/8]    Loss: 5.944645404815674\n",
      "\n",
      "\n",
      "\n",
      "Epoch[115]    Iter[1/8]    Loss: 5.940279483795166\n",
      "Epoch[115]    Iter[2/8]    Loss: 5.925144195556641\n",
      "Epoch[115]    Iter[3/8]    Loss: 5.928163528442383\n",
      "Epoch[115]    Iter[4/8]    Loss: 5.93848180770874\n",
      "Epoch[115]    Iter[5/8]    Loss: 5.946520805358887\n",
      "Epoch[115]    Iter[6/8]    Loss: 5.9261932373046875\n",
      "Epoch[115]    Iter[7/8]    Loss: 5.9229960441589355\n",
      "Epoch[115]    Iter[8/8]    Loss: 5.936963081359863\n",
      "\n",
      "\n",
      "\n",
      "Epoch[116]    Iter[1/8]    Loss: 5.945035934448242\n",
      "Epoch[116]    Iter[2/8]    Loss: 5.934506893157959\n",
      "Epoch[116]    Iter[3/8]    Loss: 5.92722749710083\n",
      "Epoch[116]    Iter[4/8]    Loss: 5.927053451538086\n",
      "Epoch[116]    Iter[5/8]    Loss: 5.935179710388184\n",
      "Epoch[116]    Iter[6/8]    Loss: 5.921205520629883\n",
      "Epoch[116]    Iter[7/8]    Loss: 5.93062686920166\n",
      "Epoch[116]    Iter[8/8]    Loss: 5.92116117477417\n",
      "\n",
      "\n",
      "\n",
      "Epoch[117]    Iter[1/8]    Loss: 5.938253879547119\n",
      "Epoch[117]    Iter[2/8]    Loss: 5.938579559326172\n",
      "Epoch[117]    Iter[3/8]    Loss: 5.931525230407715\n",
      "Epoch[117]    Iter[4/8]    Loss: 5.926840782165527\n",
      "Epoch[117]    Iter[5/8]    Loss: 5.9344987869262695\n",
      "Epoch[117]    Iter[6/8]    Loss: 5.933969497680664\n",
      "Epoch[117]    Iter[7/8]    Loss: 5.944137096405029\n",
      "Epoch[117]    Iter[8/8]    Loss: 5.92597770690918\n",
      "\n",
      "\n",
      "\n",
      "Epoch[118]    Iter[1/8]    Loss: 5.922658920288086\n",
      "Epoch[118]    Iter[2/8]    Loss: 5.928933620452881\n",
      "Epoch[118]    Iter[3/8]    Loss: 5.94167947769165\n",
      "Epoch[118]    Iter[4/8]    Loss: 5.9313435554504395\n",
      "Epoch[118]    Iter[5/8]    Loss: 5.934564113616943\n",
      "Epoch[118]    Iter[6/8]    Loss: 5.917048454284668\n",
      "Epoch[118]    Iter[7/8]    Loss: 5.926940441131592\n",
      "Epoch[118]    Iter[8/8]    Loss: 5.936319351196289\n",
      "\n",
      "\n",
      "\n",
      "Epoch[119]    Iter[1/8]    Loss: 5.933266639709473\n",
      "Epoch[119]    Iter[2/8]    Loss: 5.92750358581543\n",
      "Epoch[119]    Iter[3/8]    Loss: 5.937196731567383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[119]    Iter[4/8]    Loss: 5.925244331359863\n",
      "Epoch[119]    Iter[5/8]    Loss: 5.932672500610352\n",
      "Epoch[119]    Iter[6/8]    Loss: 5.9364333152771\n",
      "Epoch[119]    Iter[7/8]    Loss: 5.921945571899414\n",
      "Epoch[119]    Iter[8/8]    Loss: 5.924441337585449\n",
      "\n",
      "\n",
      "\n",
      "Epoch[120]    Iter[1/8]    Loss: 5.94089937210083\n",
      "Epoch[120]    Iter[2/8]    Loss: 5.938778400421143\n",
      "Epoch[120]    Iter[3/8]    Loss: 5.931064605712891\n",
      "Epoch[120]    Iter[4/8]    Loss: 5.930751323699951\n",
      "Epoch[120]    Iter[5/8]    Loss: 5.9207048416137695\n",
      "Epoch[120]    Iter[6/8]    Loss: 5.933658123016357\n",
      "Epoch[120]    Iter[7/8]    Loss: 5.924910068511963\n",
      "Epoch[120]    Iter[8/8]    Loss: 5.923132419586182\n",
      "\n",
      "\n",
      "\n",
      "Epoch[121]    Iter[1/8]    Loss: 5.928915977478027\n",
      "Epoch[121]    Iter[2/8]    Loss: 5.943060398101807\n",
      "Epoch[121]    Iter[3/8]    Loss: 5.9266791343688965\n",
      "Epoch[121]    Iter[4/8]    Loss: 5.934845924377441\n",
      "Epoch[121]    Iter[5/8]    Loss: 5.931097030639648\n",
      "Epoch[121]    Iter[6/8]    Loss: 5.924646377563477\n",
      "Epoch[121]    Iter[7/8]    Loss: 5.931211948394775\n",
      "Epoch[121]    Iter[8/8]    Loss: 5.924091815948486\n",
      "\n",
      "\n",
      "\n",
      "Epoch[122]    Iter[1/8]    Loss: 5.940333366394043\n",
      "Epoch[122]    Iter[2/8]    Loss: 5.922381401062012\n",
      "Epoch[122]    Iter[3/8]    Loss: 5.929194450378418\n",
      "Epoch[122]    Iter[4/8]    Loss: 5.909542083740234\n",
      "Epoch[122]    Iter[5/8]    Loss: 5.9294281005859375\n",
      "Epoch[122]    Iter[6/8]    Loss: 5.926225662231445\n",
      "Epoch[122]    Iter[7/8]    Loss: 5.938398361206055\n",
      "Epoch[122]    Iter[8/8]    Loss: 5.951040267944336\n",
      "\n",
      "\n",
      "\n",
      "Epoch[123]    Iter[1/8]    Loss: 5.922693252563477\n",
      "Epoch[123]    Iter[2/8]    Loss: 5.932138919830322\n",
      "Epoch[123]    Iter[3/8]    Loss: 5.935422420501709\n",
      "Epoch[123]    Iter[4/8]    Loss: 5.920330047607422\n",
      "Epoch[123]    Iter[5/8]    Loss: 5.932931423187256\n",
      "Epoch[123]    Iter[6/8]    Loss: 5.928992748260498\n",
      "Epoch[123]    Iter[7/8]    Loss: 5.931690216064453\n",
      "Epoch[123]    Iter[8/8]    Loss: 5.9363203048706055\n",
      "\n",
      "\n",
      "\n",
      "Epoch[124]    Iter[1/8]    Loss: 5.924117088317871\n",
      "Epoch[124]    Iter[2/8]    Loss: 5.932832717895508\n",
      "Epoch[124]    Iter[3/8]    Loss: 5.926353931427002\n",
      "Epoch[124]    Iter[4/8]    Loss: 5.916171550750732\n",
      "Epoch[124]    Iter[5/8]    Loss: 5.9413886070251465\n",
      "Epoch[124]    Iter[6/8]    Loss: 5.934379577636719\n",
      "Epoch[124]    Iter[7/8]    Loss: 5.915558815002441\n",
      "Epoch[124]    Iter[8/8]    Loss: 5.927189350128174\n",
      "\n",
      "\n",
      "\n",
      "Epoch[125]    Iter[1/8]    Loss: 5.926131725311279\n",
      "Epoch[125]    Iter[2/8]    Loss: 5.942709922790527\n",
      "Epoch[125]    Iter[3/8]    Loss: 5.943392753601074\n",
      "Epoch[125]    Iter[4/8]    Loss: 5.916998863220215\n",
      "Epoch[125]    Iter[5/8]    Loss: 5.930324554443359\n",
      "Epoch[125]    Iter[6/8]    Loss: 5.915742874145508\n",
      "Epoch[125]    Iter[7/8]    Loss: 5.941217422485352\n",
      "Epoch[125]    Iter[8/8]    Loss: 5.9093017578125\n",
      "\n",
      "\n",
      "\n",
      "Epoch[126]    Iter[1/8]    Loss: 5.924373149871826\n",
      "Epoch[126]    Iter[2/8]    Loss: 5.937344074249268\n",
      "Epoch[126]    Iter[3/8]    Loss: 5.921798229217529\n",
      "Epoch[126]    Iter[4/8]    Loss: 5.913198471069336\n",
      "Epoch[126]    Iter[5/8]    Loss: 5.9462432861328125\n",
      "Epoch[126]    Iter[6/8]    Loss: 5.949156284332275\n",
      "Epoch[126]    Iter[7/8]    Loss: 5.9290337562561035\n",
      "Epoch[126]    Iter[8/8]    Loss: 5.925973415374756\n",
      "\n",
      "\n",
      "\n",
      "Epoch[127]    Iter[1/8]    Loss: 5.918015003204346\n",
      "Epoch[127]    Iter[2/8]    Loss: 5.929769039154053\n",
      "Epoch[127]    Iter[3/8]    Loss: 5.929256916046143\n",
      "Epoch[127]    Iter[4/8]    Loss: 5.925745964050293\n",
      "Epoch[127]    Iter[5/8]    Loss: 5.921327114105225\n",
      "Epoch[127]    Iter[6/8]    Loss: 5.924936294555664\n",
      "Epoch[127]    Iter[7/8]    Loss: 5.936376571655273\n",
      "Epoch[127]    Iter[8/8]    Loss: 5.920262813568115\n",
      "\n",
      "\n",
      "\n",
      "Epoch[128]    Iter[1/8]    Loss: 5.933716773986816\n",
      "Epoch[128]    Iter[2/8]    Loss: 5.933139801025391\n",
      "Epoch[128]    Iter[3/8]    Loss: 5.929169178009033\n",
      "Epoch[128]    Iter[4/8]    Loss: 5.935404300689697\n",
      "Epoch[128]    Iter[5/8]    Loss: 5.929633140563965\n",
      "Epoch[128]    Iter[6/8]    Loss: 5.917994022369385\n",
      "Epoch[128]    Iter[7/8]    Loss: 5.934576988220215\n",
      "Epoch[128]    Iter[8/8]    Loss: 5.9093403816223145\n",
      "\n",
      "\n",
      "\n",
      "Epoch[129]    Iter[1/8]    Loss: 5.914002418518066\n",
      "Epoch[129]    Iter[2/8]    Loss: 5.926205158233643\n",
      "Epoch[129]    Iter[3/8]    Loss: 5.931733131408691\n",
      "Epoch[129]    Iter[4/8]    Loss: 5.922914028167725\n",
      "Epoch[129]    Iter[5/8]    Loss: 5.9439849853515625\n",
      "Epoch[129]    Iter[6/8]    Loss: 5.929186820983887\n",
      "Epoch[129]    Iter[7/8]    Loss: 5.946918964385986\n",
      "Epoch[129]    Iter[8/8]    Loss: 5.93013334274292\n",
      "\n",
      "\n",
      "\n",
      "Epoch[130]    Iter[1/8]    Loss: 5.927603721618652\n",
      "Epoch[130]    Iter[2/8]    Loss: 5.92388391494751\n",
      "Epoch[130]    Iter[3/8]    Loss: 5.913745403289795\n",
      "Epoch[130]    Iter[4/8]    Loss: 5.913329124450684\n",
      "Epoch[130]    Iter[5/8]    Loss: 5.928545951843262\n",
      "Epoch[130]    Iter[6/8]    Loss: 5.935460090637207\n",
      "Epoch[130]    Iter[7/8]    Loss: 5.92453670501709\n",
      "Epoch[130]    Iter[8/8]    Loss: 5.948955535888672\n",
      "\n",
      "\n",
      "\n",
      "Epoch[131]    Iter[1/8]    Loss: 5.926555156707764\n",
      "Epoch[131]    Iter[2/8]    Loss: 5.929759979248047\n",
      "Epoch[131]    Iter[3/8]    Loss: 5.923966884613037\n",
      "Epoch[131]    Iter[4/8]    Loss: 5.913661956787109\n",
      "Epoch[131]    Iter[5/8]    Loss: 5.932791709899902\n",
      "Epoch[131]    Iter[6/8]    Loss: 5.9288330078125\n",
      "Epoch[131]    Iter[7/8]    Loss: 5.915838718414307\n",
      "Epoch[131]    Iter[8/8]    Loss: 5.932706356048584\n",
      "\n",
      "\n",
      "\n",
      "Epoch[132]    Iter[1/8]    Loss: 5.922407150268555\n",
      "Epoch[132]    Iter[2/8]    Loss: 5.928018569946289\n",
      "Epoch[132]    Iter[3/8]    Loss: 5.921947479248047\n",
      "Epoch[132]    Iter[4/8]    Loss: 5.92172384262085\n",
      "Epoch[132]    Iter[5/8]    Loss: 5.933011054992676\n",
      "Epoch[132]    Iter[6/8]    Loss: 5.924367427825928\n",
      "Epoch[132]    Iter[7/8]    Loss: 5.9283318519592285\n",
      "Epoch[132]    Iter[8/8]    Loss: 5.924628734588623\n",
      "\n",
      "\n",
      "\n",
      "Epoch[133]    Iter[1/8]    Loss: 5.910054683685303\n",
      "Epoch[133]    Iter[2/8]    Loss: 5.924696445465088\n",
      "Epoch[133]    Iter[3/8]    Loss: 5.933935642242432\n",
      "Epoch[133]    Iter[4/8]    Loss: 5.921870708465576\n",
      "Epoch[133]    Iter[5/8]    Loss: 5.934269905090332\n",
      "Epoch[133]    Iter[6/8]    Loss: 5.922850131988525\n",
      "Epoch[133]    Iter[7/8]    Loss: 5.939646244049072\n",
      "Epoch[133]    Iter[8/8]    Loss: 5.9186177253723145\n",
      "\n",
      "\n",
      "\n",
      "Epoch[134]    Iter[1/8]    Loss: 5.921481609344482\n",
      "Epoch[134]    Iter[2/8]    Loss: 5.933216094970703\n",
      "Epoch[134]    Iter[3/8]    Loss: 5.929598331451416\n",
      "Epoch[134]    Iter[4/8]    Loss: 5.913259983062744\n",
      "Epoch[134]    Iter[5/8]    Loss: 5.946371555328369\n",
      "Epoch[134]    Iter[6/8]    Loss: 5.913599014282227\n",
      "Epoch[134]    Iter[7/8]    Loss: 5.933145523071289\n",
      "Epoch[134]    Iter[8/8]    Loss: 5.912437438964844\n",
      "\n",
      "\n",
      "\n",
      "Epoch[135]    Iter[1/8]    Loss: 5.909268379211426\n",
      "Epoch[135]    Iter[2/8]    Loss: 5.9168524742126465\n",
      "Epoch[135]    Iter[3/8]    Loss: 5.936065673828125\n",
      "Epoch[135]    Iter[4/8]    Loss: 5.926853179931641\n",
      "Epoch[135]    Iter[5/8]    Loss: 5.921453952789307\n",
      "Epoch[135]    Iter[6/8]    Loss: 5.941431522369385\n",
      "Epoch[135]    Iter[7/8]    Loss: 5.937569618225098\n",
      "Epoch[135]    Iter[8/8]    Loss: 5.92025899887085\n",
      "\n",
      "\n",
      "\n",
      "Epoch[136]    Iter[1/8]    Loss: 5.92288064956665\n",
      "Epoch[136]    Iter[2/8]    Loss: 5.929300785064697\n",
      "Epoch[136]    Iter[3/8]    Loss: 5.908905029296875\n",
      "Epoch[136]    Iter[4/8]    Loss: 5.921862602233887\n",
      "Epoch[136]    Iter[5/8]    Loss: 5.925405979156494\n",
      "Epoch[136]    Iter[6/8]    Loss: 5.9224419593811035\n",
      "Epoch[136]    Iter[7/8]    Loss: 5.926288604736328\n",
      "Epoch[136]    Iter[8/8]    Loss: 5.926788806915283\n",
      "\n",
      "\n",
      "\n",
      "Epoch[137]    Iter[1/8]    Loss: 5.943175315856934\n",
      "Epoch[137]    Iter[2/8]    Loss: 5.928888320922852\n",
      "Epoch[137]    Iter[3/8]    Loss: 5.93167781829834\n",
      "Epoch[137]    Iter[4/8]    Loss: 5.9402899742126465\n",
      "Epoch[137]    Iter[5/8]    Loss: 5.913432598114014\n",
      "Epoch[137]    Iter[6/8]    Loss: 5.899340629577637\n",
      "Epoch[137]    Iter[7/8]    Loss: 5.913569450378418\n",
      "Epoch[137]    Iter[8/8]    Loss: 5.917778491973877\n",
      "\n",
      "\n",
      "\n",
      "Epoch[138]    Iter[1/8]    Loss: 5.938632488250732\n",
      "Epoch[138]    Iter[2/8]    Loss: 5.933103561401367\n",
      "Epoch[138]    Iter[3/8]    Loss: 5.926284313201904\n",
      "Epoch[138]    Iter[4/8]    Loss: 5.915873050689697\n",
      "Epoch[138]    Iter[5/8]    Loss: 5.923996448516846\n",
      "Epoch[138]    Iter[6/8]    Loss: 5.944116592407227\n",
      "Epoch[138]    Iter[7/8]    Loss: 5.908561706542969\n",
      "Epoch[138]    Iter[8/8]    Loss: 5.916316509246826\n",
      "\n",
      "\n",
      "\n",
      "Epoch[139]    Iter[1/8]    Loss: 5.930984973907471\n",
      "Epoch[139]    Iter[2/8]    Loss: 5.932750701904297\n",
      "Epoch[139]    Iter[3/8]    Loss: 5.923104286193848\n",
      "Epoch[139]    Iter[4/8]    Loss: 5.9163031578063965\n",
      "Epoch[139]    Iter[5/8]    Loss: 5.924519062042236\n",
      "Epoch[139]    Iter[6/8]    Loss: 5.922449111938477\n",
      "Epoch[139]    Iter[7/8]    Loss: 5.917403697967529\n",
      "Epoch[139]    Iter[8/8]    Loss: 5.90924072265625\n",
      "\n",
      "\n",
      "\n",
      "Epoch[140]    Iter[1/8]    Loss: 5.926864147186279\n",
      "Epoch[140]    Iter[2/8]    Loss: 5.930751800537109\n",
      "Epoch[140]    Iter[3/8]    Loss: 5.942415237426758\n",
      "Epoch[140]    Iter[4/8]    Loss: 5.940836429595947\n",
      "Epoch[140]    Iter[5/8]    Loss: 5.9063544273376465\n",
      "Epoch[140]    Iter[6/8]    Loss: 5.9330267906188965\n",
      "Epoch[140]    Iter[7/8]    Loss: 5.898087501525879\n",
      "Epoch[140]    Iter[8/8]    Loss: 5.915196895599365\n",
      "\n",
      "\n",
      "\n",
      "Epoch[141]    Iter[1/8]    Loss: 5.919112205505371\n",
      "Epoch[141]    Iter[2/8]    Loss: 5.931706428527832\n",
      "Epoch[141]    Iter[3/8]    Loss: 5.917982578277588\n",
      "Epoch[141]    Iter[4/8]    Loss: 5.914308071136475\n",
      "Epoch[141]    Iter[5/8]    Loss: 5.926281929016113\n",
      "Epoch[141]    Iter[6/8]    Loss: 5.939128398895264\n",
      "Epoch[141]    Iter[7/8]    Loss: 5.926534175872803\n",
      "Epoch[141]    Iter[8/8]    Loss: 5.935628414154053\n",
      "\n",
      "\n",
      "\n",
      "Epoch[142]    Iter[1/8]    Loss: 5.920907974243164\n",
      "Epoch[142]    Iter[2/8]    Loss: 5.930524826049805\n",
      "Epoch[142]    Iter[3/8]    Loss: 5.9188408851623535\n",
      "Epoch[142]    Iter[4/8]    Loss: 5.910363674163818\n",
      "Epoch[142]    Iter[5/8]    Loss: 5.930215835571289\n",
      "Epoch[142]    Iter[6/8]    Loss: 5.921699047088623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[142]    Iter[7/8]    Loss: 5.92020845413208\n",
      "Epoch[142]    Iter[8/8]    Loss: 5.918332099914551\n",
      "\n",
      "\n",
      "\n",
      "Epoch[143]    Iter[1/8]    Loss: 5.914766311645508\n",
      "Epoch[143]    Iter[2/8]    Loss: 5.951513290405273\n",
      "Epoch[143]    Iter[3/8]    Loss: 5.922235012054443\n",
      "Epoch[143]    Iter[4/8]    Loss: 5.940061569213867\n",
      "Epoch[143]    Iter[5/8]    Loss: 5.912796497344971\n",
      "Epoch[143]    Iter[6/8]    Loss: 5.923604965209961\n",
      "Epoch[143]    Iter[7/8]    Loss: 5.902493953704834\n",
      "Epoch[143]    Iter[8/8]    Loss: 5.910752296447754\n",
      "\n",
      "\n",
      "\n",
      "Epoch[144]    Iter[1/8]    Loss: 5.935431003570557\n",
      "Epoch[144]    Iter[2/8]    Loss: 5.9403462409973145\n",
      "Epoch[144]    Iter[3/8]    Loss: 5.921947479248047\n",
      "Epoch[144]    Iter[4/8]    Loss: 5.909196853637695\n",
      "Epoch[144]    Iter[5/8]    Loss: 5.934201240539551\n",
      "Epoch[144]    Iter[6/8]    Loss: 5.9053874015808105\n",
      "Epoch[144]    Iter[7/8]    Loss: 5.904537200927734\n",
      "Epoch[144]    Iter[8/8]    Loss: 5.925022125244141\n",
      "\n",
      "\n",
      "\n",
      "Epoch[145]    Iter[1/8]    Loss: 5.939350128173828\n",
      "Epoch[145]    Iter[2/8]    Loss: 5.9071946144104\n",
      "Epoch[145]    Iter[3/8]    Loss: 5.92919397354126\n",
      "Epoch[145]    Iter[4/8]    Loss: 5.92919397354126\n",
      "Epoch[145]    Iter[5/8]    Loss: 5.9330596923828125\n",
      "Epoch[145]    Iter[6/8]    Loss: 5.9110941886901855\n",
      "Epoch[145]    Iter[7/8]    Loss: 5.922118186950684\n",
      "Epoch[145]    Iter[8/8]    Loss: 5.9067463874816895\n",
      "\n",
      "\n",
      "\n",
      "Epoch[146]    Iter[1/8]    Loss: 5.939642906188965\n",
      "Epoch[146]    Iter[2/8]    Loss: 5.9134697914123535\n",
      "Epoch[146]    Iter[3/8]    Loss: 5.918950080871582\n",
      "Epoch[146]    Iter[4/8]    Loss: 5.9209208488464355\n",
      "Epoch[146]    Iter[5/8]    Loss: 5.921955108642578\n",
      "Epoch[146]    Iter[6/8]    Loss: 5.910587310791016\n",
      "Epoch[146]    Iter[7/8]    Loss: 5.925699234008789\n",
      "Epoch[146]    Iter[8/8]    Loss: 5.923118591308594\n",
      "\n",
      "\n",
      "\n",
      "Epoch[147]    Iter[1/8]    Loss: 5.929817199707031\n",
      "Epoch[147]    Iter[2/8]    Loss: 5.909512042999268\n",
      "Epoch[147]    Iter[3/8]    Loss: 5.913339138031006\n",
      "Epoch[147]    Iter[4/8]    Loss: 5.941686153411865\n",
      "Epoch[147]    Iter[5/8]    Loss: 5.921121120452881\n",
      "Epoch[147]    Iter[6/8]    Loss: 5.930394172668457\n",
      "Epoch[147]    Iter[7/8]    Loss: 5.900963306427002\n",
      "Epoch[147]    Iter[8/8]    Loss: 5.919851303100586\n",
      "\n",
      "\n",
      "\n",
      "Epoch[148]    Iter[1/8]    Loss: 5.9347333908081055\n",
      "Epoch[148]    Iter[2/8]    Loss: 5.914159297943115\n",
      "Epoch[148]    Iter[3/8]    Loss: 5.917861461639404\n",
      "Epoch[148]    Iter[4/8]    Loss: 5.9266357421875\n",
      "Epoch[148]    Iter[5/8]    Loss: 5.915064334869385\n",
      "Epoch[148]    Iter[6/8]    Loss: 5.949786186218262\n",
      "Epoch[148]    Iter[7/8]    Loss: 5.900479793548584\n",
      "Epoch[148]    Iter[8/8]    Loss: 5.9073591232299805\n",
      "\n",
      "\n",
      "\n",
      "Epoch[149]    Iter[1/8]    Loss: 5.9253950119018555\n",
      "Epoch[149]    Iter[2/8]    Loss: 5.923908710479736\n",
      "Epoch[149]    Iter[3/8]    Loss: 5.936540126800537\n",
      "Epoch[149]    Iter[4/8]    Loss: 5.919468402862549\n",
      "Epoch[149]    Iter[5/8]    Loss: 5.9174113273620605\n",
      "Epoch[149]    Iter[6/8]    Loss: 5.891439437866211\n",
      "Epoch[149]    Iter[7/8]    Loss: 5.917290687561035\n",
      "Epoch[149]    Iter[8/8]    Loss: 5.923577308654785\n",
      "\n",
      "\n",
      "\n",
      "Epoch[150]    Iter[1/8]    Loss: 5.903923511505127\n",
      "Epoch[150]    Iter[2/8]    Loss: 5.923359394073486\n",
      "Epoch[150]    Iter[3/8]    Loss: 5.9278388023376465\n",
      "Epoch[150]    Iter[4/8]    Loss: 5.912631511688232\n",
      "Epoch[150]    Iter[5/8]    Loss: 5.925818920135498\n",
      "Epoch[150]    Iter[6/8]    Loss: 5.917935848236084\n",
      "Epoch[150]    Iter[7/8]    Loss: 5.925368309020996\n",
      "Epoch[150]    Iter[8/8]    Loss: 5.938875198364258\n",
      "\n",
      "\n",
      "\n",
      "Epoch[151]    Iter[1/8]    Loss: 5.910467624664307\n",
      "Epoch[151]    Iter[2/8]    Loss: 5.920634746551514\n",
      "Epoch[151]    Iter[3/8]    Loss: 5.928511619567871\n",
      "Epoch[151]    Iter[4/8]    Loss: 5.9258623123168945\n",
      "Epoch[151]    Iter[5/8]    Loss: 5.9172844886779785\n",
      "Epoch[151]    Iter[6/8]    Loss: 5.925380229949951\n",
      "Epoch[151]    Iter[7/8]    Loss: 5.9178948402404785\n",
      "Epoch[151]    Iter[8/8]    Loss: 5.904930591583252\n",
      "\n",
      "\n",
      "\n",
      "Epoch[152]    Iter[1/8]    Loss: 5.925963878631592\n",
      "Epoch[152]    Iter[2/8]    Loss: 5.936313152313232\n",
      "Epoch[152]    Iter[3/8]    Loss: 5.917428493499756\n",
      "Epoch[152]    Iter[4/8]    Loss: 5.919492244720459\n",
      "Epoch[152]    Iter[5/8]    Loss: 5.904836654663086\n",
      "Epoch[152]    Iter[6/8]    Loss: 5.930264949798584\n",
      "Epoch[152]    Iter[7/8]    Loss: 5.918456077575684\n",
      "Epoch[152]    Iter[8/8]    Loss: 5.910603046417236\n",
      "\n",
      "\n",
      "\n",
      "Epoch[153]    Iter[1/8]    Loss: 5.910187244415283\n",
      "Epoch[153]    Iter[2/8]    Loss: 5.9153594970703125\n",
      "Epoch[153]    Iter[3/8]    Loss: 5.922237873077393\n",
      "Epoch[153]    Iter[4/8]    Loss: 5.947841644287109\n",
      "Epoch[153]    Iter[5/8]    Loss: 5.911352634429932\n",
      "Epoch[153]    Iter[6/8]    Loss: 5.918678283691406\n",
      "Epoch[153]    Iter[7/8]    Loss: 5.915278434753418\n",
      "Epoch[153]    Iter[8/8]    Loss: 5.9186224937438965\n",
      "\n",
      "\n",
      "\n",
      "Epoch[154]    Iter[1/8]    Loss: 5.941629886627197\n",
      "Epoch[154]    Iter[2/8]    Loss: 5.907223701477051\n",
      "Epoch[154]    Iter[3/8]    Loss: 5.9204182624816895\n",
      "Epoch[154]    Iter[4/8]    Loss: 5.931951999664307\n",
      "Epoch[154]    Iter[5/8]    Loss: 5.930372714996338\n",
      "Epoch[154]    Iter[6/8]    Loss: 5.916597843170166\n",
      "Epoch[154]    Iter[7/8]    Loss: 5.892049789428711\n",
      "Epoch[154]    Iter[8/8]    Loss: 5.896456718444824\n",
      "\n",
      "\n",
      "\n",
      "Epoch[155]    Iter[1/8]    Loss: 5.914058685302734\n",
      "Epoch[155]    Iter[2/8]    Loss: 5.9140801429748535\n",
      "Epoch[155]    Iter[3/8]    Loss: 5.922398567199707\n",
      "Epoch[155]    Iter[4/8]    Loss: 5.933023929595947\n",
      "Epoch[155]    Iter[5/8]    Loss: 5.928398609161377\n",
      "Epoch[155]    Iter[6/8]    Loss: 5.910426616668701\n",
      "Epoch[155]    Iter[7/8]    Loss: 5.910621643066406\n",
      "Epoch[155]    Iter[8/8]    Loss: 5.913511753082275\n",
      "\n",
      "\n",
      "\n",
      "Epoch[156]    Iter[1/8]    Loss: 5.90968656539917\n",
      "Epoch[156]    Iter[2/8]    Loss: 5.920858860015869\n",
      "Epoch[156]    Iter[3/8]    Loss: 5.923719882965088\n",
      "Epoch[156]    Iter[4/8]    Loss: 5.909797191619873\n",
      "Epoch[156]    Iter[5/8]    Loss: 5.919041156768799\n",
      "Epoch[156]    Iter[6/8]    Loss: 5.911780834197998\n",
      "Epoch[156]    Iter[7/8]    Loss: 5.919919013977051\n",
      "Epoch[156]    Iter[8/8]    Loss: 5.937421798706055\n",
      "\n",
      "\n",
      "\n",
      "Epoch[157]    Iter[1/8]    Loss: 5.917252063751221\n",
      "Epoch[157]    Iter[2/8]    Loss: 5.925753593444824\n",
      "Epoch[157]    Iter[3/8]    Loss: 5.929965496063232\n",
      "Epoch[157]    Iter[4/8]    Loss: 5.904257297515869\n",
      "Epoch[157]    Iter[5/8]    Loss: 5.934381008148193\n",
      "Epoch[157]    Iter[6/8]    Loss: 5.905191421508789\n",
      "Epoch[157]    Iter[7/8]    Loss: 5.895925521850586\n",
      "Epoch[157]    Iter[8/8]    Loss: 5.93722677230835\n",
      "\n",
      "\n",
      "\n",
      "Epoch[158]    Iter[1/8]    Loss: 5.9127421379089355\n",
      "Epoch[158]    Iter[2/8]    Loss: 5.924286365509033\n",
      "Epoch[158]    Iter[3/8]    Loss: 5.941275596618652\n",
      "Epoch[158]    Iter[4/8]    Loss: 5.921261787414551\n",
      "Epoch[158]    Iter[5/8]    Loss: 5.912216663360596\n",
      "Epoch[158]    Iter[6/8]    Loss: 5.909609317779541\n",
      "Epoch[158]    Iter[7/8]    Loss: 5.906100749969482\n",
      "Epoch[158]    Iter[8/8]    Loss: 5.915736675262451\n",
      "\n",
      "\n",
      "\n",
      "Epoch[159]    Iter[1/8]    Loss: 5.93607234954834\n",
      "Epoch[159]    Iter[2/8]    Loss: 5.9222331047058105\n",
      "Epoch[159]    Iter[3/8]    Loss: 5.896512985229492\n",
      "Epoch[159]    Iter[4/8]    Loss: 5.904961585998535\n",
      "Epoch[159]    Iter[5/8]    Loss: 5.93339729309082\n",
      "Epoch[159]    Iter[6/8]    Loss: 5.924711227416992\n",
      "Epoch[159]    Iter[7/8]    Loss: 5.940537452697754\n",
      "Epoch[159]    Iter[8/8]    Loss: 5.888187408447266\n",
      "\n",
      "\n",
      "\n",
      "Epoch[160]    Iter[1/8]    Loss: 5.92214822769165\n",
      "Epoch[160]    Iter[2/8]    Loss: 5.905590057373047\n",
      "Epoch[160]    Iter[3/8]    Loss: 5.917717456817627\n",
      "Epoch[160]    Iter[4/8]    Loss: 5.934613227844238\n",
      "Epoch[160]    Iter[5/8]    Loss: 5.910089492797852\n",
      "Epoch[160]    Iter[6/8]    Loss: 5.911364555358887\n",
      "Epoch[160]    Iter[7/8]    Loss: 5.91310977935791\n",
      "Epoch[160]    Iter[8/8]    Loss: 5.911440849304199\n",
      "\n",
      "\n",
      "\n",
      "Epoch[161]    Iter[1/8]    Loss: 5.938925266265869\n",
      "Epoch[161]    Iter[2/8]    Loss: 5.911777496337891\n",
      "Epoch[161]    Iter[3/8]    Loss: 5.916418075561523\n",
      "Epoch[161]    Iter[4/8]    Loss: 5.914551734924316\n",
      "Epoch[161]    Iter[5/8]    Loss: 5.922412395477295\n",
      "Epoch[161]    Iter[6/8]    Loss: 5.9137187004089355\n",
      "Epoch[161]    Iter[7/8]    Loss: 5.922447681427002\n",
      "Epoch[161]    Iter[8/8]    Loss: 5.909420490264893\n",
      "\n",
      "\n",
      "\n",
      "Epoch[162]    Iter[1/8]    Loss: 5.91754674911499\n",
      "Epoch[162]    Iter[2/8]    Loss: 5.924535751342773\n",
      "Epoch[162]    Iter[3/8]    Loss: 5.909770488739014\n",
      "Epoch[162]    Iter[4/8]    Loss: 5.917491436004639\n",
      "Epoch[162]    Iter[5/8]    Loss: 5.9180684089660645\n",
      "Epoch[162]    Iter[6/8]    Loss: 5.9194207191467285\n",
      "Epoch[162]    Iter[7/8]    Loss: 5.901808261871338\n",
      "Epoch[162]    Iter[8/8]    Loss: 5.919699668884277\n",
      "\n",
      "\n",
      "\n",
      "Epoch[163]    Iter[1/8]    Loss: 5.932000160217285\n",
      "Epoch[163]    Iter[2/8]    Loss: 5.916604042053223\n",
      "Epoch[163]    Iter[3/8]    Loss: 5.910431385040283\n",
      "Epoch[163]    Iter[4/8]    Loss: 5.9052605628967285\n",
      "Epoch[163]    Iter[5/8]    Loss: 5.913405418395996\n",
      "Epoch[163]    Iter[6/8]    Loss: 5.895363807678223\n",
      "Epoch[163]    Iter[7/8]    Loss: 5.942149639129639\n",
      "Epoch[163]    Iter[8/8]    Loss: 5.910601615905762\n",
      "\n",
      "\n",
      "\n",
      "Epoch[164]    Iter[1/8]    Loss: 5.9338459968566895\n",
      "Epoch[164]    Iter[2/8]    Loss: 5.905212879180908\n",
      "Epoch[164]    Iter[3/8]    Loss: 5.899766445159912\n",
      "Epoch[164]    Iter[4/8]    Loss: 5.939796447753906\n",
      "Epoch[164]    Iter[5/8]    Loss: 5.9230217933654785\n",
      "Epoch[164]    Iter[6/8]    Loss: 5.902701377868652\n",
      "Epoch[164]    Iter[7/8]    Loss: 5.916531085968018\n",
      "Epoch[164]    Iter[8/8]    Loss: 5.912893295288086\n",
      "\n",
      "\n",
      "\n",
      "Epoch[165]    Iter[1/8]    Loss: 5.8994879722595215\n",
      "Epoch[165]    Iter[2/8]    Loss: 5.911644458770752\n",
      "Epoch[165]    Iter[3/8]    Loss: 5.916243076324463\n",
      "Epoch[165]    Iter[4/8]    Loss: 5.92290735244751\n",
      "Epoch[165]    Iter[5/8]    Loss: 5.9196600914001465\n",
      "Epoch[165]    Iter[6/8]    Loss: 5.927762985229492\n",
      "Epoch[165]    Iter[7/8]    Loss: 5.920939922332764\n",
      "Epoch[165]    Iter[8/8]    Loss: 5.914305210113525\n",
      "\n",
      "\n",
      "\n",
      "Epoch[166]    Iter[1/8]    Loss: 5.893927574157715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[166]    Iter[2/8]    Loss: 5.941244125366211\n",
      "Epoch[166]    Iter[3/8]    Loss: 5.905074596405029\n",
      "Epoch[166]    Iter[4/8]    Loss: 5.906886577606201\n",
      "Epoch[166]    Iter[5/8]    Loss: 5.921187877655029\n",
      "Epoch[166]    Iter[6/8]    Loss: 5.912374973297119\n",
      "Epoch[166]    Iter[7/8]    Loss: 5.939869403839111\n",
      "Epoch[166]    Iter[8/8]    Loss: 5.912555694580078\n",
      "\n",
      "\n",
      "\n",
      "Epoch[167]    Iter[1/8]    Loss: 5.920961856842041\n",
      "Epoch[167]    Iter[2/8]    Loss: 5.90256929397583\n",
      "Epoch[167]    Iter[3/8]    Loss: 5.924848556518555\n",
      "Epoch[167]    Iter[4/8]    Loss: 5.904579162597656\n",
      "Epoch[167]    Iter[5/8]    Loss: 5.919424533843994\n",
      "Epoch[167]    Iter[6/8]    Loss: 5.8960747718811035\n",
      "Epoch[167]    Iter[7/8]    Loss: 5.917626857757568\n",
      "Epoch[167]    Iter[8/8]    Loss: 5.922630786895752\n",
      "\n",
      "\n",
      "\n",
      "Epoch[168]    Iter[1/8]    Loss: 5.895447731018066\n",
      "Epoch[168]    Iter[2/8]    Loss: 5.931437015533447\n",
      "Epoch[168]    Iter[3/8]    Loss: 5.930219650268555\n",
      "Epoch[168]    Iter[4/8]    Loss: 5.9327497482299805\n",
      "Epoch[168]    Iter[5/8]    Loss: 5.899964332580566\n",
      "Epoch[168]    Iter[6/8]    Loss: 5.913357734680176\n",
      "Epoch[168]    Iter[7/8]    Loss: 5.900019645690918\n",
      "Epoch[168]    Iter[8/8]    Loss: 5.926298141479492\n",
      "\n",
      "\n",
      "\n",
      "Epoch[169]    Iter[1/8]    Loss: 5.919338703155518\n",
      "Epoch[169]    Iter[2/8]    Loss: 5.918568134307861\n",
      "Epoch[169]    Iter[3/8]    Loss: 5.9115214347839355\n",
      "Epoch[169]    Iter[4/8]    Loss: 5.919912815093994\n",
      "Epoch[169]    Iter[5/8]    Loss: 5.92413854598999\n",
      "Epoch[169]    Iter[6/8]    Loss: 5.907272815704346\n",
      "Epoch[169]    Iter[7/8]    Loss: 5.915303707122803\n",
      "Epoch[169]    Iter[8/8]    Loss: 5.923975944519043\n",
      "\n",
      "\n",
      "\n",
      "Epoch[170]    Iter[1/8]    Loss: 5.9219746589660645\n",
      "Epoch[170]    Iter[2/8]    Loss: 5.9142069816589355\n",
      "Epoch[170]    Iter[3/8]    Loss: 5.908563613891602\n",
      "Epoch[170]    Iter[4/8]    Loss: 5.915952205657959\n",
      "Epoch[170]    Iter[5/8]    Loss: 5.929598808288574\n",
      "Epoch[170]    Iter[6/8]    Loss: 5.918492317199707\n",
      "Epoch[170]    Iter[7/8]    Loss: 5.904224395751953\n",
      "Epoch[170]    Iter[8/8]    Loss: 5.90485954284668\n",
      "\n",
      "\n",
      "\n",
      "Epoch[171]    Iter[1/8]    Loss: 5.908679008483887\n",
      "Epoch[171]    Iter[2/8]    Loss: 5.918272018432617\n",
      "Epoch[171]    Iter[3/8]    Loss: 5.914206504821777\n",
      "Epoch[171]    Iter[4/8]    Loss: 5.930641174316406\n",
      "Epoch[171]    Iter[5/8]    Loss: 5.917905807495117\n",
      "Epoch[171]    Iter[6/8]    Loss: 5.926527976989746\n",
      "Epoch[171]    Iter[7/8]    Loss: 5.898496150970459\n",
      "Epoch[171]    Iter[8/8]    Loss: 5.911661624908447\n",
      "\n",
      "\n",
      "\n",
      "Epoch[172]    Iter[1/8]    Loss: 5.905689239501953\n",
      "Epoch[172]    Iter[2/8]    Loss: 5.923105716705322\n",
      "Epoch[172]    Iter[3/8]    Loss: 5.911162853240967\n",
      "Epoch[172]    Iter[4/8]    Loss: 5.911230564117432\n",
      "Epoch[172]    Iter[5/8]    Loss: 5.902219772338867\n",
      "Epoch[172]    Iter[6/8]    Loss: 5.922463893890381\n",
      "Epoch[172]    Iter[7/8]    Loss: 5.917918682098389\n",
      "Epoch[172]    Iter[8/8]    Loss: 5.912510395050049\n",
      "\n",
      "\n",
      "\n",
      "Epoch[173]    Iter[1/8]    Loss: 5.9167962074279785\n",
      "Epoch[173]    Iter[2/8]    Loss: 5.94861364364624\n",
      "Epoch[173]    Iter[3/8]    Loss: 5.919035911560059\n",
      "Epoch[173]    Iter[4/8]    Loss: 5.916367053985596\n",
      "Epoch[173]    Iter[5/8]    Loss: 5.920910358428955\n",
      "Epoch[173]    Iter[6/8]    Loss: 5.897067070007324\n",
      "Epoch[173]    Iter[7/8]    Loss: 5.9005560874938965\n",
      "Epoch[173]    Iter[8/8]    Loss: 5.9100565910339355\n",
      "\n",
      "\n",
      "\n",
      "Epoch[174]    Iter[1/8]    Loss: 5.897204875946045\n",
      "Epoch[174]    Iter[2/8]    Loss: 5.923926830291748\n",
      "Epoch[174]    Iter[3/8]    Loss: 5.907893180847168\n",
      "Epoch[174]    Iter[4/8]    Loss: 5.921228885650635\n",
      "Epoch[174]    Iter[5/8]    Loss: 5.9008870124816895\n",
      "Epoch[174]    Iter[6/8]    Loss: 5.933361530303955\n",
      "Epoch[174]    Iter[7/8]    Loss: 5.921359539031982\n",
      "Epoch[174]    Iter[8/8]    Loss: 5.910948753356934\n",
      "\n",
      "\n",
      "\n",
      "Epoch[175]    Iter[1/8]    Loss: 5.895264625549316\n",
      "Epoch[175]    Iter[2/8]    Loss: 5.9305644035339355\n",
      "Epoch[175]    Iter[3/8]    Loss: 5.911905765533447\n",
      "Epoch[175]    Iter[4/8]    Loss: 5.917521953582764\n",
      "Epoch[175]    Iter[5/8]    Loss: 5.914761543273926\n",
      "Epoch[175]    Iter[6/8]    Loss: 5.916201114654541\n",
      "Epoch[175]    Iter[7/8]    Loss: 5.894585609436035\n",
      "Epoch[175]    Iter[8/8]    Loss: 5.9268574714660645\n",
      "\n",
      "\n",
      "\n",
      "Epoch[176]    Iter[1/8]    Loss: 5.921064853668213\n",
      "Epoch[176]    Iter[2/8]    Loss: 5.906327247619629\n",
      "Epoch[176]    Iter[3/8]    Loss: 5.937972545623779\n",
      "Epoch[176]    Iter[4/8]    Loss: 5.901802062988281\n",
      "Epoch[176]    Iter[5/8]    Loss: 5.910490036010742\n",
      "Epoch[176]    Iter[6/8]    Loss: 5.920213222503662\n",
      "Epoch[176]    Iter[7/8]    Loss: 5.903470516204834\n",
      "Epoch[176]    Iter[8/8]    Loss: 5.917325496673584\n",
      "\n",
      "\n",
      "\n",
      "Epoch[177]    Iter[1/8]    Loss: 5.9119062423706055\n",
      "Epoch[177]    Iter[2/8]    Loss: 5.924155235290527\n",
      "Epoch[177]    Iter[3/8]    Loss: 5.919877052307129\n",
      "Epoch[177]    Iter[4/8]    Loss: 5.901503562927246\n",
      "Epoch[177]    Iter[5/8]    Loss: 5.923895359039307\n",
      "Epoch[177]    Iter[6/8]    Loss: 5.916720867156982\n",
      "Epoch[177]    Iter[7/8]    Loss: 5.915276527404785\n",
      "Epoch[177]    Iter[8/8]    Loss: 5.913466930389404\n",
      "\n",
      "\n",
      "\n",
      "Epoch[178]    Iter[1/8]    Loss: 5.8849568367004395\n",
      "Epoch[178]    Iter[2/8]    Loss: 5.902890205383301\n",
      "Epoch[178]    Iter[3/8]    Loss: 5.906294345855713\n",
      "Epoch[178]    Iter[4/8]    Loss: 5.905860424041748\n",
      "Epoch[178]    Iter[5/8]    Loss: 5.92954683303833\n",
      "Epoch[178]    Iter[6/8]    Loss: 5.922478675842285\n",
      "Epoch[178]    Iter[7/8]    Loss: 5.943571090698242\n",
      "Epoch[178]    Iter[8/8]    Loss: 5.909598350524902\n",
      "\n",
      "\n",
      "\n",
      "Epoch[179]    Iter[1/8]    Loss: 5.923379898071289\n",
      "Epoch[179]    Iter[2/8]    Loss: 5.917313575744629\n",
      "Epoch[179]    Iter[3/8]    Loss: 5.919335842132568\n",
      "Epoch[179]    Iter[4/8]    Loss: 5.928570747375488\n",
      "Epoch[179]    Iter[5/8]    Loss: 5.890131950378418\n",
      "Epoch[179]    Iter[6/8]    Loss: 5.906913757324219\n",
      "Epoch[179]    Iter[7/8]    Loss: 5.919068813323975\n",
      "Epoch[179]    Iter[8/8]    Loss: 5.897019386291504\n",
      "\n",
      "\n",
      "\n",
      "Epoch[180]    Iter[1/8]    Loss: 5.902585029602051\n",
      "Epoch[180]    Iter[2/8]    Loss: 5.915005683898926\n",
      "Epoch[180]    Iter[3/8]    Loss: 5.922292232513428\n",
      "Epoch[180]    Iter[4/8]    Loss: 5.906451225280762\n",
      "Epoch[180]    Iter[5/8]    Loss: 5.903219699859619\n",
      "Epoch[180]    Iter[6/8]    Loss: 5.917604923248291\n",
      "Epoch[180]    Iter[7/8]    Loss: 5.925503730773926\n",
      "Epoch[180]    Iter[8/8]    Loss: 5.920363903045654\n",
      "\n",
      "\n",
      "\n",
      "Epoch[181]    Iter[1/8]    Loss: 5.9152302742004395\n",
      "Epoch[181]    Iter[2/8]    Loss: 5.910634994506836\n",
      "Epoch[181]    Iter[3/8]    Loss: 5.9212236404418945\n",
      "Epoch[181]    Iter[4/8]    Loss: 5.915168285369873\n",
      "Epoch[181]    Iter[5/8]    Loss: 5.909974575042725\n",
      "Epoch[181]    Iter[6/8]    Loss: 5.934560775756836\n",
      "Epoch[181]    Iter[7/8]    Loss: 5.8958740234375\n",
      "Epoch[181]    Iter[8/8]    Loss: 5.917080402374268\n",
      "\n",
      "\n",
      "\n",
      "Epoch[182]    Iter[1/8]    Loss: 5.912066459655762\n",
      "Epoch[182]    Iter[2/8]    Loss: 5.9108052253723145\n",
      "Epoch[182]    Iter[3/8]    Loss: 5.901959419250488\n",
      "Epoch[182]    Iter[4/8]    Loss: 5.929504871368408\n",
      "Epoch[182]    Iter[5/8]    Loss: 5.917759418487549\n",
      "Epoch[182]    Iter[6/8]    Loss: 5.8992600440979\n",
      "Epoch[182]    Iter[7/8]    Loss: 5.9372053146362305\n",
      "Epoch[182]    Iter[8/8]    Loss: 5.9082818031311035\n",
      "\n",
      "\n",
      "\n",
      "Epoch[183]    Iter[1/8]    Loss: 5.905107498168945\n",
      "Epoch[183]    Iter[2/8]    Loss: 5.937536239624023\n",
      "Epoch[183]    Iter[3/8]    Loss: 5.927017688751221\n",
      "Epoch[183]    Iter[4/8]    Loss: 5.8866167068481445\n",
      "Epoch[183]    Iter[5/8]    Loss: 5.914671897888184\n",
      "Epoch[183]    Iter[6/8]    Loss: 5.900960445404053\n",
      "Epoch[183]    Iter[7/8]    Loss: 5.920742511749268\n",
      "Epoch[183]    Iter[8/8]    Loss: 5.8992414474487305\n",
      "\n",
      "\n",
      "\n",
      "Epoch[184]    Iter[1/8]    Loss: 5.907629013061523\n",
      "Epoch[184]    Iter[2/8]    Loss: 5.911961078643799\n",
      "Epoch[184]    Iter[3/8]    Loss: 5.926362991333008\n",
      "Epoch[184]    Iter[4/8]    Loss: 5.931258201599121\n",
      "Epoch[184]    Iter[5/8]    Loss: 5.924872398376465\n",
      "Epoch[184]    Iter[6/8]    Loss: 5.905523777008057\n",
      "Epoch[184]    Iter[7/8]    Loss: 5.915860176086426\n",
      "Epoch[184]    Iter[8/8]    Loss: 5.890085697174072\n",
      "\n",
      "\n",
      "\n",
      "Epoch[185]    Iter[1/8]    Loss: 5.90141487121582\n",
      "Epoch[185]    Iter[2/8]    Loss: 5.93739652633667\n",
      "Epoch[185]    Iter[3/8]    Loss: 5.907751083374023\n",
      "Epoch[185]    Iter[4/8]    Loss: 5.901456356048584\n",
      "Epoch[185]    Iter[5/8]    Loss: 5.930049896240234\n",
      "Epoch[185]    Iter[6/8]    Loss: 5.9046807289123535\n",
      "Epoch[185]    Iter[7/8]    Loss: 5.89730978012085\n",
      "Epoch[185]    Iter[8/8]    Loss: 5.912802696228027\n",
      "\n",
      "\n",
      "\n",
      "Epoch[186]    Iter[1/8]    Loss: 5.914087772369385\n",
      "Epoch[186]    Iter[2/8]    Loss: 5.913485050201416\n",
      "Epoch[186]    Iter[3/8]    Loss: 5.931275844573975\n",
      "Epoch[186]    Iter[4/8]    Loss: 5.899878025054932\n",
      "Epoch[186]    Iter[5/8]    Loss: 5.927903652191162\n",
      "Epoch[186]    Iter[6/8]    Loss: 5.903399467468262\n",
      "Epoch[186]    Iter[7/8]    Loss: 5.916931629180908\n",
      "Epoch[186]    Iter[8/8]    Loss: 5.908767223358154\n",
      "\n",
      "\n",
      "\n",
      "Epoch[187]    Iter[1/8]    Loss: 5.939146518707275\n",
      "Epoch[187]    Iter[2/8]    Loss: 5.9209442138671875\n",
      "Epoch[187]    Iter[3/8]    Loss: 5.916082382202148\n",
      "Epoch[187]    Iter[4/8]    Loss: 5.91909646987915\n",
      "Epoch[187]    Iter[5/8]    Loss: 5.917366027832031\n",
      "Epoch[187]    Iter[6/8]    Loss: 5.881274223327637\n",
      "Epoch[187]    Iter[7/8]    Loss: 5.899242401123047\n",
      "Epoch[187]    Iter[8/8]    Loss: 5.900069236755371\n",
      "\n",
      "\n",
      "\n",
      "Epoch[188]    Iter[1/8]    Loss: 5.932971000671387\n",
      "Epoch[188]    Iter[2/8]    Loss: 5.902379035949707\n",
      "Epoch[188]    Iter[3/8]    Loss: 5.923213481903076\n",
      "Epoch[188]    Iter[4/8]    Loss: 5.932859420776367\n",
      "Epoch[188]    Iter[5/8]    Loss: 5.908111572265625\n",
      "Epoch[188]    Iter[6/8]    Loss: 5.896931171417236\n",
      "Epoch[188]    Iter[7/8]    Loss: 5.905614852905273\n",
      "Epoch[188]    Iter[8/8]    Loss: 5.933374404907227\n",
      "\n",
      "\n",
      "\n",
      "Epoch[189]    Iter[1/8]    Loss: 5.9248270988464355\n",
      "Epoch[189]    Iter[2/8]    Loss: 5.907147407531738\n",
      "Epoch[189]    Iter[3/8]    Loss: 5.912026405334473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[189]    Iter[4/8]    Loss: 5.9141950607299805\n",
      "Epoch[189]    Iter[5/8]    Loss: 5.914940357208252\n",
      "Epoch[189]    Iter[6/8]    Loss: 5.912707328796387\n",
      "Epoch[189]    Iter[7/8]    Loss: 5.890008926391602\n",
      "Epoch[189]    Iter[8/8]    Loss: 5.929375648498535\n",
      "\n",
      "\n",
      "\n",
      "Epoch[190]    Iter[1/8]    Loss: 5.92898416519165\n",
      "Epoch[190]    Iter[2/8]    Loss: 5.922328472137451\n",
      "Epoch[190]    Iter[3/8]    Loss: 5.885161399841309\n",
      "Epoch[190]    Iter[4/8]    Loss: 5.908961772918701\n",
      "Epoch[190]    Iter[5/8]    Loss: 5.911048412322998\n",
      "Epoch[190]    Iter[6/8]    Loss: 5.915148735046387\n",
      "Epoch[190]    Iter[7/8]    Loss: 5.922691822052002\n",
      "Epoch[190]    Iter[8/8]    Loss: 5.908210277557373\n",
      "\n",
      "\n",
      "\n",
      "Epoch[191]    Iter[1/8]    Loss: 5.889007568359375\n",
      "Epoch[191]    Iter[2/8]    Loss: 5.939112663269043\n",
      "Epoch[191]    Iter[3/8]    Loss: 5.90545654296875\n",
      "Epoch[191]    Iter[4/8]    Loss: 5.923725605010986\n",
      "Epoch[191]    Iter[5/8]    Loss: 5.90349817276001\n",
      "Epoch[191]    Iter[6/8]    Loss: 5.9263386726379395\n",
      "Epoch[191]    Iter[7/8]    Loss: 5.911186695098877\n",
      "Epoch[191]    Iter[8/8]    Loss: 5.908064365386963\n",
      "\n",
      "\n",
      "\n",
      "Epoch[192]    Iter[1/8]    Loss: 5.907897472381592\n",
      "Epoch[192]    Iter[2/8]    Loss: 5.906590461730957\n",
      "Epoch[192]    Iter[3/8]    Loss: 5.896240711212158\n",
      "Epoch[192]    Iter[4/8]    Loss: 5.91298246383667\n",
      "Epoch[192]    Iter[5/8]    Loss: 5.9291911125183105\n",
      "Epoch[192]    Iter[6/8]    Loss: 5.912945747375488\n",
      "Epoch[192]    Iter[7/8]    Loss: 5.935837268829346\n",
      "Epoch[192]    Iter[8/8]    Loss: 5.902652263641357\n",
      "\n",
      "\n",
      "\n",
      "Epoch[193]    Iter[1/8]    Loss: 5.9145941734313965\n",
      "Epoch[193]    Iter[2/8]    Loss: 5.906217098236084\n",
      "Epoch[193]    Iter[3/8]    Loss: 5.920164108276367\n",
      "Epoch[193]    Iter[4/8]    Loss: 5.931940078735352\n",
      "Epoch[193]    Iter[5/8]    Loss: 5.902441024780273\n",
      "Epoch[193]    Iter[6/8]    Loss: 5.900907039642334\n",
      "Epoch[193]    Iter[7/8]    Loss: 5.912225723266602\n",
      "Epoch[193]    Iter[8/8]    Loss: 5.908621788024902\n",
      "\n",
      "\n",
      "\n",
      "Epoch[194]    Iter[1/8]    Loss: 5.8951029777526855\n",
      "Epoch[194]    Iter[2/8]    Loss: 5.916441440582275\n",
      "Epoch[194]    Iter[3/8]    Loss: 5.924078464508057\n",
      "Epoch[194]    Iter[4/8]    Loss: 5.911707401275635\n",
      "Epoch[194]    Iter[5/8]    Loss: 5.909759998321533\n",
      "Epoch[194]    Iter[6/8]    Loss: 5.9141740798950195\n",
      "Epoch[194]    Iter[7/8]    Loss: 5.917917251586914\n",
      "Epoch[194]    Iter[8/8]    Loss: 5.923186302185059\n",
      "\n",
      "\n",
      "\n",
      "Epoch[195]    Iter[1/8]    Loss: 5.905359268188477\n",
      "Epoch[195]    Iter[2/8]    Loss: 5.925307750701904\n",
      "Epoch[195]    Iter[3/8]    Loss: 5.89447021484375\n",
      "Epoch[195]    Iter[4/8]    Loss: 5.9120941162109375\n",
      "Epoch[195]    Iter[5/8]    Loss: 5.934006690979004\n",
      "Epoch[195]    Iter[6/8]    Loss: 5.890805721282959\n",
      "Epoch[195]    Iter[7/8]    Loss: 5.923792839050293\n",
      "Epoch[195]    Iter[8/8]    Loss: 5.914062976837158\n",
      "\n",
      "\n",
      "\n",
      "Epoch[196]    Iter[1/8]    Loss: 5.907052993774414\n",
      "Epoch[196]    Iter[2/8]    Loss: 5.91391658782959\n",
      "Epoch[196]    Iter[3/8]    Loss: 5.92276668548584\n",
      "Epoch[196]    Iter[4/8]    Loss: 5.919567584991455\n",
      "Epoch[196]    Iter[5/8]    Loss: 5.915709495544434\n",
      "Epoch[196]    Iter[6/8]    Loss: 5.922572135925293\n",
      "Epoch[196]    Iter[7/8]    Loss: 5.917804718017578\n",
      "Epoch[196]    Iter[8/8]    Loss: 5.900430202484131\n",
      "\n",
      "\n",
      "\n",
      "Epoch[197]    Iter[1/8]    Loss: 5.909687042236328\n",
      "Epoch[197]    Iter[2/8]    Loss: 5.895409107208252\n",
      "Epoch[197]    Iter[3/8]    Loss: 5.896646022796631\n",
      "Epoch[197]    Iter[4/8]    Loss: 5.927253246307373\n",
      "Epoch[197]    Iter[5/8]    Loss: 5.923605442047119\n",
      "Epoch[197]    Iter[6/8]    Loss: 5.897507667541504\n",
      "Epoch[197]    Iter[7/8]    Loss: 5.907770156860352\n",
      "Epoch[197]    Iter[8/8]    Loss: 5.931117534637451\n",
      "\n",
      "\n",
      "\n",
      "Epoch[198]    Iter[1/8]    Loss: 5.8922929763793945\n",
      "Epoch[198]    Iter[2/8]    Loss: 5.923334121704102\n",
      "Epoch[198]    Iter[3/8]    Loss: 5.916800498962402\n",
      "Epoch[198]    Iter[4/8]    Loss: 5.913973808288574\n",
      "Epoch[198]    Iter[5/8]    Loss: 5.927854061126709\n",
      "Epoch[198]    Iter[6/8]    Loss: 5.908994674682617\n",
      "Epoch[198]    Iter[7/8]    Loss: 5.925897121429443\n",
      "Epoch[198]    Iter[8/8]    Loss: 5.917057514190674\n",
      "\n",
      "\n",
      "\n",
      "Epoch[199]    Iter[1/8]    Loss: 5.9281086921691895\n",
      "Epoch[199]    Iter[2/8]    Loss: 5.887357711791992\n",
      "Epoch[199]    Iter[3/8]    Loss: 5.919857025146484\n",
      "Epoch[199]    Iter[4/8]    Loss: 5.90419340133667\n",
      "Epoch[199]    Iter[5/8]    Loss: 5.903120994567871\n",
      "Epoch[199]    Iter[6/8]    Loss: 5.918116569519043\n",
      "Epoch[199]    Iter[7/8]    Loss: 5.925116062164307\n",
      "Epoch[199]    Iter[8/8]    Loss: 5.9130778312683105\n",
      "\n",
      "\n",
      "\n",
      "Epoch[200]    Iter[1/8]    Loss: 5.91227388381958\n",
      "Epoch[200]    Iter[2/8]    Loss: 5.9153056144714355\n",
      "Epoch[200]    Iter[3/8]    Loss: 5.918424129486084\n",
      "Epoch[200]    Iter[4/8]    Loss: 5.910048961639404\n",
      "Epoch[200]    Iter[5/8]    Loss: 5.933250427246094\n",
      "Epoch[200]    Iter[6/8]    Loss: 5.900406837463379\n",
      "Epoch[200]    Iter[7/8]    Loss: 5.900547504425049\n",
      "Epoch[200]    Iter[8/8]    Loss: 5.911128044128418\n",
      "\n",
      "\n",
      "\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "main()\n",
    "print('DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba189d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "d3a10e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torch.load('test.pkl').cuda()\n",
    "checkpointdir = './pretrained/myMoCo/checkpoint_0200.pth.tar'\n",
    "checkpoint = torch.load(checkpointdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "3ae2f9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = myMoCo().cuda()\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "66c76f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, target = model(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "id": "1a95d3de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(output, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56f4562",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "id": "aa1085f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "1c54ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw(x):\n",
    "\n",
    "    color = ['r', 'y', 'g', 'b', 'm', 'c', 'k', 'w']\n",
    "    ptr = 0\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    for pos in x:\n",
    "        plt.scatter(pos.numpy()[:, 0], pos.numpy()[:, 1], c = color[ptr], s=10)\n",
    "        ptr = (ptr+1)%len(color)\n",
    "    \n",
    "    plt.axis([-1.5, 1.5, -1.5, 1.5])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "id": "4b6c8e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightdir = './pretrained/MLP/mlp0200.pth.tar'\n",
    "weight = torch.load(weightdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "d3e94661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLP(512).cuda()\n",
    "mlp.load_state_dict(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "bbcee96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 4, 2]),\n",
       " tensor([[[-0.2025, -0.9793],\n",
       "          [-0.3625, -0.9320],\n",
       "          [-0.0365, -0.9993],\n",
       "          [-0.3414, -0.9399]],\n",
       " \n",
       "         [[ 0.3041, -0.9526],\n",
       "          [-0.1705, -0.9854],\n",
       "          [ 0.2064, -0.9785],\n",
       "          [ 0.3797, -0.9251]],\n",
       " \n",
       "         [[ 0.1043, -0.9945],\n",
       "          [-0.1390, -0.9903],\n",
       "          [ 0.2298, -0.9732],\n",
       "          [-0.0414, -0.9991]],\n",
       " \n",
       "         [[ 0.4627, -0.8865],\n",
       "          [ 0.4510, -0.8925],\n",
       "          [-0.1928, -0.9812],\n",
       "          [-0.2789, -0.9603]],\n",
       " \n",
       "         [[-0.5406, -0.8413],\n",
       "          [ 0.1015, -0.9948],\n",
       "          [-0.4834, -0.8754],\n",
       "          [-0.0055, -1.0000]],\n",
       " \n",
       "         [[ 0.0675, -0.9977],\n",
       "          [ 0.2670, -0.9637],\n",
       "          [-0.0869, -0.9962],\n",
       "          [ 0.3328, -0.9430]]]))"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '../CUHK01/dataset.pkl'\n",
    "train_dataset = torch.load(path).cuda()\n",
    "\n",
    "st = 500\n",
    "end = 505\n",
    "N = end-st+1\n",
    "show_data = train_dataset[st:end+1]\n",
    "inDim = show_data.shape[2]\n",
    "print(show_data.shape)\n",
    "\n",
    "inputs = show_data.reshape(-1, inDim)\n",
    "outputs = mlp(inputs)\n",
    "outputs = nn.functional.normalize(outputs, dim=1)\n",
    "outputs = outputs.cpu().detach()\n",
    "\n",
    "outDim = outputs.shape[1]\n",
    "outputs = outputs.reshape(N, -1, outDim)\n",
    "outputs.shape, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "e8042573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c45ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649d675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cd9adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2bbcdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyi/anaconda3/envs/tianyi1.13/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_248509/854700355.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow2dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/WORK/ViTMLP/visualization.py\u001b[0m in \u001b[0;36mshow2dim\u001b[0;34m(show_data, num_pos)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mdata_2dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pca'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mfig_2dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_embedding_2dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_2dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m't-SNE Embedding'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tianyi1.13/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0mEmbedding\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtraining\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlow\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdimensional\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \"\"\"\n\u001b[0;32m-> 1108\u001b[0;31m         \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tianyi1.13/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, skip_num_points)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m             )\n\u001b[1;32m    836\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tianyi1.13/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tianyi1.13/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m             raise ValueError(\n\u001b[1;32m    795\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m             )\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "num_pos = 4\n",
    "visualization.show2dim(outputs, num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d9e52bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyi/anaconda3/envs/tianyi1.13/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tianyi/anaconda3/envs/tianyi1.13/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:986: FutureWarning: The PCA initialization in TSNE will change to have the standard deviation of PC1 equal to 1e-4 in 1.2. This will ensure better convergence.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization.show2dim(inputs, num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c080bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianyi/anaconda3/envs/tianyi1.13/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  FutureWarning,\n",
      "/home/tianyi/anaconda3/envs/tianyi1.13/lib/python3.7/site-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  FutureWarning,\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n",
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfQAAAHzCAYAAADW0+8yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAA9hAAAPYQGoP6dpAABF00lEQVR4nO3dfXRcdX7n+U+VZAvbsiRLfpBcQrZl3ElIGGHaCxiLp5Z3m5hssktDk8YN2Z05mTMTbKeTsZk53YSnHrJnwczSPJzMTu+c3emG5TTQ3t2ctJs+sQTdCAyMGyNISGIj2RIqSbb1UCo9WLKsqv3juqS6UtWtp3urbl29X/8Q/W7VrWul7W/9fr/v7/v1RaPRqAAAQFHzF/oBAABA7gjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHkBABwDAAwjoAAB4AAEdAAAPIKADAOABBHQAADyAgA4AgAcQ0AEA8AACOgAAHlBa6AcA4IDBU9JIp1R9jVSzrdBPAyAPCOiAl0wOSz99QOr8xfzY1q9L974mrVhTuOcC4DhfNBqNFvohANjkx3dJXcek6Oz8mK9EatwtPfhW4Z4LgOPYQwe8YvCUMTOPD+aS8XPnL6Sh07Z/ZLjvjPpO/kpj/WdtvzeAzLDkDnjFSKf19eEvbNtPnx4P6f0XDmmgo31urLapWbsOHNby8kpbPgNAZpihA16xZqv19eprbPuo9184pHOfHTeNnfvsuN574aBtnwEgMwR0wCvWfsVIgPOVmMd9Jca4TbPzcN8ZDXS0KxoxL+1HI7Ma6Ghn+R0oEAI64CX3vmYkwMVr3G2M22T83JeW18cGehJfGDwlnf65I3v5ANhDB7xlxRojm33otLFn7sA59PINV1teX13bYB7gKB2QF8zQAS+q2SZt+11HispUbNyi2qZm+fzmpX2fv0S1Tc1aXbfZ/IafPmAcpYvXdUx681u2PxuwlBHQgSIz09mlqba3dbnrTMGeYdeBw9pw3U7T2IbrdmrXgcPmF6Y6Stf5tw4/KbB0UFgGKBKRkREN79uv6Xd+OTdWdsftqn75JfmrqgryTGP9ZzU20KPVtQ2LZ+aSsWf+6h7rm7D8DtiCgA4UicG939b0u+3SbNxst6REZbc2a+2rrxTuwawMnpJe+g3r11DJDrAFS+5AEZjp7DJm5rMLlq5nZzX9zi8LuvxuKdlRungOVrIDlhICOlAEZru7La9fPns2Pw+SjURH6RIZ/sL5ZwE8jIAOFIGSTZssr5du3pyfB8lG7Cjdt39h/TobK9kBSxEBHSgCy7Y2quyO26WSBUvXJSUqu+N2lTZuKcyDZeKa/y4vleyApYqADhSJ6pdfUtmtzaaxslubVf3yS5bvc8Mxtzl5qGQHLFVkuQMuEgqFFA6HVVlZqcrKxF3LLned0eWzZ1W6ebPlzNyNx9zmOFjJLpF0fq9AsSOgAy4wNTWltrY29fb2zo3V19erpaVFZWVlWd2zKI+52cyJ3yvgVgR0wAWOHj2qYDCo+L+OPp9PgUBAe/akKMySwExnl87fdnvS6xve/VVx7LvnKNnvdf369dq+fTszdngKzVmAAguFQqYZZEw0GlVvb69GR0czDjrpHHPzekC3+r2eO3dOb71lFLJhxg6vICkOKLBwOGx5fXR0NON7FvUxN5uk+r3GBINBtba2Ovw0gPMI6ECBVVRUWF7PZknYjmNuoWBYPb8OarQvvcDoNql+rzHxKyFAMWPJHSiwqqoq1dfXJ91Dz3aPt/rllzT88D5zlnsax9ymxqbV+ly7ek/2z43Vb6/T7oPNKisvnmXpZL/XZLLZ2gDchKQ4wAWmp6fV2trqSDZ2usfcYn72RKuCHQOKRuK+XPh9CjTV6u4nWnJ6lnxL9HtN5v777yego6gR0AEXGR0dnZspxoLLTGeXZru70w7IuQgFw/rJn/x10ut/+Fe/r8qN6S1lu0ns9/rJJ5/o3Llztp0mANyEJXfAReIDeSEKw4QHxiyvj/aPLQrooWBY4YExVdatdm2wj/1eN2zYsGjGHggE1NJSXCsPQCIEdMClhvftNwrDxJl+t13DD+9zrDBMRe1qy+uVdfPXi3GvvaysTHv27Em4EgIUO7LcARcqVP/zqkCF6rfXyef3mcZ9fp/qt9eZZuCtz7Ur2DFgel2wY0DHDpu/hLhRZWWlGhoaCObwFAI64EKF7H+++2CzAk21prFAU612H5xvDDP8/qeafucdrZy8YHpdNBJV78n+oj3qBhQzltwBFypkYZiy8jLd/USLRvvCxp553N54/L7+TVdef75im042fkszpSvm7pForx2As5ihAy7khv7nlRsr1PDVgCkwJ9rXXxf+Qv/N2f/L/N466714APYjoAMulW3/c6ck29f3KarqUI/2rPtfVLZsctFeO4D84Bw64HKZFoZxylTb2xp68KGk19d8fUjjDb+tyoPtrs1yB7yMPXTA5Uobt9gSyEOhkMLhcNZHtVLt6y+vnNF6nZCme6Tybdk+JoAsEdABj5uamlJbW1vOZWVj+/rTv3pXikTmL/iiKgtMq7TysvHz8BdSDQEdyDf20AGPa2trUzAYNI1l2zK0+uWXVHbzDaaxssC0qr82FPeia7J6TgC5YYYOqFtSr6SrJTVYvtKVZU4HT0kjnUYgXTAzDoVCCRuTxLcMzWT53V9VpbVv/D+6/L/dqct/95FKKy7Nz8x9JVLjbmbnQIEQ0LGEjUp6VNLxuLGdkp6WZA7WrixzOjks/fQBqfMX82Nbvy7d+5q0Yo0kKRy2LvCSbcvQ0n91RKVvfsv82Y27jc8GUBBkuWMJ2y/pQ0lx+8HyS7pJ0oumV7qypeiP75K6jknRuGNksVnyg29JMmbor7/+etJb5NwydOi0sWeeYHVgoURd44LjQQ1M9KtuVZ02lgeyegQ77gF4ATN0LFHdMs/MYyJXxnsUW34PBcOmmXlMfJlTq+X3yNCkosMX5ateIX/NSjse3lhm7/yFQiXrFS5dp8rLF1Q5e94I7p2/MAJtzTZVVVWpvr5ewWAwYcvQnGuZ12xLGcgTdY2b+W9v1f/5P2/SyZFP58a2r79Bh3Y8ovLlFkVp4rYXxlbX6vCJZ3Ty/MeZ3QPwKAI6lqjF+8pmXyoW0LNpKSpJ0YszmjnyuSKdI3Nj/q1rtOyea+VbsSzTBzaZOn9KbdX71XvV78yN1U/9nVpG/rPKopOmTPOWlpaCtgxNVF3uP36lV/84NGpKy+248ImePfGMnrzl+4tvkmB7YaCmUV9svEYqKU3vHnazyF0ACoGAjiWqPsX1q+f+r0xaisabOfK5Il0jprFI14hmjnyu5Xub0nrKZNpOXVSw7LdMY8Gy31Lrmn+hPcMvmjLNC9kydK66XJxz65fr82sX/84i0YhOnv9YfePBxUvnP33A2F6I0zh0Rn9+Kawnt96Y3j3skkbuAlAIHFvDErVJRgLcwr8C/ivj89numbQUjYkMTRoz84UZKlEp0jmiyNBk1k8eCoXUe35EUZ+5znvUV6Leq35Ho1vuSThjLETL0ERd4y6stU4i7J9YsL1xZXvBlCsgqURRfXVsUHXTE6nvYacEXy7UdUx681vOfSaQBgI6lrCnpbmeYTE3XRk3S6elaLzo8EXLT0513UrKzPVdeVhuTlOi6nLrBqct31O3qs48MNJp/foEAX3RPRYIhULq6enR6Oio5esWSfLlwpS7ABQIS+5YwipkZLP3yNgzT34O3aqlaCK+6hVJr6Vz3UpFhfX598p17sn0nqsu9277XFOXDecv6drPx/SPv7lakbgphd/nV9O66xcvla/ZavkZ/WWrUt/jipyr5qX4ckGVPBQSM3RADZJ2KVVRGSlxS9FE/DUr5d+6RvItuOAzEuNyyXaPZa77fAu2AHw+1dfX53VJPR2Jusb961P1aqr5Z6axpnXX69CORxbfYO1XjD3qBFsMp2saTQE96T2uyLlqXoovF1TJQyFxDh1wiJNZ7tPT04sy17Opz55PibrG9Y0H1Z/OGfKLI8YedYJEtL7ZybTuYduZ/DTO/wOFQEAHHObIOfQrCpG5XlAZFLJZqKenR2+9lTzg3nXXXWpoSL1KY/Xlgix3FBJ76IDD/DUrJZsDeYydgTzX9qp5kUYhm2RS5h6k+2descaYiefw5QJwAgEdWOLsaq/qdrZXzcvhywXgBJLigAKLDE1q9vRQTmfTc2Fne1W3a2lpUSBg3mfPZ9U8wEnM0IECcTJpLl12t1d1u0JWzQOcxgwdKBCr0rD5krJITe8/5OlJ8qsQVfMApxHQgQJwsjRsJlImih35A+OY1sURy9eZdUt6T0bBHgD5QkAHCsDJ0rCZSFqkJjqr+qm/M1qypl2nfFRGj/lvSPpTSfdc+dl6FQCAPQjoQAE4WRo2UwkTxab/QS0j/9n4Ie065Y9K+nDB2IeSvmfTkwKwQlIcMkMPaFvESsNGuhYsu/skf2NupWEzNZco1vHXGj36XVVevmDMzBeyrFPeLel4gvHIlfEepVNaF0D2COhIDz2gbbfsnmsXZ7k3GlnuTguOBzWwoFxqZeA3VTn998nfZFmnfHGmvNmXIqADzqL0K9JD/WrHOFkadqGxS2M6fOIZnTz/8dzY9vU36NCOR1S+fHUO/3/ulrF3nswREdABZ7GHjtToAe0of81KlWyrycsy++ETz6jjwiemsY4Ln+jZE88YP9z7mhG84zXuNsYtbZK0U4v/SfFfGTeCeSgYVs+vgxrtI1EOsBtL7kiNHtBziqLeeRLB8aBpZh4TiUZ08vzH6hsPGsvvWdcpf1pGAlz8XvpNkp7W1Ni0Wp9rV+/J/rkr9dvrtPtgs8rKvVNeFigkAjpSowe0J+qdD0z0W17vn+ifbz+aVZ3yCkkvykiA+1LS1YrNzFufa1WwY8D06mDHgI4dbtfdT1B2FbADS+5Ibe1XjAQ4X4l53FdijC+B2bkX6p3XrqqzvF6X4nr6GiTtUvwye+/JfkUj5nSdaCSq3pP91svvg6ek0z93bFun0HX0ATsxQ0d67n1tcQ/otPZW3S9Rxnc8u+udz3R2aba7W6WbN6u0cUtOz56JQHlA29ffoI4LnygSjcyN+31+Na27PuGf3Q7hgTHL66P9Y6rcuKBincOnKtxQRx+wGwEd6fFgD+iUGd9XpKx3nmZAj4yMaHjffk2/88u5sbI7blf1yy/JX1WV+R8gC4d2PKJnF/yZm9Zdr0M7HnHsMytqV1ter6xLcP2nDxjZ9vFiFetsOFVhVUd/+d4my/fm81QCkAkCOjLjoR7QVhnfT97y/bmxlPXO05ydD+/br+l3201j0++2a/jhfVr76ivpPXSOypev1p9d+2/0xdovNFk6oWvWX+PYzDymKlCh+u11CnYMmJbdfX6fAk21qlw+IJ1+b/5LYuxUxULxpypy+N/gXB39Rfefr6OfKFAzq4fbEdCxJKWd8a35eufBYFDxZRt8Pp8CgUBaAX2ms8s0M58zO6vpd36py11nHF9+T5TYN14/oZqWtY4n9u0+2Kxjh81Z7pubVqpl8/8qvfS38y/c+nVp+z+3vlmOpyrSqqOfIKDnMqsH8oGAjiUpo4xvGfXOW1tbTcEwEAiopSW9DO3Z7m7L65fPns0qoGeyH2+V2Ldnz56MPzsTZeVluvuJFo32hY0987rVqmz9ptTVZn5h1zFpZsL6Zjmeqsimjn62s3ognwjoWJIyzfieq3c+Ojq3Z55JIlzJpk2W10s3b077XlLm+/F2J/Zlq3JjhZEAZ7Ws3tMuXd0s9R5PXLEuxy2fbOroZzurB/KJY2vwnFAopJ6eHo2OjiZ9TSzj2+8z/xXw+/zavv6GpPvKlZWVamhoUDQaTfkZ8ZZtbVTZHbdLJQuO/pWUqOyO2zOenVvtxyeSTmJfrjI6ApaqWNFN+7OsWJeeZfdcK3+jOVveqo6+m7rjAckwQ4dnZFr8JZuM72wKzMSyoqv+/bMKPXrIPKu+tVnVL7+U0Z8zm/14uxL7EskqWSxVsaK67dLvOHeqwrdimZbvbUo7Y91N3fGAZGjOAs84evRo0sQ1qz3ivvGg+i3OoWf7GckCne+GFZrtD2Z9Dn2q7W0NPfhQ0us1P/6RrvranTk9eyYuvdqRNNBZJosVWcMfstzhdszQ4Qm57BFvLA+kdXQr089IlhXtl3TV3sUBN13Z7sfnmtiXSE7JYkVWrCjTWT2QbwR0eIJdxV/s+gwns6Jj+/HT77ZLs3Gz25ISld3anHTWn2tiXyI5JYsVabEif81KEuDgSiTFwROc3CPO5jPSCnQ5qH75JZXd2mwaS3c/PpbYZ8fvxJZksZpt0rbfLYpgDrgZM3R4gh3FX+z8DKezov1VVVr76iu63HXGOMOe57rwc89BshjgGszQ4RktLS0KBMx74bnuEWf7GbFAJ9+CG/iMRCq7Al1p4xZd9bU7CxLMYzI9AgbAGWS5o+BCwbDCA1eqhy3supUFO/eIc/mMXLKiQ6GQwuGwo38Gu5EsBhQWAR0FMzU2rdbnzPW967fXaffBZpWVO1tbPJ8yCXTZnHMHAImAjgL62ROtSTtw3f2EfcvkxSC2SnHy1Mc6Pz5g+1lxAN5HUhwKIhQMm2bmMdFIVL0n+zXaF7Zl+d3NQqGQBvuH9PevfqGBzy7MX1i3XNo+Ld+VVfl811sHUJwI6CiI8MCY5fXR/jHPBvT4ZfXoR2XSoF+m7LlBv3SyTLpx2vS+Yg/oPYMT6h2ZVH31SjXUrCr04wCeQ0BHQVTUrra8Xllnfb2YxdqYRsd90oWSxS+IGuPRCZ98q4yld9/kiKZ7/l5jyyJaXbc5vw+co9HJS3r8zU/1QefQ3NjNW2v01H1NqqBkKmAbAjoKoipQofrtdUn30L06OzeVj51McWp0wictv6gVf3dUpcPdOnHcGK5tatauA4e1vLw4ZuuPv/mpPuoaNo191DWsx97o0PMP7SjQUwHewzl0FMzug80KNNWaxgJNtdp9sDnJO4qfqXzsyhT5qKuiRjAf+dI0fO6z43rvhYMOPJ39egYn9EHnkCILcm8j0ag+6BxSz9CEo5+fUUtXoMgxQ0fBlJWX6e4nWjTaFzb2zG06h54Lp89Sx5eP9ZVHFV03a+yZR+f30H1+nzb89lr95m2r9fEH/2HRPaKRWQ10tGus/6zrl997R6wDae/wpCP76XRGw1JEQEfBVW6sKHggz1cAWFQ+dvu0kQAXt5ceW6UYOv2h5b3GBnpyDugznV2a7e52rHRs/RrrL0X11c4UoEnW6W7myOfWLV2BIkZAB5TfABDfxtS3TNKN09qwuk6/s+U6rW2onvtyU77hasv7rK5tyPoZIiMjGt63X9Pv/HJurOyO21Xyl09rzOezrUJdw9pVunlrjT7qGjYtu/t9Pt3YWO3I7NzJTneAmxHQseSlEwDCJZdsK8WabhvTio1bVNvUrHOfHVc0Mt8m1ecv0YbrdiacnQfHgxqY6FfdqjrLHu/D+/Yb7VfjTP3qXV148I/0X7/9gCT7KtQ9dV+THnujw5TlfmNjtZ66z5mZck4tXYEiRqU4LHmzp4c089pnSa9/sm1Kn471zP2cz1Ksl8ZH9d4LBzXQMR98E2W5j10a0+ETz+jk+Y/nxravv0GHdjyi8uXmI4AznV06f9vtST/z7X1/osmaGtsr1PUMTah32Plz6JGhSV16+aOk15c/fCMzdHgSM3QsealamZ4NDUhxx8WDwaBaW1vzUop1eXml7vzuDzXWf9bYM69tSDgzP3ziGXVc+MQ01nHhEz174hk9ecv3TeOz3d2Wn7lqeESTNTW2V6hrqFmVl4IytHTFUsWxNSx5yVqdRn1ScPmEwiWXzONxgS5fVtdt1sbttyVdZj95/mNFohHTeCQa0cnzH6tvPGgaL9m0yfKzJqrNrVDz+ee0Cy1dsRQxQwdkBICFWe6X6lbo3ctfJH2PW0qxDkwsrokfr3+i37Sfvmxro8ruuN3YQ5+d35uP+HwabGzUZE2N6f1u+DNmyrdimZbvbaKlK5YUAjqgxAFgquSSLr3ekfQ9bgl0tavqLK/XJbhe/fJLGn54nynLfbCxUSe/8T/O/RzbQ4/9OYuxFru/ZiUJcFgyCOhAnPgAUKWV5jPjVywMdIUWKA9o+/ob1HHhE9Oyu9/nV9O66xNmu/urqrT21Vd0ueuMLp89q8jGjero6tTluD7sgUBALS0t1GIHigRZ7oCF6enpuTPjMfnMck/X+KUxPZtmlruVREfpvvOjE0nPkVOLHXAPAjqQhlRnxu3RLalX0tWSsisa0zceVH8a59DT1TM4oW++2J70+usHmotm+R3wOpbckQe5ByqnpSrI4mwgH5X0qKTjcWM7JT0tKbOSuBvLA7YE8phC1WIHkDkCOhxkX6BySiYFWZzzqKSFdds/lPQ9SS/m6RkSK1QtdjcL953R+Lkvk9YEAAqFJXc4pmfw36l35EvVVw+qoSaWUOWXdJMKHahiHn//L5Imky0syOKMbknfsLh+RIVe1WAP3TA9HtL7LxxKWbUPKBQKy8B2o5OX9J0fteubL96pP3/lIX3zhT/Xd370RwpfvEpSRMaMvSfFXZyXaUEWZ/SmuP5liuvOe+q+Jt3YWG0ac7IWu1u9/8IhnfvsuGmsmHrTw/tYcoftHn/zU33UNWEa+6jrGj32xv16/qH/cmXkSxV65plpQRZn1Ke4bt1xLR8qVizT8w/tyFstdjcK950xzcxjiqk3PbyPGTps1TM4oQ86hxRZsJETifr1QedX1DMUq0JW+ECVTUGWTMx0dmmq7W1d7jpj8apNMvIKFv5V9F8Zd08SYUPNKt2ybd2SC+aSNH7OeqVkbKDwK04AAR22Sp0VvVZuCVSxgix+n/mvgd/n1/b1N2Q9O4+MjGhw77d1/rbbNfTgQzp3620a3PttRUKhJO94WkZeQbybrozDDZzsTQ/YhYCOhMJ9Z9R38lca6z+b0ftSZ0VfLTcFqkM7HlHTuutNY03rrtehHY9kfc9Evcan323X8MP7kryjQkaS4BFJP7jy3xdldRIgOB7Ur8+dyNM+P2K96X3+EtO4z1+i2qZmltvhCmS5w8SOTN7EWdHSjY2r9PxDzWndI99Hg+wqyJKq1/iGd3+l0sYtWd/fHcfslqZ0e9MDhUJAXwIyCY5v/+Uf69xnxxWNzHfh8vlLtOG6nbrzuz9M7/MuzuixNzqyqv1d7EeDptre1tCDDyW9XvPjH+mqr92Z9f0Lf8wOqXrTA4VClruHZRoc7crkzSUr2upoULpfKAopVa/x0s2bs7537JjdQvHH7JzPysfqus0EcrgSe+gelum5WbszeTPNio59oYhfHZDMXyjcLtZrXCXmvVaVlKjsjttzWm5P55gdgKWLgO5R2QTHQmfy2vWFIhQKqaenR6Ojo3Y8VsaqX35JZbeacwXKbm1W9csv5XRfp4/ZAShuLLl7VDrBceGyYSyTN9keutPLjLl+oZiamlJbW1vBW50u7DVeunlzTjPzmGz6nhezUCikcDjscGMcwDuYoXtUtsFx14HD2nDdTtPYhut2ateBw7Y9WzK5Hg1qa2tTMGg+xhUMBtXa2mr3o6altHGLrvranbYE8xi7jtlFhiY1e3pIkSHrugGFMDU1paNHj+r111/XW2+9pZ/85Cc6evSopqenC/1ogKuR5e5huWSsFyqTN9ujQaFQSK+//nrS6/fff78rZnk9gxPqHcm9fGq2x+yiF2c0c+RzRTpHjPssH9b5zZd19e6bFFhrndCXL0ePHlUwGFT8P00+n0+BQEB79uwp4JMB7kZA97BiPjeb6ReKnp4evfXWW0mv33XXXWpoKFw1r9HJS3r8zU9THuVz9vx9ty69elaRrqjG/Rf1g6v/Rh0VZ+euuuE8e7F8MQPciD10D1teXqk7v/vDojw3m+nRoIoK6/7qtgWBwVPSSKdUfY1Usy3ttxkNa4ZNYx91DeuxNzr0/EM7HD5/b/SljwydVqTz30mSfnD13+iz1d2mV3Wc/0TPnnimoOfZw+Gw5fXR0VECOpAEe+hLwOq6zdq4/baiCebZqKqqUn19vXw+n2nc5/Opvr4+9yAwOSz9+C7ppd+QXt0jvfgV4+eLIynfOt+wxrwYFolG9UHnkHqGJhxuzfmopA8VHV4ryVhm76g4q4hvwfMon21jE8vbFzPAgwjo8IyWlhYFAub95EAgoJaWltxv/tMHpK5j5rGuY9Kb30r51lQNa86c+icHz993y+g/H5GvelCSdK4sZPmOQp5nd/yLGeBhLLnDM8rKyrRnzx6Njo7OLc3aEgAGT0mdv1g8Hp01xodOWy6/p2pYUzUzqD6L64mOGKZv/gifv2ZQ/q3/qA29ay3fUejz7C0tLWptbTUdP7TtixngYQR0eI7t55ZHOq2vD39hGdAb1q7SzVtrEjSs8enGxmptuaZGn1vcPreCPvWmn5bd86rqj+xVU3izPlvdbVp2z9d59lAwrPDAmCrrVqty4+Ildse+mAEeR0AHUlmz1fp69TUpb/HUfU2mhjVX1wxq97Uz2tt8jcqvcrKgzyYZ/ec/lBSRb8VFLd/7f+jQwHo991mVTk7MV9PLtW1sKlNj02p9rl29J+eX9Ou312n3wWaVlS8u/LMUAznFdJALjq0B6fjxXcaeeTRun9tXIjXulh5Mflxuod7hfq0qe0JrVv06bnSnLo3/W733wpMOZbmHJX1Pxl76/GdKT6tvfMyWtrHp+NkTrQp2DCgaiTtf7vcp0FSru59Y2svpbqlyiOJGQAfScXHESICL30vf+nXp3tekFWsyuNF+xWbL8/ySbpL0osNHDHskfSnpakn5PZMfCob1kz/566TX//Cvfj/h8vtSQTEd2IEld+RFqn1T11uxxpiJD5029swzPIduiGWcLxS5Mt7jcGvOBuU7kMeEB8Ysr4/2jxXn/y5sEAqFTDPzmGg0qt7eXs7eI20EdDgq031T16vZpogCig5flE+T8tdYZ7CbLf5H2+xLFSLgOludzlBRa119rrKucNXpCo1iOrALAR2Oan2uXcGOAdNYsGNAxw63u3rfNDI0aQTt6hVzQXthHXRJ8m9do2X3XCtfXPnW5OpTXLduqGM3Z6vTmVUFKlS/vS7pHvpSmZ0Hx4MaWJCzQDEd2IWADseEgmHTzDwmGomq92S/RvvCrvuH3Cpozxz5XJEuc2W4SNeIZo58ruV7m9K4uznjfF5sDz2/s3Or6nSpmvdkY/fBZh07bF6tCTTVavfBZot3ecPYpTEdPvGMTp7/eG4sVjs/Vkwn2R46AR3pIikOjun5dVA/f+rtpNd/97E71fBVd/XwvvRqhxG04/9W+CRffYWiXyZfGl3+8I1pLr8nzziX8vflJtx3Rj/7s+TJVr/3/M8dW34f7Qsbe+ZFlE+R63Gyx9//i6R97J+85fuanp5eVEyHLHdkihk6HFNs+6aRoUnTzHxOVJbBXJKiwxeltAJ6haQXlW3GuV3tV8fPfWl5PbfqdNYqN1YUTSC34zhZcDxompnHRKLztfM3lgcopoOcEdDhmGLbN40OX8z6vb7qFRm+I/2M8+B4UJ1DQf3fbTP65Oz43Hii9qvpKt9gvV+fW3W6zM10dmm2u1ulmzertHFLXj/bSltbm4JBc7OaYDCo1tbWtI+TDaSojd8/0T+3n04gRy5ozgJH7T7YrEBTrWnMrfumqYKy7+oKybdw0NhjzyzbPT1jl8b0+Pt/oX997F/q0Tc+0SdnzasEsfar2ajYaFSn8/lLTOM+f4lqm5otZ+ehYFg9vw5qtM961SIdkZERDe79ts7fdruGHnxI5269TYN7v61IKJTzvXMVO062cFcy/jhZOmpT1MYvdO18eAczdDiqrLxMdz/RUhT7pv6alfJvXZNwD93fGJcYF58wd2XcCYdPPKOOC5/o8lSVLo1tWnQ9vv1qNsvvuw4c1nsvHDRluW+4bqd2HTic8PVOHEEc3rdf0++2m8am323X8MP7tPbVV7K6p13sOk4WKA9o+/obku6hO12hD0sHSXFIS9EXhklTOkfTEh1ps1twPKh/fexfSpKmRzdptOsPkr72P3z7Bt2ybV3Wn5VudTq7S7fOdHbp/G23J72+4d1fFXT5PRQK6fXXX096/f777097eXz80pieTZLlXr7cXbkkKF7M0GEp81lZt4wCKvkvL5qNhXu3vhXLtHxvk2XQ9tesTDMBLnvx+64lZdZLuyVToxodXZ713ms61emcOII4291tef3y2bMFDeh2HicrX75aT97yffWNB/NWOx9LDwEdltIvDDMq6VEV+jhWuiIjI8Zy7zu/nBsru+N2Vb/8kvxVVXkJ2lbi911Lrwpp+epuXRq7WvFpLz5FtbFsSh3H29Rx3NljTk6Ubi3ZtHgbIV7p5s0Z3S/Gzsp3dvdm31geIJDDMQR0JJXZrOxRGQVT4n0o48z1i84+aBbcvHcrLd53rdj8lsJn7zLtpW8sm9Id1YNzP2eafZ0JJ44gLtvaqLI7bjf+/zAb18WupERltzZnPDt3ovIdvdlRTMhyR1LpzMoMsaYjkQWvmG864iYznV3GzDw+iEjS7Kym3/mlLnedKcyDLXBoxyNqWne9JMlfOq2qa/4/NTef0Pf++036xoagvr72vMr887/zTLOvMxE7gujzm9P8fX6f6rfXZZ1XUf3ySyq71XzioezWZlW//FLG97KqfJeryspKNTQ0EMzhaszQkVT6szJ3Nh1JJpO920S1t/Ml2b5rT0+P+ksvJ32fU808nCjd6q+q0tpXX9HlrjPG7z3Lc+jhvjOmmXlMNDKrgY52jfWfdbCLHeAOBHQklX5hGHc1HUklnb1bq9rb+c5KXrjvWqhmHk4eQSxt3JJTAlwhK98BbsGSOyylVxgm1nRk4f+c/FfG3TM7l+b3blViLqqikhKV3XG7Shu3zJ0Bj9dx4RM9e+KZ/D1oErHsa59vwfK3z6f6+nrHl4UrN1ao4auBAh5f7Jb0nuK3ctxW+Q4oBM6hIy2pZ2XuaDqSrkgopOGH9yXMcu8vnZg7A57If9z9nwqeqZzPZh65Niaxj/VJirf/8o917rPjikbmcyN8/hJtuG6nI93jALchoMNm2TUdKZREe7e/PndCTx5/POl7Ht/5pL66YUe+HtGSk9nXdjQmsdd+JW89+6IujY8uqnznVH93wI0I6MAC8VXaEnHDDD0fjh49mrSoihNH46x1S/qGxfUjin2BTLfyHeA17KEDC8TOgPt95r8efp9f29ffsCSCuV2NSeyTzkkKw+q6zdq4/TaCOZYcAjqQQPwZ8Jimddfr0I5HCvNAC4RCIfX09DgWWNNpTJJfxXWSAigEjq2h6OTjbLhba2/na1/bjqNx9jb0iZ2kSLaH7v58DcBp7KGjaLjpbHih5HNfO9vPcqLNqqG4TlIA+caSO4qGm8+G50O+97VbWloUCJhXJdJpTGLV0Cc3FTL6AhyR9IMr/31RBHPAwJI7ikJwPGiamcdEohGdPP+x+saDrlgSd8rU1JRaW1stX2N3yddsGpM40WZ1sQaxxA4sxgwdRSG+P3gi/SmuF7u2tjYNDQ1ZviYWbHsGJ/T+6QvqGZqw5bMzaUySfkMfAHZjho6iEN8fPJG6FNeLWWypPZnYvraWrdB3fnRCH3TOB/6bt9boqfuaVLFiWT4edVFDn/GKsCZXj2vV2GqtCq/Oqs3qYt0yjrEVR/EiIF8I6CgKC/uDx/h9fjWtu97Ty+2pjpDV1NSopaVF//Ynn+qjrmHTtY+6hvXYGx16/qH8VLaLNfQ58w/dOnnre7pQP7+XXh/epL1r/yCHu1uXfgWWOpbcUTTcdjZ8prNLU21vO94/PdURspaWFp0bu6wPOocUWZAwF4lG9UHnkG3L7wslOg+/+2CzPr/7hAY3njO9tq/iyxwTGB+VcWwt3ocyMt8BMENH0XDL2fDIyIiG9+1P2NjFX1Vl++fFuqslO0JWWVmpvz99wfIevcOTaqhZZdszWZ2HH9SgeisW95yPKJcExm6ZZ+bzdzXGe8TyO5Y6ZugoOhvLA/rqhh0FW2Yf3rdf0++aj2BNv9uu4Yf3OfaZqY6Q1a9Zafn++mrr65lqa2tTMBg0jQWDQbW2tjqUwJh+6VdgqWKGDmRgprPLNDOfMzur6Xd+qctdZ+a6ttkp1RGyhrWrdPPWGn3UNWxadvf7fLqxsdrW2XmyJL3YefjG7Y2W788ugbEQpV9JvkNxYYYOZGC2e/FScrzLZ886+vlWR8ieuq9JNzZWm8ZubKzWU/c12foMqZL0Vs6sdKC5Taz068J/svxXxu0MuKMyWrV+Q9KfSrrnys/Wf26g0JihAxko2bTJ8nrp5s35eZAEKlYs0/MP7VDP0IR6hydVX73S1pn53OekUef9UO0jejauTO+q0dW6zn+9/qfr/yiHT35ai0u/3nRl3E5WyXcv2vxZgH2o5Q5kaHDvt4099NnZ+cGSEpXd2qy1r75SuAfLk3DfGb39N0d04eKsIiuq5sYT1Xk/O3BWx39wUuHP57Psc6/r3iNjz9yJpfD0+64DbkNABzIUCYU0/PA+W7LcQ6GQwuFwWmVVC216PKT3XzikgY75hMDL1Zt08Xf2SMuuStj17WdPtCrYMaBoJC473+9ToKlWdz9hXRO+MN6TscyezA8k7crTswCZYckdyJC/qkprX31Fl7vO6PLZsyrdvDnjRLh8tUG10/svHNK5z8xHx5aFvtTagY90y8GXF30hyU9dd7vRdx3Fi6Q4IEuljVt01dfuzCqr3erYlxuF+85ooKNd0cisaTwaiSh06tfyT44sfk9R1nXPZ/IdYC8COpBn+W6Daofxc9bnvMcGehaNLazrvpA9dd2d8LSMZLt4TiTfAfZiyR3Is1THvuxug2qH8g3WS82raxfPXGN13ZPtobtvuT0m1nfdyeQ7wH7M0IE8S+fYl9tUbNyi2qZm+fwlpnGfv0S1Tc1aXbc54ft2H2xWoKnWNBZoqtXug81OPaqNGmQkwLk3mIeCYfX8OqjRPs7Igxk6ECc/lcHSqc3uNjOdXfrq9v9BJyYnde70x3PjG67bqV0HDid9X1l5me5+okWjfWGN9o+psm51WjPz4HhQAwWs1+92U2PTan2u3ZR0mPtxQBQ7jq0BBWjLOT09rdbWVtdnuSdqRHP59ptU+if/QhVbfyvpzDxbY5fGdDiuII0kbV9/gw7teETly926555/xXccEPlAQAe0X0YlsEjcmF9GIpSzlcGS1WZ3i3wX0Xn8/b9I2vP+yVu+b/vnFaNQMKyf/MlfJ73+h3/1+y7OT4CT2EPHEhdryxlZMB7fltMsUQ/wbFnVZi+0uUY0s+ajavGNaOwUHA/q5PmPTcFckiLR+barKNbjgMgH9tCxxKXTltPYTy/GYjDpVqILBcMKD5j3uNNpRGNnZ7l02q6yn17MxwHhNAI6lrj0K4NZFYOJr1/uBul++bBKrsp3I5raFG1Vs2u76j3FexwQTmPJHUtcepXBiq0YTLqV6Fqfa1ewY8D8uo4BHTvcrmVbG1V2x+1SifmomkpKVHbH7bb3fQ+UBxxou2qPyNCkZk8PKTI0WbBniFfcxwHhFGboQBptOYupGEzsy8dC8V8+Kisr06q1Xv3yS4sb0dzarOqXX3Lk2Q/teET/6a+/pwv/dFLn15XpwvoyNa27Xod2POLI56USvTijmSOfK9I5X9rWv3WNlt1zrXwrlhXkmaTsjwPC2wjoQBqVwYqpGEy6Xz7CA2Oq3DiiitqQRvurFO5fY35d/5gqvxrIuRFNuiIjI5rat1/3x315UPPNqvvf/438BTqyNnPkc0W6zHXqI10jmjnyuZbvbSrIM8Wr3FhBIMccAjowp0HJCsoUUzGY9L58jKrut/+99vzFhxo/F9HqWr9C/Vt07PDv6tLEVcbr4pKrShu3OBbIY4b37TeOyMU7/l81/PC+gvSZjwxNmmbmc6JSpHNEkaFJ+WtW5v25gGQI6ECaWlpaFhWDCQQCamlxVyGPdL58TI//K73/QrsGOuaPpNX+s3/SHftm9bfP3pf35Kq5I3ILxR2Rc/oLxULR4Yupr+cY0NM9hQCkg4AOpKmsrEx79uxxfTEYKdWXj269/8K7OveZ+bz3ub+blXynte3OUt3yz/ObXJXvI3Lp8FWvyOm6lWI8Agn3I6ADGXJzII+x+vIR7juhgY6FhXSkaEQa6Ijo955flvd64Pk+IpcOf81K+beuMfbQ4w83+CR/45qcltuL6QgkigfH1gAPS1SJbvycdbXnsYH8V4PO5ohcuO+M+k7+SmP9Z517rnuulb/RnCzobzSy3LNVbEcgUTyYoQNLTPmGr1peX11rfd0p6R6Rmx4P6f0XDmmgYz6BrrapWbsOHNbycntXTnwrlmn53iZFhiYVHb4oX/WKnBPhiukIJIoLAR1YYoze5jfr3GcfKL5sus8vbbjuZts7qKXLX1WV1hG59184pHOfHTeNnfvsuN574aDu/O4PnXm2mpU5J8DFFNMRSBQXltyBJWjXgee14Tpz4tuG65q168DzhXmgOKWNW3TV1+5Musw+0NGuaMTcMCYamdVAR3vq5ffBU9Lpn0tDp2184szETiH4fD7TuM/nU319PQEdWWOGDqSlW0Yjl8VFZ4rR8vJK3fndH2qs/6zGBnq0urahYDPzTIyf+9Ly+thAT+I/x+Sw9NMHpM5fzI9t/bp072vSijWLX++wYjkCieJCP3S4Us/ghHpHJlVfvVINNasK+CSjkh6VuSzsThllYanQlW/hvjP62Z8lzwL/ved/njig//guqeuYFI2b2ftKpMbd0oNv2f+gaSqGI5AoHszQ4Sqjk5f0+Juf6oPOobmxm7fW6Kn7mlRRkNrZj0r6cMHYhzJqv7+Y/8dZ4oz9/2ad++y4adnd5y/Rhut2Jg7mg6fMM/OY6KwxPnRaqtnm3ENbIJDDTuyhw1Uef/NTfdQ1bBr7qGtYj73RUYCn6ZYxM194ZjtyZbwn708EadeBw9pw3U7T2IbrdmrXgcOJ3zDSaX3D4S9sejKgsJihwzV6BidMM/OYSDSqDzqH1DM0kefl98Udy8y+lBf204tNxvv/a7Za37D6GtOPoWDYaFxDBzMUGQI6XKN3xLrXdO/wZJ4Den2K61fn5SnyxT15C+lZXbc5vUS+tV8xEuCS7aFfWW6fGptW63Ptppay9dvrtPtgc94r5wHZIKDDNerXWJ/zra/Od2erTTIS4D6UedndL6Nfujdm5+7LW3DAva9Jb37LvJfeuNsYv6L1uXYFOwZMbwt2DOjY4Xbd/QTZ53A/9tDhGg1rV+nmrTXyLzif6/f5dPPWmhxnjd2S3lPm+95Pywje8W66Mu4N7spbcMiKNUY2+/5T0t6jxn8ffGvuyFooGFbvyX5FIwvKsUai6j3Zr9E+6+pukhQcD+rX506obzyY8rWAE5ihw1Weuq9Jj73RYZot3thYrafua8ryjrkeO6uQkc3eI2PP3Bvn0GPcl7fgsJptCTPawwNjlm8b7R9Lup8+dmlMh088o5PnP54b277+Bh3a8YjKl69O+B7ACQR0uErFimV6/qEd6hmaUO+wHfu5dh07a5CXAnmMk3kLM51dmu3uTlrC1U0qaq0Db2Vd8uuHTzyjjgufmMY6LnyiZ088oydv+b4djwekhYAOV2qoWWXDzDB27Gyh+GNn3gvSmXAibyEyMqLhffvNTVbuuF3VL78kf1VVxvfLh6pAheq31ynYMWBadvf5fQo01SadnQfHg6aZeUwkGtHJ8x+rbzyojeUBx54biMceOjwsnWNnS5sTeQvD+/Zr+t1209j0u+0afnhfTs/qtN0HmxVoqjWNBZpqtftgc5J3SAMT/UmvSVJ/iuuAnZihw8OW1rGzbNmZtzDT2WWamc+ZndX0O7/U5a4zrl1+Lysv091PtGi0L2zsmadxDr12VZ3l9boU1wE7EdDhYUvj2Fmu7MxbmO3utrx++exZ1wb0mMqNFWkXlAmUB7R9/Q3quPCJInG9aP0+v5rWXc9yO/KKJXd4nH3HziJDk5o9PaTIkHUiWbFqqFmlW7atyyl3oWTTJsvrpZs3Z33vbIRCIfX09Gh0dNSxzzi04xE1rbveNNa07nod2vGIY58JJEK3NSwR2R87i16c0cyRzxXpHJkb829do2X3XCtfisIr4b4zGj/3pSPtSZ28dy4G937b2EOfjavKVlKislubtfbVV/LyDFNTU2prazO1J62vr1dLS4vKypyp+tY3HlT/RL/qVtUxM0dBENCBFC692qFI14gU/zfFJ/kb12j53sT7zNPjIb3/wiENdMwnh9U2NWvXgcNaXp5bdy0n722HSCik4Yf3FTTL/ejRowoGg4r/583n8ykQCGjPnuTtV4FiRkBH0XOyBnlkaFKXXv4o6fXlD98of83io11v/+UfJ23xeed3f5jTMzl5bztd7jpj7Jnn+Rx6KBTS66+/nvT6/fffT8tSeBJJcSha+ahBHh2+mPr6goAe7jtjmj3PvTYyq4GOdo31n816idzJe9uttHFLxoE8FAopHA7n1Cc8HLYu0zo6OloUAT0yNKno8EX5qlck/NIILERAR9GyqkH+/EM7bPkMX/WKjK+Pn7M+3z420JN10HXy3oWUaM97bcU63XrzrVq3eW1G96qosM5Qd3swzyVnA0sbWe4oSrEa5JEFO0bxNcjt4K9ZKf/WNZJvwQWf8Y9soplT+Qbr8+2ra7M/LufkvQupra1NwaC5qcmF0AUdeeX/1c+eaNX0+HTa96qqqlJ9fb18C4rl+Hw+1dfXuz6gzxz53MjZiBPpGtHMkc8L9EQoFgR0FKV0apDbZdk918rfuMY05m80ZkyJVGzcotqmZvn8JaZxn79EtU3NOc2gnbx3oYRCIfX29mphOo/PL/nWRxQ83adjhxdvM1hpaWlRIGDONA8EAmppcXcb1MjQpDEzX5jZFJUinSOePTIJe7DkjqKUz97pvhXLtHxvU0Z7mrsOHNZ7Lxw07XdvuG6ndh04nPPzOHnvQki15x1dEZlrYZpuwZeysjLt2bNHo6Ojc3vmbp+ZS9nlbAAxBHQUpVgN8o+6hk3L7n6fTzc2VjvS8tNfszLtf0yXl1fqzu/+UGP9Z419bRvPijt570JIteetCWPp3KqFaTLFEshjssnZAGJYckfReuq+Jt3YWG0ay613uv1W123Wxu23ORJwU9073HdGfSd/pbH+s7Z/tp2S7XlHI1L0vF+aNP6Zsmph6hXZ5GwAMZxDR9Gzr3e6N7i98Ewi09PTam1tNWW5R8/7pZNl8kX8CjTV6u4n3L3/bRey3JEtAjrgMcVSeCaRC30X9Kv/clyDn4bmZub12+u0+2CzysqdKdnqVpxDR6YI6PAsJyvIuVW474x+9mfJS5v+3vM/L4r99kxamAIwkBQHz8lHBTm38krhmUxamAIwkBQHz7GqIJc3g6ek0z+Xhk7n7zPl3cIzAFJjhg5PiVWQWyi+gpyjy++Tw9JPH5A6fzE/tvXr0r2vSSvWJH+fTWKFZ5LtoSeanS/FrYmcDZ6SRjql6mukmm2FfhpAEgEdHpNOBTlHg9ZPH5C6jpnHuo5Jb35LevAt5z43TrqFZ5by1oQkzXR2aba7O7NucAX+wgZYISkOntIzOKFvvpi8TOjrB5qdC+iDp6SXfiP59f2n8jqbS1V45js/OpG0MI9dzW3cKDIyouF9+7Pr1/7ju4wvaNH51Q/5SqTG3Xn7wgYkwx46PCVWQc6/oEiJ3+fTzVtrnJ2dj3RaXx/+wrnPTsCq8Ey+mtu40fC+/Zp+1/ylb/rddg0/vM/6jYOnjJl5fDCXjJ87f5H3fAlgIQI6PKdgFeTWbLW+Xn2Ns5+fgXw2t3GTmc4uY2Y+uyAoz85q+p1f6nLXmeRvdtkXNmAh9tDhORUrlun5h3bkv4Lc2q8Y+6nJlmRdlDyVz+Y2bjLb3W15/fLZs8n304voCxuWJmboKCo9gxN6//SFtJaEG2pW6ZZt6/KbuX3va0bwjte42xh3kWRbE1Wll7V7c6kqSy8X6MmcVbJpk+X10s2bk1+MfWHzmVvXyldijLvoCxuWJpLiUBSKLiN76LSxBOviY03hizN67I0OfdA5pOW+Wd1RPaj6q6bmrtfX16ulpUVlZdYlV4PjQQ1M9KtuVZ02lgcsX+sGg3u/beyhxy+7l5So7NZmrX31Fes3XxwxTiyQ5Q4XIqCjKCzVjOx86BmaUPvbf6uJkQuK/+fA5/MpEAhoz57EpWTHLo3p8IlndPL8x3Nj29ffoEM7HlH5cvd2RouEQhp+eF92We4xRfCFDUsPe+hwvYIXi/G4ipIZjQ+fXzQejUbV29ur0dHRhD3FD594Rh0XPjGNdVz4RM+eeEZP3vJ9px43Z/6qKq199RVd7jpj7JmneQ49FAopHA4bPdZrthHI4ToEdLhewYvFeFw4HLa8niigB8eDppl5TCQa0cnzH6tvPOj65ffSxi1pBfKpqSm1tbWZWrumux0B5BNJcXC9pZqRvVi3pPck9dh614oK6yYoiWbnAxP9lu/pT3G9mLS1tSkYDJrGgsGgWltbC/REQGIEdLheIYvFZJJV75xRSfslfUPSn0q658rP1jPrdFVVVam+vl6+Bb9fn8+n+vr6hAG9dlWd5T3rUlwvFqFQSL29vVqYahS/HQG4BQEdRSHfxWJGJy/pOz86oW++2K4/f+VjffOFdn3nRycUvjjjyOdZe1TShwvGPpT0Pds+oaWlRYGAeYk8EAiopaUl4esD5QFtX3+D/D7zPyF+n1/b19/g+uX2dKWzHQG4BVnuKCr5Khbjnqz6bhkz82SOSLKvJero6OjcnnmimXm88UtjerYIs9wzEQqF9Prrrye9fv/99yf9PUWGJhUdvihf9Qr5a5bKthAKiaQ4FJWGmlWOJ8DlI6s+/ZalvRbXJOlL2RnQ0wnkMeXLV+vJW76vvvGg+ovoHHomYtsRwWAw4ZG+RL+r6MUZzRz5XJHOkbkx/9Y1WnbPtfK5sWYCPIOADizgZFZ95gVy6lPc8eqsnsNOG8sDtgRyt85oW1pa1Nraaspyt9qOmDnyuSJdI6axSNeIZo58ruV7He4ngCWNgA4s4GRW/eNvfqqPuoZNYx91DeuxNzqSLOVvkrRTxp55JG7cL+km2Tk7LxS3z2jLysq0Z8+etLYjIkOTpj/HnKgU6RxRZGjSVV9W4C0kxQELOJVVn33L0qdlBO94N10ZL35WM1o3qaysVENDg+WWRHT4ouU9Ul0HckFABxJwIqs++5alFZJelJEA94Mr/33xynhxm5vRLkzNjZvRFhNf9YqcrgO5YMkdSMCJFqy5L+U3yAtL7PHSmtEW0RK1v2al/FvXGCsO8V9SfJK/cQ3L7XAUM3TAgp0tWAtZIMet7J7RuqEQ0LJ7rpW/0dx5zd9o5AQATuIcOpBH8S1LY1zdBjYPLr3akXRGm25WuBvb67o1ax/eRUAHCiBfBXKKgR1Z7u4pBAQUDgEdgCtkO6PtGZzQN19sT3r99QPNS/5LE5YGkuKAJatbRiW6q+WGZDt/zcqsEuBorwsYCOjAkjMqo+HL8bixnTLOtRffUTja6wIGstyBJcf57m35xOkBwEBAB5aUbhkz88iC8ciV8Z68P5Ed8t1eF3AjkuKAJeU9SX9qcf0Hknbl6Vnsx+kBLGXsoQOpDJ6SRjql6mukmm2Ffpocub97Wy7y0V4XcCsCOpDM5LD00wekzl/Mj239unTva9KKNcnf52re794GLFXsoQPJ/PQBqeuYeazrmPTmt/L2CM6UMvV29zZgqWIPHUhk8JT00m8kv77/lKPL7/kpZdoj6Uu55Rw6gNwwQwcSGem0vj78haMf//ibn+qjrmHT2Eddw3rsjQ4bP6VBRgIcwRzwAgI6kMiardbXq69x7KN7Bif0QeeQqS65JEWiUX3QOVTQTmIA3IuADiSy9itGApyvxDzuKzHGHVxuT6eUKQAsREAHkrn3Nalxt3mscbcx7iBKmQLIBsfWgGRWrJEefEsaOm3smefpHHqslGmydqCcswaQCFnugAuFL87osTc6HM5yd0a474zGz32p1bUNWl23udCPAywZBHTAxYqplOn0eEjvv3BIAx3zvclrm5q168BhLS+vLOCTAUsDAR2ALd7+yz/Wuc+OKxqZnRvz+Uu04bqduvO7PyzgkwFLA0lxAHIW7jujgY52UzCXpGhkVgMd7RrrP1uYBwOWEAI6gJyNn/vS8vrYQHG2ZQWKCQEdQM7KN1h3aVtdSzU6wGkEdAA5q9i4RbVNzfL5zYV4fP4S1TY1k+0O5AEBHYAtdh04rA3X7TSNbbhup3YdOFygJwKWFrLcAdhqrP+sxgZ6OIcO5BkBHQAAD2DJHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAHENABAPAAAjoAAB5AQAcAwAMI6AAAeAABHQAADyCgAwDgAQR0AAA8gIAOAIAH/P/UxKi8ZZ/8TAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualization.show3dim(outputs, num_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979d64f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13454dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import extractor as ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb40e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['../dataset0/cam0/1/0.jpeg', '../dataset0/cam1/13/60.jpeg']\n",
    "a = ViT.get_ViT_feat(paths[0])\n",
    "b = ViT.get_ViT_feat(paths[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72e05527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8442], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as tnf\n",
    "cos_sim = tnf.cosine_similarity(a, b)\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a7034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6721d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea0916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4b1ae58a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7071,  0.7071])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor([-0.5, 0.5])\n",
    "x = nn.functional.normalize(x, dim=0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a9e993f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]**2+x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95536248",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tianyi1.13",
   "language": "python",
   "name": "tianyi1.13"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
